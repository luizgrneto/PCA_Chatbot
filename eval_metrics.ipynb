{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f08cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgrneto/agent-pca/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "# from datasets import Dataset\n",
    "import json\n",
    "\n",
    "\n",
    "import os\n",
    "# import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cfaa43",
   "metadata": {},
   "source": [
    "## Carregar Vector Store e configurar fun√ß√µes de retrieval e gera√ß√£o de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa49bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_transformers\n",
    "#rank-bm25\n",
    "#langchain_text_splitters\n",
    "#chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a332e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vectorstore.hybrid_vector_store import HybridVectorStore\n",
    "from src.config.settings import settings\n",
    "\n",
    "#### Chroma Vector Store\n",
    "#### Para criar do zero, ver Vector_Store.ipynb\n",
    "store = HybridVectorStore(\n",
    "    persist_path=settings.DATA_DB,\n",
    "    embedding_model=settings.EMBEDDING_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "729b06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "llm = OllamaLLM(model=\"deepseek-r1:latest\", temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Voc√™ √© um ACP - um Agente Conversacional Pedag√≥gico especializado em ajudar estudantes com d√∫vidas relacionadas a conte√∫dos acad√™micos.\n",
    "Sua fun√ß√£o √© fornecer respostas claras e informativas com base no material de estudo fornecido pelo contexto.\n",
    "Inclua todas as informa√ß√µes relevantes do contexto em suas respostas, evitando suposi√ß√µes ou informa√ß√µes externas.\n",
    "Suas respostas devem ser sempre em portugu√™s brasileiro e devem usar um tom leve.\n",
    "\n",
    "Se n√£o encontrar a resposta no contexto, diga:\n",
    "\"Nenhuma informa√ß√£o dispon√≠vel no contexto.\"\n",
    "            \n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pergunta:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "chain = (\n",
    "        prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bdbe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√ìtimo questionamento! Vamos esclarecer a diferen√ßa entre esses dois pap√©is importantes no ecossistema de Machine Learning.\n",
      "\n",
      "De acordo com o contexto:\n",
      "\n",
      "1.  **Foco:** O Data Scientist se concentra principalmente em extrair insights e desenvolver/refinar modelos de Machine Learning. O ML Engineer se concentra na parte de engenharia, respons√°vel por construir, implementar e manter esses modelos.\n",
      "\n",
      "2.  **Expertise:** O Data Scientist tem uma forte base em an√°lise, matem√°tica e estat√≠stica. O ML Engineer tem uma compreens√£o mais profunda de princ√≠pios de engenharia de software, infraestrutura e servi√ßos em nuvem.\n",
      "\n",
      "3.  **Colabora√ß√£o:** Ambos precisam de habilidades de comunica√ß√£o, mas o ML Engineer tende a trabalhar mais com engenheiros de software, DevOps e profissionais de TI para integrar os modelos de Machine Learning aos sistemas existentes.\n",
      "\n",
      "Em resumo, embora ambos contribuam para o ecossistema de Machine Learning, o Data Scientist √© mais focado na an√°lise e modelagem estat√≠stica, enquanto o ML Engineer √© mais focado na engenharia e implementa√ß√£o dos modelos. H√° sobreposi√ß√£o, mas suas √°reas de especializa√ß√£o s√£o distintas! üòä\n"
     ]
    }
   ],
   "source": [
    "#Fun√ß√£o que integra busca e gera√ß√£o de resposta\n",
    "\n",
    "def rag_pipeline(question: str):\n",
    "    docs = store.hybrid_search(question, top_k=5)\n",
    "    context = \"\\n\\n\".join([d[1] for d in docs])\n",
    "\n",
    "    chain = (\n",
    "        prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "response = rag_pipeline(\"Qual a diferen√ßa entre Data Scientist e ML Engineer?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c0802b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the machine learning ecosystem.\\nWhat is a Data Scientist ?\\nA Data Scientist is an expert in extracting valuable insights from large\\nvolumes of data. With a strong background in mathematics, statistics, and\\nprogramming, Data Scientists analyze and interpret data to solve complex\\nproblems and support better decision-making within an organization. They\\nwork closely with business stakeholders to understand their objectives and\\ndevelop machine learning models to help achieve those goals.\\nKey responsibilities of a Data Scientist include:\\nGathering, cleaning, and preprocessing data\\nDeveloping machine learning models and algorithms\\nEvaluating model performance and optimizing as needed\\nCommunicating findings and insights to business stakeholders\\nWhat is an ML Engineer?\\nAn ML Engineer, or Machine Learning Engineer, is a professional who\\ndesigns, develops, and implements machine learning models. They work\\nclosely with data scientists to translate prototypes into efficient and', \"Unlock your future in ML Ops with Navigating ML Ops: A\\nBeginner' s Bluepr int.\\nML Engineer vs Data\\nScientist: What's the\\ndifference?\\nMay 7, 2023 ML Engineer , Data Scientist, Careers,\\nPhoto by Fatos Bytyqi on Unsplash\\nLooking t o up y our ML Ops game? Check out the ML Ops\\nNow newslett er.\\nThe landscape of machine learning and artificial intelligence is evolving\\nrapidly, and as a result, we see a variety of roles emerging in the field. T wo\\nprominent roles are ML Engineers and Data Scientists. While these roles11/11/25, 10:05 PM MLOps Now - ML Engineer vs Data Scientist\\nhttps://mlopsnow.com/blog/ml-engineer-vs-data-scientist/ 1/4\\nshare some similarities, they also have important differences that set them\\napart. In this article, we‚Äôll explore the distinctions between ML Engineer vs\\nData Scientist, and discuss how each of these professionals contributes to\\nthe machine learning ecosystem.\\nWhat is a Data Scientist ?\\nA Data Scientist is an expert in extracting valuable insights from large\", \"ML Engineer vs Data Scientist: What' s the differ ence?\\nMLOps Engineer vs Data Scientist: What' s the differ ence?\\nMLOps Engineer vs ML Engineer : What' s the differ ence?\\nFollow me on Twitter: @huwdev ¬© MLOps 2024 - Built by Huw Fulcher11/11/25, 10:05 PM MLOps Now - ML Engineer vs Data Scientist\\nhttps://mlopsnow.com/blog/ml-engineer-vs-data-scientist/ 4/4\", 'designs, develops, and implements machine learning models. They work\\nclosely with data scientists to translate prototypes into efficient and\\nscalable code, as well as to optimise algorithms for better performance.\\nKey responsibilities of an ML Engineer include:\\n1. Developing and implementing machine learning models and\\nalgorithms\\n2. Collaborating with data scientists to fine-tune and optimise models\\n3. Integrating ML models into existing software systems or creating new\\napplications11/11/25, 10:05 PM MLOps Now - ML Engineer vs Data Scientist\\nhttps://mlopsnow.com/blog/ml-engineer-vs-data-scientist/ 2/4\\n4. Staying up-to-date with the latest trends and advancements in\\nmachine learning research\\nIn essence, ML Engineers are responsible for the development and\\nimplementation of machine learning models that can solve complex\\nproblems and provide valuable insights.\\nML Engineer vs Data Scientist: K ey Differ ences\\nWhile there is some overlap between the roles of ML Engineer and Data', 'problems and provide valuable insights.\\nML Engineer vs Data Scientist: K ey Differ ences\\nWhile there is some overlap between the roles of ML Engineer and Data\\nScientist, the main differences are in their areas of focus and expertise.\\n1. Focus : Data Scientists primarily work on developing and refining\\nmachine learning models, while ML Engineers concentrate on the\\nengineering side of building, deploying, and maintaining those\\nmodels.\\n2. Exper tise: Data Scientists possess strong analytical and mathematical\\nskills, along with knowledge of machine learning algorithms and\\ntechniques. ML Engineers, in contrast, have a deeper understanding of\\nsoftware engineering principles, cloud services, and infrastructure.\\n3. Collaboration : Both roles require excellent communication and\\ncollaboration skills, but ML Engineers often work more closely with\\nsoftware engineers, DevOps teams, and IT professionals to ensure the\\nseamless integration of machine learning models into an']\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o apenas de recupera√ß√£o de documentos\n",
    "\n",
    "def real_retrieval(question: str):\n",
    "    docs = store.hybrid_search(question, top_k=5)\n",
    "    return [docs[i][1] for i in range(len(docs))]\n",
    "\n",
    "retrieve = real_retrieval(\"Qual a diferen√ßa entre Data Scientist e ML Engineer?\")\n",
    "print(retrieve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2999ee6",
   "metadata": {},
   "source": [
    "## Usando Deep Eval para m√©tricas das gera√ß√µes de respostas contidas no ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5eba01",
   "metadata": {},
   "source": [
    "Datasets completos e as avalia√ß√µes est√£o dentro da pasta artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68572182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from deepeval.test_case import LLMTestCase\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7f80823",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Gera m√©tricas para cada uma das entradas da tabela de ground_truth.\n",
    "\n",
    "test_cases = []\n",
    "\n",
    "df = pd.read_csv(\"data/ground_truth/ground_truth_mlops.csv\", encoding=\"latin-1\")\n",
    "for index, row in df.iterrows():\n",
    "    test_cases.append(LLMTestCase(input=row[\"question\"], expected_output=row[\"answer\"], actual_output=rag_pipeline(row[\"question\"]), retrieval_context=real_retrieval(row[\"question\"])))\n",
    "\n",
    "### Salva os test_cases gerados em um arquivo JSON. Descomentar para usar.\n",
    "\n",
    "test_cases_dicts = [\n",
    "    {\n",
    "        \"input\": tc.input,\n",
    "        \"expected_output\": tc.expected_output,\n",
    "        \"actual_output\": tc.actual_output,\n",
    "        \"retrieval_context\": tc.retrieval_context\n",
    "    }\n",
    "    for tc in test_cases\n",
    "]\n",
    "\n",
    "# Salva a lista de dicion√°rios em um arquivo JSON\n",
    "with open(\"artifacts/eval_metrics/deepseek-r1/test_cases_mapeados.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(test_cases_dicts, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31142cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Carrega o JSON salvo anteriormente, caso necess√°rio. Descomentar para usar\n",
    "\n",
    "# with open(\"artifacts/eval_metrics/gpt-oss/test_cases_mapeados.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     test_cases_dicts = json.load(f)\n",
    "\n",
    "# # Recria a lista de LLMTestCase\n",
    "# test_cases = [\n",
    "#     LLMTestCase(\n",
    "#         input=tc[\"input\"],\n",
    "#         expected_output=tc[\"expected_output\"],\n",
    "#         actual_output=tc[\"actual_output\"],\n",
    "#         retrieval_context=tc[\"retrieval_context\"]\n",
    "#     )\n",
    "#     for tc in test_cases_dicts\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98943174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.models import OllamaModel\n",
    "\n",
    "# Modelo usado para gera√ß√£o de m√©tricas que necessitem de LLM. \n",
    "# PS: S√≥ consegui fazer o llama3 usar aqui, o gpt-oss e deepseek-r1 deram erro de timeout repetidamente.\n",
    "\n",
    "model = OllamaModel(\n",
    "    model=\"llama3:latest\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c928d970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/lgrneto/agent-pca/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/lgrneto/agent-pca/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.6396524110809825, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.64 because irrelevant nodes (nodes 2, 4, 6, and 8) are correctly ranked lower than relevant nodes, as they lack direct connections to the expected output of defining MLOps. The first node's relevance is evident from its mention of 'MLOps', while subsequent 'yes' verdicts provide more specific explanations aligning with the expected output., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5384615384615384, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.54 because the contextual recall score indicates that most sentences can be attributed to nodes in the retrieval context, but not all, suggesting a good match between expected output and retrieval context, with some minor discrepancies., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.7948717948717948, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.79 because the retrieval context contains relevant statements that discuss the definition of MLOps, its relationship with DevOps, and its importance in managing machine learning projects, despite some irrelevant information present., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the answer directly addresses the question about what MLOps is, making it highly relevant and leaving no room for improvement., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© MLOps?\n",
      "  - actual output: MLOps √© um conjunto de pr√°ticas e metodologias voltadas para gerenciar o ciclo de vida dos projetos de Machine Learning (ML). Ele surgiu da necessidade de padronizar e automatizar processos espec√≠ficos do ML, como o desenvolvimento, implanta√ß√£o e manuten√ß√£o de modelos, que s√£o diferentes dos desafios enfrentados em projetos tradicionais de software ou dados.\n",
      "\n",
      "Em resumo, o MLOps une elementos de DevOps e DataOps para garantir que os sistemas de ML sejam desenvolvidos, implantados e operados de forma eficiente e confi√°vel. Isso inclui a padroniza√ß√£o de processos, automa√ß√£o de tarefas cr√≠ticas e a cria√ß√£o de uma abordagem mais coordenada entre equipes de cientistas de dados, engenheiros de ML e DevOps.\n",
      "\n",
      "Al√©m disso, o MLOps ajuda a reduzir riscos, otimizar recursos e garantir que os modelos ML funcionem de forma est√°vel em ambientes de produ√ß√£o, permitindo que organiza√ß√µes aproveitem melhor os dados e melhorem seus processos de decis√£o. üòä\n",
      "  - expected output: MLOps √© a disciplina que combina pr√°ticas de Machine Learning, DevOps e engenharia de software para gerenciar o ciclo de vida completo de modelos, desde desenvolvimento at√© monitoramento e manuten√ß√£o cont√≠nua.\n",
      "  - context: None\n",
      "  - retrieval context: [\"Unlock your future in ML Ops with Navigating ML Ops: A\\nBeginner' s Bluepr int.\\nOther ar ticles y ou might be int erested in:\\nMast ering ML Ops: The K ey to a Successful ML Ops Car eer\\nThe ML Ops Platform: R evolutionising Machine Learning Efficiency\\nThe ML Ops Lifecy cle: A Concise Guide t o Streamlining AI and\\nMachine Learning Pr ojects\\nWhat is ML Ops? Demystif ying Machine Learning Operations11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations\\nhttps://mlopsnow.com/blog/what-is-mlops/ 10/11\\nMast ering ML Ops: ML Ops Best Practices and Challenges\\nFollow me on Twitter: @huwdev ¬© MLOps 2024 - Built by Huw Fulcher11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations\\nhttps://mlopsnow.com/blog/what-is-mlops/ 11/11\", 'accommodate the ML lifecycle. This integration ensures a streamlined and\\nefficient development process, ultimately leading to more reliable AI\\napplications and lower maintenance costs.\\nTo summarise, ML Ops builds upon DevOps principles and customises them\\nto suit the unique challenges of machine learning projects, thus enabling a\\nmore seamless and efficient management of these projects throughout\\ntheir lifecycle.11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations\\nhttps://mlopsnow.com/blog/what-is-mlops/ 4/11\\nFor a more in-depth look at ML Ops vs DevOps check out our other blog\\npost. .\\nModel Dev elopment and Deployment\\nModel Cr eation\\nModel creation is an essential part of the ML Ops process, focused on\\ndeveloping machine learning models based on specific requirements. In\\nthis phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the', \"Want t o become an ML Ops mast er? Sign up t o the ML Ops Now\\nnewslett er to get w eekly ML Ops insights.11/11/25, 10:04 PM MLOps Now - MLOps Best Practices and Challenges\\nhttps://mlopsnow.com/blog/mlops-best-practices-and-challenges/ 6/7\\nUnlock your future in ML Ops with Navigating ML Ops: A\\nBeginner' s Bluepr int.\\nOther ar ticles y ou might be int erested in:\\nMast ering ML Ops: The K ey to a Successful ML Ops Car eer\\nThe ML Ops Platform: R evolutionising Machine Learning Efficiency\\nThe ML Ops Lifecy cle: A Concise Guide t o Streamlining AI and\\nMachine Learning Pr ojects\\nWhat is ML Ops? Demystif ying Machine Learning Operations\\nMast ering ML Ops: ML Ops Best Practices and Challenges\\nFollow me on Twitter: @huwdev ¬© MLOps 2024 - Built by Huw Fulcher11/11/25, 10:04 PM MLOps Now - MLOps Best Practices and Challenges\\nhttps://mlopsnow.com/blog/mlops-best-practices-and-challenges/ 7/7\", 'seamless and efficient integration of ML into existing processes.\\nMLOps is more than just the technical side of ML lifecycle management; it\\nalso incorporates best practices and methods used in software\\ndevelopment and DevOps. Bridging the gap between data scientists, ML\\nengineers, and DevOps, ML Ops enables a more coordinated approach to\\nML projects. T eams can more easily track, reproduce, and iterate on\\nmodels, ensuring stability and performance in production environments.\\nBy adopting an ML Ops approach, organisations not only position\\nthemselves for better scalability and faster deployment of ML models, but\\nalso optimise resources and reduce risk. As a result, businesses can\\nleverage data more effectively, enhancing their decision-making processes\\nand achieving better outcomes in the competitive marketplace.\\nFundamentals o f ML Ops\\nMachine Learning Operations\\nMLOps stands for Machine L earning Oper ations . It is an IT practice that', '‚Ä¢ Handling concerns about model fairness and adversarial attacks.\\nMLOps is a methodology for ML engineering that unifies ML system development (the ML element) with ML system \\noperations (the Ops element). It advocates formalizing and (when beneficial) automating critical steps of ML system \\nconstruction. MLOps provides a set of standardized processes and technology capabilities for building, deploying, \\nand operationalizing ML systems rapidly and reliably.\\nMLOps supports ML development and deployment in the way that DevOps and DataOps support application engi -\\nneering and data engineering (analytics). The difference is that when you deploy a web service, you care about resil -\\nience, queries per second, load balancing, and so on. When you deploy an ML model, you also need to worry about \\nchanges in the data, changes in the model, users trying to game the system, and so on. This is what MLOps is about.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=521298;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59.</span>65s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m59.\u001b[0m65s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7555555555555555, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.76 because irrelevant nodes (nodes 2 and 4) are correctly ranked lower than relevant nodes (nodes 1 and 3), as they don't provide information about the differences between a Data Scientist and an ML Engineer, which is crucial to understanding the question., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the contextual recall score indicates that the expected output can be partially attributed to nodes in retrieval context, but not entirely, suggesting a moderate level of relevance between the two., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.8, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.80 because the input question about the difference between MLOps and Data Scientist is well-represented in the retrieval context statements that discuss the development lifecycle of data science projects, ML system construction, and the challenges faced by ML engineers. For example, statement 'To understand ML Ops, it‚Äôs essential to be familiar with the development lifecycle of data science projects.' directly relates to the input question, while other relevant statements like 'Practicing MLOps means that you advocate for automation and monitoring at all steps of ML system construction...' provide context on what MLOps entails. The contextual relevancy score is high because the retrieval context effectively addresses the input question's focus on the differences between MLOps and Data Scientist., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 0.8571428571428571, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.86 because the response effectively addressed the main question, providing a clear distinction between MLOps and Data Scientist. Although there might be some minor tangents or unnecessary details, they do not significantly detract from the overall relevance of the answer., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.5714285714285714, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.57 because the actual output contradicts the retrieval context by defining a Data Scientist's role in terms of creating and validating Machine Learning models, which is not mentioned in the context, and also highlights differences between Data Scientists and MLOps that are unrelated to Einstein winning a Nobel Prize., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Qual a diferen√ßa entre MlOps e Data Scientist?\n",
      "  - actual output: MLOps (Machine Learning Operations) e Data Scientist s√£o duas fun√ß√µes/√°reas distintas no ecossistema de Machine Learning, embora complementares. Veja a diferen√ßa:\n",
      "\n",
      "### **MLOps (Machine Learning Operations):**\n",
      "- **O que √©:** MLOps √© uma pr√°tica de **engenharia** voltada para a **gest√£o e opera√ß√£o de sistemas de Machine Learning** em produ√ß√£o. √â como um \"DevOps\" para ML, focando em:\n",
      "  - **Automatiza√ß√£o** de processos como integra√ß√£o, teste, implanta√ß√£o e monitoramento de modelos.\n",
      "  - **Manuten√ß√£o** cont√≠nua dos modelos, garantindo que eles funcionem bem ao longo do tempo.\n",
      "  - **Infraestrutura** e **deployment** dos modelos em sistemas reais.\n",
      "\n",
      "- **Papel:** Garante que os modelos criados pelos Data Scientists sejam **operacionalizados, escal√°veis e monitorados** em ambiente de produ√ß√£o.\n",
      "\n",
      "### **Data Scientist:**\n",
      "- **O que √©:** Um Data Scientist √© um **cientista de dados** que se concentra em **criar e validar modelos de Machine Learning**. Suas principais tarefas incluem:\n",
      "  - **An√°lise de dados** e **sele√ß√£o de features**.\n",
      "  - **Desenvolvimento** e **treinamento** de modelos preditivos.\n",
      "  - **Evalu√ß√£o** do desempenho dos modelos.\n",
      "\n",
      "- **Papel:** Respons√°vel pela **cria√ß√£o do \"queijo\" (modelo)**, enquanto o MLOps cuida de como ele ser√° \"comido\" (implantado e mantido) em larga escala.\n",
      "\n",
      "### **Diferen√ßa Principal:**\n",
      "- **Data Scientist** cria o modelo, enquanto **MLOps** garante que o modelo funcione bem no dia a dia, como em um sistema de produ√ß√£o. S√£o fun√ß√µes complementares, mas com focos diferentes: um no **desenvolvimento do modelo** e outro na sua **manuten√ß√£o e opera√ß√£o**.\n",
      "  - expected output: A diferen√ßa entre um Data Scientist e um ML Engineer √© que o primeiro se concentra em desenvolver modelos de aprendizado autom√°tico, enquanto o segundo se concentra na engenharia da constru√ß√£o e implanta√ß√£o desses modelos.\n",
      "  - context: None\n",
      "  - retrieval context: ['https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.', \"ML Engineer vs Data Scientist: What' s the differ ence?\\nMLOps Engineer vs Data Scientist: What' s the differ ence?\\nMLOps Engineer vs ML Engineer : What' s the differ ence?\\nFollow me on Twitter: @huwdev ¬© MLOps 2024 - Built by Huw Fulcher11/11/25, 10:05 PM MLOps Now - ML Engineer vs Data Scientist\\nhttps://mlopsnow.com/blog/ml-engineer-vs-data-scientist/ 4/4\", 'ML platform . Similarly, Xin et al. analyze ML pipelines at\\nGoogle to understand typical model configurations and retraining\\npatterns. Polyzotis et al. survey challenges centric to data\\nmanagement for machine learning deployments. Paleyes et al. re-\\nview published reports of individual ML deployments and survey\\ncommon challenges . Our study instead focuses on issues across\\nthe production workflow (i.e., MLOps practices and challenges) as\\nopposed to individual pain-points, identified by interviewing those\\nwho are are most affected by it‚Äîthe ML engineers.\\nData Science and ML-Related Interview Studies. Kandel et\\nal. interview data analysts at enterprises, focusing on broader\\norganizational contexts like we do; however, MLOps workflows\\nand challenges extend beyond data analysis. Other studies build\\non Kandel et al.‚Äôs work, exploring aspects such as collaboration,\\ncode practices, and tools , all centered on gen-\\neral data analysis and data science, as opposed to transitioning', \"Therefore, many businesses are investing in their data science teams and ML capabilities\\nto develop predictive models that can deliver business value to their users.\\nThis document is for data scientists and ML engineers who want to apply DevOps\\n\\xa0(https://cloud.google.com/devops/) principles to ML systems (MLOps). MLOps is an ML\\nengineering culture and practice that aims at unifying ML system development (Dev) and\\nML system operation (Ops). Practicing MLOps means that you advocate for automation\\nand monitoring at all steps of ML system construction, including integration, testing,\\nreleasing, deployment and infrastructure management.\\nData scientists can implement and train an ML model with predictive performance on an\\noffline holdout dataset, given relevant training data for their use case. However, the real\\nchallenge isn't building an ML model, the challenge is building an integrated ML system and\", 'subset of MLOps capability services.\\nML development\\nExperimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for \\ndata preparation and ML modeling. Experimentation starts when the ML use case is well defined, meaning that the \\nfollowing questions have been answered:\\n‚Ä¢ What is the task?\\n‚Ä¢ How can we measure business impact?\\n‚Ä¢ What is the evaluation metric?\\nFigure 5. The ML development process\\n17\\n‚Ä¢ What is the relevant data?\\n‚Ä¢ What are the training and serving requirements?\\nExperimentation aims to arrive at an effective prototype model for the ML use case at hand. In addition to experimen -\\ntation, data scientists need to formalize their ML training procedures. They do this by implementing an end-to-end \\npipeline, so that the procedures can be operationalized and run in production. Figure 5 shows the process of ML \\ndevelopment. \\nDuring experimentation, data scientists typically perform the following steps:']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=776936;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.</span>31s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m52.\u001b[0m31s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7555555555555555, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.76 because irrelevant nodes are correctly ranked lower than relevant nodes (nodes 2 and 4) as they don't provide direct answers to the question about the differences between MLOps and DevOps, while nodes 1 and 3 offer valuable insights into the topic., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5555555555555556, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.56 because the contextual recall score indicates that most sentences in the expected output can be attributed to nodes in the retrieval context, but some sentences remain unconnected, suggesting that there are still areas where the information does not align with the provided context., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.9354838709677419, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.94 because the retrieval context provides relevant statements that directly address the difference between MLOps and DevOps, such as 'MLOps establishes a defined and scalable development process...' and 'DevOps focuses on streamlining the development, testing and deployment of traditional software applications.' These statements demonstrate a clear understanding of both concepts and their distinct differences., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about the difference between MLOps and DevOps, making it highly relevant to the input., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.5833333333333334, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.58 because the actual output contradicts the retrieval context in several ways: it implies that MLOps and DevOps have different focuses within software development, specifically mentioning Machine Learning (ML), whereas the retrieval context only discusses MLOps' focus on managing the ML lifecycle; it also suggests that data management is essential in MLOps, but the retrieval context only mentions data as a necessary input for developing machine learning models without providing specific details about its management., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Qual a diferen√ßa entre MLOps e DevOps?\n",
      "  - actual output: A diferen√ßa entre **MLOps** e **DevOps** est√° em seus focos e aplica√ß√µes dentro do desenvolvimento de software e, especificamente, no contexto do Machine Learning (ML). Ambos compartilham princ√≠pios em comum, como automa√ß√£o, integra√ß√£o cont√≠nua e entrega cont√≠nua, mas se diferenciam em aspectos-chave:\n",
      "\n",
      "### Pontos de Semelhan√ßa:\n",
      "- Ambos buscam **automatizar processos** e melhorar a velocidade e qualidade do desenvolvimento.\n",
      "- Requerem **colabora√ß√£o** entre equipes (desenvolvimento, opera√ß√µes, infraestrutura, etc.).\n",
      "- Utilizam pr√°ticas como **CI/CD (Continuous Integration/Continuous Delivery)**.\n",
      "\n",
      "---\n",
      "\n",
      "### Principais Diferen√ßas:\n",
      "1. **Origem e Contexto**:\n",
      "   - **DevOps** foca no desenvolvimento de **softwares tradicionais**, otimizando ciclos de desenvolvimento, implanta√ß√£o e manuten√ß√£o.\n",
      "   - **MLOps** surgiu a partir dos princ√≠pios do DevOps, mas se especializa no gerenciamento do **ciclo de vida do Machine Learning**, incluindo dados, treinamento de modelos, valida√ß√£o e monitoramento em produ√ß√£o.\n",
      "\n",
      "2. **Tratamento de Dados**:\n",
      "   - **DevOps**: Os dados s√£o **outputs** do sistema (ex: logs, m√©tricas de desempenho).\n",
      "   - **MLOps**: Os dados s√£o **inputs essenciais** para o modelo, exigindo gerenciamento espec√≠fico (limpeza, versionamento, etc.).\n",
      "\n",
      "3. **Monitoramento**:\n",
      "   - **DevOps**: O monitoramento √© voltado para a **sa√∫de do sistema** (ex: uptime, desempenho).\n",
      "   - **MLOps**: Requer **valida√ß√£o cont√≠nua dos modelos** para detectar degrada√ß√£o de desempenho devido a mudan√ßas nos dados ou no ambiente.\n",
      "\n",
      "---\n",
      "\n",
      "### Resumo:\n",
      "MLOps √© como o DevOps, mas com um olhar especial para o Machine Learning. Ele incorpora as boas pr√°ticas do DevOps e adiciona camadas extras para lidar com dados, modelos e valida√ß√£o cont√≠nua. üòä\n",
      "  - expected output: DevOps foca em desenvolvimento e opera√ß√£o de software tradicional, enquanto MLOps lida tamb√©m com dados, treinamento de modelos, versionamento de experimentos e monitoramento de m√©tricas de infer√™ncia e drift.\n",
      "  - context: None\n",
      "  - retrieval context: [\"Scalability and governance\\n\\nMLOps establishes a defined and scalable development process, ensuring consistency, reproducibility and governance throughout the ML lifecycle. Manual deployment and monitoring are slow and require significant human effort, hindering scalability. Without proper centralized monitoring, individual models might experience performance issues that go unnoticed, impacting overall accuracy.\\n\\nWhat's the relationship to DevOps?\\n\\nMLOps and DevOps focus on different aspects of the development process. DevOps focuses on streamlining the development, testing and deployment of traditional software applications. It emphasizes collaboration between development and operations teams to automate processes and improve software delivery speed and quality.\\n\\nMLOps builds upon DevOps principles and applies them to the machine learning lifecycle. It goes beyond deploying code, encompassing data management, model training, monitoring and continuous improvement.\", 'strategic in their decision-making.\\nSimilarities between MLOPs and DevOps\\nBoth MLOps and DevOps share a need for process automation, continuous integration, and continuous delivery .\\nIt also helps to have proper testing of the code base for both MLOps and DevOps.\\nIn addition, there should be adequate collaboration between software developers and those who manage the infrastructure, as well as other stakeholders.\\nDissimilarities between MLOps and DevOps\\nAlthough MLOps is derived from DevOps, there are subtle dif ferences between the two.\\nIn MLOps, data is a necessary input for developing the machine learning model. But in DevOps, data is an output of the program, not an input.\\nIn MLOPs, the model must be validated continuously in production for performance deterioration caused by new data over time. The software system does not deteriorate\\nin DevOps; it is merely monitored for health maintenance purposes.', 'What are the key elements of an effective MLOps strategy?\\n\\nMLOps requires skills, tools and practices to effectively manage the machine learning lifecycle. MLOps teams need a diverse skillset encompassing both technical and soft skills. They must understand the entire data science pipeline, from data preparation and model training to evaluation. Familiarity with software engineering practices like version control, CI/CD pipelines and containerization are also crucial. In addition, knowledge of DevOps principles, infrastructure management and automation tools is essential for the efficient deployment and operation of ML models.', 'systems (MLOps). This document covers concepts to consider when setting up an MLOps\\nenvironment for your data science practices, such as CI, CD, and CT in ML.\\nThe following topics are discussed:11/13/25, 11:39 PM MLOps: Continuous delivery and automation pipelines in machine learning | Cloud Architecture Center | Google Cloud Do‚Ä¶\\nhttps://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning 2/18\\nDevOps versus MLOps\\nSteps for developing ML models\\nMLOps maturity levels\\nMlOps for generative AI\\nDevOps versus MLOps\\nDevOps\\xa0(https://cloud.google.com/devops/) is a popular practice in developing and operating\\nlarge-scale software systems. This practice provides benefits such as shortening the\\ndevelopment cycles, increasing deployment velocity, and dependable releases. To achieve\\nthese benefits, you introduce two concepts in the software system development:\\nContinuous integration (CI)\\xa0(https://en.wikipedia.org/wiki/Continuous_integration)', 'What is MLOps?\\n\\nMLOps, short for machine learning operations, is a set of practices designed to create an assembly line for building and running machine learning models. It helps companies automate tasks and deploy models quickly, ensuring everyone involved (data scientists, engineers, IT) can cooperate smoothly and monitor and improve models for better accuracy and performance.\\n\\nThe term MLops is a combination of machine learning (ML) and DevOps. The term was coined in 2015 in a paper called \"Hidden technical debt in machine learning systems,\" which outlined the challenges inherent in dealing with large volumes of data and how to use DevOps processes to instill better ML practices. Creating an MLOps process incorporates continuous integration and continuous delivery (CI/CD) methodology from DevOps to create an assembly line for each step in creating a machine learning product.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=701448;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56.</span>39s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m56.\u001b[0m39s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7095238095238094, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.71 because irrelevant nodes, such as the fairy tale about Goldilocks (ranked 4), are correctly ranked lower than relevant nodes that provide insights into concept drift and its impact on machine learning models (ranks 1, 2, and 5)., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the contextual recall score indicates that half of the expected output can be attributed to nodes in the retrieval context, while the other half does not have a clear connection to any node., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.6086956521739131, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.61 because the input question about drift in machine learning models doesn't seem to be related to the statements in the retrieval context that discuss model retraining, monitoring, and performance degradation. The relevant statements focus on the importance of continuous monitoring and retraining to prevent accuracy drift and other issues, whereas the input question is more focused on understanding what drift means in a machine learning context., error: None)\n",
      "  - ‚ùå Answer Relevancy (score: 0.7857142857142857, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.79 because, although there are some irrelevant statements made in the actual output that could have brought down the score further, the overall relevance of the output to the input question about 'drift' in machine learning is still relatively high., error: None)\n",
      "  - ‚ùå Faithfulness (score: 0.3076923076923077, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.31 because all contradictions indicate that the actual output does not directly contradict the retrieval context, and since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© drift em modelos de machine learning?\n",
      "  - actual output: Okay, vamos entender o que √© \"drift\" em modelos de machine learning!\n",
      "\n",
      "Em resumo, **drift em machine learning √© uma mudan√ßa no mundo real que afeta os dados ou a rela√ß√£o entre os dados e o objetivo do modelo, fazendo com que o modelo, uma vez bom, comece a dar resultados cada vez piores com o tempo.**\n",
      "\n",
      "Existem principalmente dois tipos de drift:\n",
      "\n",
      "1.  **Data Drift (Drift de Dados):**\n",
      "    *   **O que √©:** Quando as caracter√≠sticas dos dados que o modelo recebe na pr√°tica (dados de produ√ß√£o) mudam de forma diferente daquelas usadas para trein√°-lo.\n",
      "    *   **Exemplo:** Imagine um modelo treinado para detectar fraudes de cart√£o de cr√©dito usando dados hist√≥ricos. Se, depois de algum tempo, o padr√£o de compra dos clientes mudar completamente (por exemplo, muitos passarem a fazer compras online em vez de lojas f√≠sicas), os dados que o modelo recebe mudam. Se o modelo foi treinado apenas com dados de compras f√≠sicas, ele pode come√ßar a mal detectar fraudes nesse novo padr√£o.\n",
      "    *   **Analogia do contexto:** √â como o \"Goldilocks and the Three Bears\" - os dados precisam estar \"just right\". Se ficarem muito diferentes (\"muito grande\") ou praticamente iguais (\"muito pequeno\"), o modelo pode ter problemas. O drift de dados √© quando eles ficam \"muito grandes\".\n",
      "\n",
      "2.  **Concept Drift (Drift de Conceito):**\n",
      "    *   **O que √©:** Quando a rela√ß√£o entre os dados e o objetivo que o modelo deve alcan√ßar muda. O mundo real muda de forma que a defini√ß√£o de \"fraude\" ou \"bom comprador\" muda, independente dos dados.\n",
      "    *   **Exemplo:** Um modelo de classifica√ß√£o de imagens foi treinado para identificar gatos. Funcionava perfeitamente. Mas depois, a defini√ß√£o de \"gato\" na cultura ou at√© mesmo a pr√≥pria biologia dos gatos mudou de forma significativa (um cen√°rio raro, mas imagine!), fazendo com que o modelo, baseado nos dados hist√≥ricos, n√£o mais identifique corretamente os gatos na pr√°tica.\n",
      "    *   **Analogia do contexto:** √â quando as pr√≥prias regras ou a correla√ß√£o que o modelo aprendeu na √©poca mudam, e isso faz com que o modelo \"estale\".\n",
      "\n",
      "**Por que √© um problema?**\n",
      "\n",
      "*   O modelo foi criado com base em um conjunto espec√≠fico de dados e padr√µes do passado.\n",
      "*   Se esses dados ou padr√µes mudam (drift), o modelo pode se tornar \"desatualizado\" ou \"estragado\".\n",
      "*   Isso pode fazer com que o modelo comece a fazer erros mais frequentemente, prever valores ruins, ou at√© mesmo discriminar de forma diferente.\n",
      "\n",
      "**Como lidar?**\n",
      "\n",
      "*   **Monitoramento:** √â crucial monitorar continuamente o desempenho do modelo e verificar se os dados recebidos s√£o similares aos dados de treino (para detectar data drift) ou se o desempenho est√° conforme o esperado (para tentar detectar concept drift).\n",
      "*   **Retreinamento:** Quando se detecta drift, o modelo pode precisar ser reentrenado com os novos dados ou adaptado especificamente para lidar com as mudan√ßas.\n",
      "\n",
      "Ent√£o, o drift √© uma quest√£o importante na manuten√ß√£o de modelos de machine learning em produ√ß√£o, porque o mundo real n√£o para de mudar!\n",
      "  - expected output: Drift √© a mudan√ßa estat√≠stica no comportamento dos dados ou das rela√ß√µes entre vari√°veis ao longo do tempo, resultando em perda de performance do modelo.\n",
      "  - context: None\n",
      "  - retrieval context: [\"On availability of new training data: New data isn't systematically available for the ML\\nsystem and instead is available on an ad hoc basis when new data is collected and\\nmade available in the source databases.11/13/25, 11:39 PM MLOps: Continuous delivery and automation pipelines in machine learning | Cloud Architecture Center | Google Cloud Do‚Ä¶\\nhttps://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning 12/18\\nOn model performance degradation: The model is retrained when there is noticeable\\nperformance degradation.\\nOn significant changes in the data distributions (concept drift\\n\\xa0(https://en.wikipedia.org/wiki/Concept_drift)). It's hard to assess the complete\\nperformance of the online model, but you notice significant changes on the data\\ndistributions of the features that are used to perform the prediction. These changes\\nsuggest that your model has gone stale, and that needs to be retrained on fresh data.\\nChallenges\", \"Monitoring and optimization\\n\\nIn the lifecycle of a deployed machine learning model, continuous vigilance ensures effectiveness and fairness over time. Model monitoring forms the cornerstone of this phase, involving the ongoing scrutiny of the model's performance in the production environment. This step helps identify emerging issues, such as accuracy drift, bias and concerns around fairness, which could compromise the model's utility or ethical standing. Monitoring is about overseeing the model's current performance and anticipating potential problems before they escalate.\", 'asked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:\\n5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\ncharacter, looks for things that are not too big or not too small, things that are ‚Äújust\\nright.‚Äù\\nOperationalizing Machine Learning: An Interview Study\\nThe model gets retrained every day, so we don‚Äôt have the\\nscenario of like: Oh, our models got stale and we need to re-\\ntrain it because it‚Äôs starting to make mistakes because data\\nhas drifted...fortunately we‚Äôve never had to deal with [such\\na] scenario. Sometimes there are bad jobs, but\\nwe can always effectively roll back to a different .\\nHowever, a few engineers mentioned that natural data shift\\ncould cause some hand-curated features and data quality\\nchecks to corrupt (P3, P6, P8). P6 discussed a histogram used', 'object recognition, probabilities or likelihoods as embeddings). P1\\ndescribed a push at their company to rely more on neural networks:\\nA general trend is to try to move more into the neural\\nnetwork, and to combine models wherever possible so\\nthere are fewer bigger models. Then you don‚Äôt have\\nthese intermediate dependencies that cause drift and\\nperformance regressions...you eliminate entire classes of\\nbugs and and issues by consolidating all these different\\npiecemeal stacks.\\n4.5.6 Organizationally Supporting ML Engineers Requires Delib-\\nerate Practices. Our interviewees reported various organizational\\nprocesses for sustaining models as part of their ML infrastructure.\\nP6, P12, P14, P16, P18, and P19 described on-call processes for su-\\npervising production ML models. For each model, at any point in\\ntime, some ML engineer would be on call, or primarily responsible\\nfor it. Any bug or incident observed (e.g., user complaint, pipeline', 'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes. Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 0.00% pass rate\n",
      "Faithfulness: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=336088;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59.</span>57s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m59.\u001b[0m57s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7555555555555555, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.76 because irrelevant nodes, such as those discussing MLOps and data versioning, are correctly ranked lower than the relevant nodes that provide definitions and explanations about feature stores, like the first and third nodes in retrieval contexts., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.6, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.60 because the contextual recall score indicates that the expected output is partially attributed to nodes in retrieval context, suggesting a moderate level of relevance between the two., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.8125, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.81 because the retrieval context provides detailed information about the purpose and functionality of a feature store, which is highly relevant to understanding what a feature store is. For example, statements like 'A feature store needs to provide an API for both high-throughput batch serving and low-latency real-time serving for the feature values...' and 'Feature stores promote consistency and reusability of features across different models and projects.' demonstrate the context's focus on the concept of a feature store, making it highly relevant to the input question., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the answer directly addresses the question about what a feature store is, making it highly relevant and accurate., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.9090909090909091, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.91 because the actual output only partially aligns with the retrieval context, as the claim mentions avoiding duplication of features with different definitions, which is not explicitly mentioned in the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© feature store?\n",
      "  - actual output: Um **feature store** √© um reposit√≥rio centralizado criado para padronizar a defini√ß√£o, armazenamento e acesso a **features** (atributos ou caracter√≠sticas) utilizadas no treinamento e na infer√™ncia de modelos de machine learning.\n",
      "\n",
      "Ele atua como um intermedi√°rio entre os modelos e os dados, permitindo que:\n",
      "\n",
      "*   **Sejam encontradas e reutilizadas** facilmente as *feature sets* dispon√≠veis para diferentes entidades (ex: clientes, produtos).\n",
      "*   **Se evite** a duplica√ß√£o de features com defini√ß√µes diferentes.\n",
      "*   **Sejam servidas** features atualizadas e consistentes.\n",
      "*   **Se elimine a \"training-serving skew\"** (diferen√ßas entre os dados usados para treinamento e para a predi√ß√£o em tempo real), garantindo que as mesmas features sejam usadas em ambos os processos.\n",
      "\n",
      "Al√©m disso, o feature store oferece funcionalidades importantes como:\n",
      "\n",
      "*   **Ingest√£o e servi√ß√£o** de dados com alta capacidade (batch) e baixa lat√™ncia (real-time).\n",
      "*   **Vers√£o de features**, permitindo consultas no ponto em que o dado foi capturado.\n",
      "*   Suporte a diferentes tipos de dados (tabular, imagens, texto).\n",
      "\n",
      "Em resumo, o feature store ajuda a equipe de data science a economizar tempo, evitando a repeti√ß√£o de tarefas de prepara√ß√£o de dados e engenharia de features, e promove a reutiliza√ß√£o e consist√™ncia das features em projetos diferentes.\n",
      "  - expected output: Uma feature store √© um sistema que centraliza cria√ß√£o, versionamento, armazenamento e disponibiliza√ß√£o de features para treinamento e infer√™ncia.\n",
      "  - context: None\n",
      "  - retrieval context: ['high-throughput batch serving and low-latency real-time serving for the feature values, and\\nto support both training and serving workloads.\\nThe feature store helps data scientists do the following:\\nDiscover and reuse available feature sets for their entities, instead of re-creating the\\nsame or similar ones.\\nAvoid having similar features that have different definitions by maintaining features\\nand their related metadata.\\nServe up-to-date feature values from the feature store.\\nAvoid training-serving skew by using the feature store as the data source for\\nexperimentation, continuous training, and online serving. This approach makes sure\\nthat the features used for training are the same ones used during serving:\\nFor experimentation, data scientists can get an offline extract from the feature\\nstore to run their experiments.\\nFor continuous training, the automated ML training pipeline can fetch a batch of\\nthe up-to-date feature values of the dataset that are used for the training task.', 'repository also provides data consistency for training and inference. This helps data scientists and ML researchers \\nsave time on data preparation and feature engineering, which typically take up a significant amount of their time. Key \\nfunctionalities in the data and feature repository include the following:\\n15\\n‚Ä¢ Enable shareability, discoverability, reusability, and versioning of data assets.\\n‚Ä¢ Allow real-time ingestion and low-latency serving for event streaming and online prediction workloads. \\n‚Ä¢ Allow high-throughput batch ingestion and serving for extract, transform, load (ETL) processes and model \\ntraining, and for scoring workloads.\\n‚Ä¢ Enable feature versioning for point-in-time queries.\\n‚Ä¢ Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -', 'compatibility and consistency with the prediction service API.11/13/25, 11:39 PM MLOps: Continuous delivery and automation pipelines in machine learning | Cloud Architecture Center | Google Cloud Do‚Ä¶\\nhttps://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning 10/18\\nIn addition to offline model validation, a newly deployed model undergoes online model\\nvalidation‚Äîin a canary deployment or an A/B testing setup‚Äîbefore it serves prediction for\\nthe online traffic.\\nFeature store\\nAn optional additional component for level 1 ML pipeline automation is a feature store. A\\nfeature store is a centralized repository where you standardize the definition, storage, and\\naccess of features for training and serving. A feature store needs to provide an API for both\\nhigh-throughput batch serving and low-latency real-time serving for the feature values, and\\nto support both training and serving workloads.', 'store to run their experiments.\\nFor continuous training, the automated ML training pipeline can fetch a batch of\\nthe up-to-date feature values of the dataset that are used for the training task.\\nFor online prediction, the prediction service can fetch in a batch of the feature\\nvalues related to the requested entity, such as customer demographic features,\\nproduct features, and current session aggregation features.\\nFor online prediction and feature retrieval, the prediction service identifies the\\nrelevant features for an entity. For example, if the entity is a customer, relevant\\nfeatures might include age, purchase history, and browsing behavior. The service\\nbatches these feature values together and retrieves all the needed features for\\nthe entity at once, rather than individually. This retrieval method helps with\\nefficiency, especially when you need to manage multiple entities.', 'Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis. It involves tracking and managing different versions of the data, allowing for traceability of results and the ability to revert to previous states if necessary. Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\\n\\nThe concept of a feature store is then introduced as a centralized repository for storing and managing features used in model training. Feature stores promote consistency and reusability of features across different models and projects. By having a dedicated system for feature management, teams can ensure they use the most relevant and up-to-date features.\\n\\nModel development']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=876909;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.</span>41s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m48.\u001b[0m41s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.8541666666666666, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.85 because irrelevant nodes, such as those discussing manual deployment or verifying predictive performance targets, are correctly ranked lower than relevant nodes that discuss model development, evaluation, and deployment. The first 'no' verdict at rank 3 is a clear indication of this, as it's not directly related to serving a model in production., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the contextual recall struggles to attribute the expected output sentences to relevant nodes in the retrieval context, with most sentences lacking clear connections to specific nodes., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.7222222222222222, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.72 because the retrieval context provides relevant information about the data science process, including model development, evaluation, and deployment, which are all related to serving a model in production. For example, statements like 'Model deployment: Implementing the ML model into a product, service, or system.' and 'To summarize, implementing ML in a production environment doesn't only mean deploying your model as an API for prediction. Rather, it means deploying an ML pipeline that can automate the retraining and deployment of new models.' provide context about what it means to serve a model in production., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about serving a model in production, making it highly relevant and leaving no room for improvement., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que significa servir um modelo em produ√ß√£o?\n",
      "  - actual output: Ent√£o, \"servir um modelo em produ√ß√£o\" significa coloc√°-lo em pr√°tica de verdade! üöÄ\n",
      "\n",
      "Imagine que voc√™ desenvolveu um modelo de intelig√™ncia artificial que faz previs√µes muito boas em seu ambiente de teste. Quando voc√™ o \"serve\" em produ√ß√£o, ele passa a fazer essas previs√µes dentro do sistema real onde as pessoas usam o produto ou servi√ßo.\n",
      "\n",
      "No contexto do MLOps, isso significa implementar o modelo de forma que ele possa receber dados do mundo real, process√°-los e fornecer respostas ou a√ß√µes no sistema principal onde o trabalho √© feito. Isso pode ser feito atrav√©s de uma API (uma esp√©cie de porta por onde o modelo recebe e envia informa√ß√µes) ou integrando-o diretamente ao sistema.\n",
      "\n",
      "√â como se voc√™ estivesse servindo um prato pronto para os clientes usarem no restaurante (a produ√ß√£o) depois de ter sido testado na cozinha (desenvolvimento)! üçΩÔ∏è\n",
      "\n",
      "√â importante garantir que o modelo funcione bem e seja monitorado continuamente ap√≥s ser servido em produ√ß√£o.\n",
      "  - expected output: Servir um modelo significa disponibiliz√°-lo por meio de um endpoint, job ou pipeline para receber dados e retornar previs√µes de forma escal√°vel e confi√°vel.\n",
      "  - context: None\n",
      "  - retrieval context: ['https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.', '‚Ä¢ Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\n‚Ä¢ Information about training, validation, and testing data splits that were used. \\n‚Ä¢ Model evaluation metrics and the validation procedure that was used.\\nIf there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\\ntion is submitted to the model registry. The model is then ready to be reviewed, approved, and deployed to the target \\n18\\nserving environment. In addition, all the relevant metadata and artifacts \\nthat were produced during model development are tracked in the metadata \\ntracking repository.\\nHowever, in most cases, ML models need to be retrained on a regular basis \\nwhen new data is available or when the code changes. In this case, the \\noutput of the ML development process is not the model to be deployed in \\nproduction. Instead, the output is the implementation of the continuous', 'Model development\\n\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks. The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\n\\nAn essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments. Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.', 'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios. Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment. Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\n\\nModel deployment', \"Verifying that models meet the predictive performance targets before they are\\ndeployed.\\nAutomated deployment to a test environment, for example, a deployment that is\\ntriggered by pushing code to the development branch.\\nSemi-automated deployment to a pre-production environment, for example, a\\ndeployment that is triggered by merging code to the main branch after reviewers\\napprove the changes.\\nManual deployment to a production environment after several successful runs of the\\npipeline on the pre-production environment.\\nTo summarize, implementing ML in a production environment doesn't only mean deploying\\nyour model as an API for prediction. Rather, it means deploying an ML pipeline that can\\nautomate the retraining and deployment of new models. Setting up a CI/CD system lets you\\nautomatically test and deploy new pipeline implementations. This system lets you cope\\nwith rapid changes in your data and business environment. You don't have to immediately\"]\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=584772;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56.</span>01s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m56.\u001b[0m01s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.6565175565175564, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.66 because the relevant nodes (nodes 1, 3, 5, and 7) are ranked higher than irrelevant nodes (nodes 2, 4, 6, and 8-10), with a clear distinction between the two groups. The reasons for the 'yes' verdicts highlight direct connections to the expected output's mentions of 'versionar modelos', 'rastrear artefatos', 'garantir rollback seguro', 'producir resultados', and 'identificar os melhores modelos'. In contrast, the 'no' verdicts are justified by the lack of information about specific topics, such as reproducing experiment results, ensuring rollback security, or testing model predictions., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5217391304347826, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.52 because the contextual recall score indicates that most of the sentences in the expected output are well-matched to nodes in the retrieval context, with some minor discrepancies., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.9090909090909091, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.91 because the retrieval context contains relevant statements about model development, monitoring, and versioning, which are all related to the importance of versioning models. For example, 'Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis.' and 'Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.' These statements demonstrate the relevance of the retrieval context to the input question., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about the importance of versioning models, making all statements highly relevant., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Por que versionar modelos √© importante?\n",
      "  - actual output: O versionamento de modelos √© importante porque:\n",
      "\n",
      "1.  **Garante Rastreabilidade:** Permite saber exatamente quais dados e quais configura√ß√µes foram usados para treinar uma vers√£o espec√≠fica do modelo. Isso √© crucial para entender por que um modelo obteve determinados resultados.\n",
      "\n",
      "2.  **Facilita a Reprodutibilidade:** Se um modelo come√ßa a ter problemas ou se quisermos replicar um resultado espec√≠fico, o versionamento permite voltar exatamente ao ponto inicial (dados, c√≥digo, configura√ß√µes) que gerou aquela vers√£o.\n",
      "\n",
      "3.  **Evita Regress√£o no Desempenho:** Ao manter um registro detalhado de todas as itera√ß√µes, √© poss√≠vel comparar facilmente diferentes vers√µes do modelo e identificar quando (e por qu√™) o desempenho melhorou ou piorou.\n",
      "\n",
      "4.  **Promove Consist√™ncia:** Garante que, ao longo do tempo, diferentes partes do projeto (modelos, dados, c√≥digo) possam ser referenciadas de forma consistente e confi√°vel.\n",
      "\n",
      "5.  **Suporta Melhores Pr√°ticas de Engenharia:** Juntamente com o controle de vers√£o de dados e o uso de sistemas como Git, o versionamento de modelos √© uma parte fundamental das melhores pr√°ticas de ML Ops (Machine Learning Operations), promovendo um fluxo de trabalho mais organizado e colaborativo.\n",
      "\n",
      "Em resumo, o versionamento ajuda a manter o controle do desenvolvimento do modelo, entender seu hist√≥rico de sucesso ou insucesso e garantir que mudan√ßas possam ser feitas de forma confi√°vel e audit√°vel.\n",
      "  - expected output: Versionar modelos permite rastrear artefatos, reproduzir experimentos, auditar previs√µes e garantir rollback seguro.\n",
      "  - context: None\n",
      "  - retrieval context: ['more expensive to analyze improvements to that model in the f uture. The cost increases when\\ncorrection models are cascaded, with a model for problem A‚Ä≤‚Ä≤learned on top of m‚Ä≤\\na, and so on,\\nfor several slightly different test distributions. Once in place, a correction cascade can create an\\nimprovement deadlock, as improving the accuracy of any indi vidual component actually leads to\\nsystem-level detriments. Mitigation strategies are to aug mentmato learn the corrections directly\\nwithin the same model by adding features to distinguish amon g the cases, or to accept the cost of\\ncreating a separate model for A‚Ä≤.\\nUndeclared Consumers. Oftentimes, a prediction from a machine learning model mais made\\nwidely accessible, either at runtime or by writing to Ô¨Åles or logs that may later be consumed by\\nother systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,', 'Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track', 'Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis. It involves tracking and managing different versions of the data, allowing for traceability of results and the ability to revert to previous states if necessary. Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\\n\\nThe concept of a feature store is then introduced as a centralized repository for storing and managing features used in model training. Feature stores promote consistency and reusability of features across different models and projects. By having a dedicated system for feature management, teams can ensure they use the most relevant and up-to-date features.\\n\\nModel development', 'Model development\\n\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks. The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\n\\nAn essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments. Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.', 'Collaboration and governance\\n\\nCreating a streamlined and efficient workflow needs the adoption of several practices and tools, among which version control stands as a cornerstone. Using systems like Git, teams can meticulously track and manage changes in code, data and models. Fostering a collaborative environment makes it easier for team members to work together on projects and ensures that any modifications can be documented and reversed when needed. The ability to roll back to previous versions is invaluable, especially when new changes introduce errors or reduce the effectiveness of the models.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=987200;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57.</span>19s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m57.\u001b[0m19s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.8541666666666666, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.85 because although there are some irrelevant nodes (nodes 3 and 6) that should be ranked lower than the relevant ones, the retrieval contexts effectively distinguish between them by providing clear reasons for their relevance or irrelevance to the input question 'O que √© um pipeline de ML?', error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.9, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.90 because the contextual recall score indicates a strong match between the expected output and the nodes in the retrieval context, with most sentences aligning well with specific nodes, demonstrating a high degree of relevance., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.9166666666666666, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.92 because the retrieval context contains relevant statements about machine learning development phases, experimentation, and pipeline management, which are closely related to the input question about what a pipeline of ML is. For example, the statement 'If the ML system requires continuous training (repeated retraining of the model), the training procedure is operationalized as a training pipeline.' directly addresses the concept of a pipeline in ML., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the answer directly addresses the question about what a machine learning (ML) pipeline is, making it highly relevant and accurate., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© um pipeline de ML?\n",
      "  - actual output: Um **pipeline de ML** √© um fluxo de trabalho automatizado que conecta todas as etapas necess√°rias para construir, treinar e implantar um modelo de machine learning. Ele integra processos como aquisi√ß√£o de dados, pr√©-processamento, engenharia de caracter√≠sticas, treinamento do modelo, avalia√ß√£o e implanta√ß√£o, garantindo que o modelo seja entregue de forma eficiente e repet√≠vel.\n",
      "\n",
      "### Principais etapas de um pipeline de ML:\n",
      "1. **Data Acquisition**: Obten√ß√£o de dados brutos de diversas fontes.\n",
      "2. **Data Preprocessing**: Limpeza, transforma√ß√£o e prepara√ß√£o dos dados.\n",
      "3. **Feature Engineering**: Sele√ß√£o e formata√ß√£o das caracter√≠sticas mais relevantes.\n",
      "4. **Model Training**: Aplica√ß√£o de algoritmos de ML aos dados preparados.\n",
      "5. **Model Evaluation**: Avalia√ß√£o da performance do modelo.\n",
      "6. **Model Deployment**: Implanta√ß√£o do modelo em produ√ß√£o.\n",
      "7. **Monitoring and Maintenance**: Monitoramento cont√≠nuo e atualiza√ß√µes peri√≥dicas.\n",
      "\n",
      "### Pipeline de Treinamento Cont√≠nuo\n",
      "Em alguns casos, o pipeline pode ser configurado para **treinamento cont√≠nuo**, onde o modelo √© retrainido repetidamente quando novos dados ou mudan√ßas no desempenho forem detectados. Isso garante que o modelo permane√ßa preciso e relevante ao longo do tempo.\n",
      "\n",
      "### Objetivo\n",
      "O pipeline de ML automatiza e conecta essas etapas, reduzindo a necessidade de codifica√ß√£o manual (\"glue code\") e evitando a forma√ß√£o de \"jungles de pipelines\" (multiplicidade de scripts desorganizados). Isso facilita a colabora√ß√£o entre pesquisadores e engenheiros e acelera o desenvolvimento de sistemas de ML em produ√ß√£o.\n",
      "\n",
      "Exemplo pr√°tico: Um pipeline de ML pode funcionar como uma linha de produ√ß√£o, onde cada etapa √© executada sequencialmente para transformar dados em um modelo funcional. üîÑ\n",
      "  - expected output: √â um fluxo automatizado que engloba etapas como ingest√£o, processamento, feature engineering, treinamento, avalia√ß√£o e deploy.\n",
      "  - context: None\n",
      "  - retrieval context: ['flow:\\n1. The core activity during this ML development phase is experimentation. As data scientists and ML research -\\ners prototype model architectures and training routines, they create labeled datasets, and they use features \\nand other reusable ML artifacts that are governed through the data and model management process. The \\nFigure 3. The MLOps process\\n9\\nprimary output of this process is a formalized training procedure, which includes data preprocessing, model \\narchitecture, and model training settings. \\n2. If the ML system requires continuous training (repeated retraining of the model), the training procedure is \\noperationalized as a training pipeline. This requires a CI/CD routine to build, test, and deploy the pipeline to \\nthe target execution environment.\\n3. The continuous training pipeline is executed repeatedly based on retraining triggers, and it produces a model \\nas output. The model is retrained as new data becomes available, or if model performance decay is detected.', 'aging these pipelines, detecting errors and recovering fro m failures are all difÔ¨Åcult and costly .\\nTesting such pipelines often requires expensive end-to-en d integration tests. All of this adds to\\ntechnical debt of a system and makes further innovation more costly.\\nPipeline jungles can only be avoided by thinking holistical ly about data collection and feature ex-\\ntraction. The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground\\nup is indeed a major investment of engineering effort, but on e that can dramatically reduce ongoing\\ncosts and speed further innovation.\\nGlue code and pipeline jungles are symptomatic of integrati on issues that may have a root cause in\\noverly separated ‚Äúresearch‚Äù and ‚Äúengineering‚Äù roles. When M L packages are developed in an ivory-\\ntower setting, the result may appear like black boxes to the t eams that employ them in practice. A\\nhybrid research approach where engineers and researchers a re embedded together on the same teams', 'https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.', 'Optimising Data Pipeline and Model P erformance\\nOptimising performance of data pipelines and models is a crucial aspect\\nof ML Ops. T o address performance-related challenges, organisations can:\\nImplement robust data preprocessing techniques to clean and\\ntransform input data efficiently.\\nUse automated feature engineering to select relevant features,\\nreducing the risk of overfitting and enhancing overall model\\nperformance.\\nImplement real-time monitoring and alerting systems for pipelines\\nand models, facilitating prompt identification and resolution of issues.\\nMLOps Ar chitectur e and T ools\\nMLOps Ar chitectur e and Design\\nThe ML Ops architecture comprises several components, including data\\ncollection , data pr ep, model training, validation, and deployment. A well-11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations\\nhttps://mlopsnow.com/blog/what-is-mlops/ 7/11\\ndesigned architecture ensures smooth collaboration between different', 'Takeaway. The MLOps anti-patterns described in this section re-\\nveal that ML engineering, as a field, is changing faster than educa-\\ntional resources can keep up. We see this as opportunities for new\\nresources, such as classroom material (e.g., textbooks, courses) to\\nprescribe the right engineering practices and rigor for the highly\\nexperimental discipline that is production ML, and automated doc-\\numentation assistance for ML pipelines in organizations.\\n5.3 Characterizing the ‚ÄúMLOps Stack‚Äù for Tool\\nBuilders\\nMLOps tool builders may be interested in an organization of the\\ndozens of tools, libraries, and services MLEs use to run ML and\\ndata processing pipelines. Although multiple MLEs reported hav-\\ning to ‚Äúglue‚Äù open-source solutions together and having to build\\n‚Äúhomegrown‚Äù infrastructure as part of their work (P1, P2, P5, P6,\\nP10, P12), an analysis of the various deployments reveals that tools\\nShreya Shankar‚àó, Rolando Garcia‚àó, Joseph M. Hellerstein, Aditya G. Parameswaran\\nRun Layer']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=240394;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58.</span>94s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m58.\u001b[0m94s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because irrelevant nodes (nodes 1 and 3) are ranked lower than relevant nodes (nodes 2 and 4), indicating that contextual precision is moderate, as some 'no' verdicts are correctly placed below the 'yes' verdicts., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5454545454545454, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.55 because the contextual recall successfully captures some of the key concepts related to ML Ops, such as experimentation and artifact tracking, but still lacks a comprehensive understanding of the topic, failing to fully attribute sentences like the one about reproducing results using the same code, data, and parameters., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5121951219512195, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.51 because the retrieval context does not mention ML reproducibility, which is the topic of the input question 'O que √© reprodutibilidade em ML?' The relevant statements in the retrieval context are about data science projects, model training, and deployment, but do not relate to reproducibility., error: None)\n",
      "  - ‚ùå Answer Relevancy (score: 0.5, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the model's response partially addressed the question, but included an irrelevant statement about not finding specific information on reproducibility in ML., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.6, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.60 because the actual output does not align with the information presented in the retrieval context, as it appears to be unrelated to the development lifecycle of data science projects or ML development processes., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© reprodutibilidade em ML?\n",
      "  - actual output: Infelizmente, n√£o encontrei informa√ß√µes espec√≠ficas sobre \"reprodutibilidade em ML\" no contexto fornecido.\n",
      "\n",
      "No entanto, posso te ajudar com outras d√∫vidas relacionadas a MLOps ou o desenvolvimento de ML, como os est√°gios do ciclo de vida, processos de desenvolvimento, m√©tricas de produto ou a import√¢ncia da curadoria de dados. Se precisar de mais alguma informa√ß√£o sobre algum desses t√≥picos, estou √† disposi√ß√£o!\n",
      "  - expected output: Capacidade de reproduzir os mesmos resultados usando o mesmo c√≥digo, dados e par√¢metros.\n",
      "  - context: None\n",
      "  - retrieval context: ['https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.', 'Building an ML-enabled system\\nBuilding an ML-enabled system is a multifaceted undertaking that combines data engineering, ML engineering, and \\napplication engineering tasks, as shown in figure 1.\\nData engineering involves ingesting, integrating, curating, and refining data to facilitate a broad spectrum of opera -\\ntional tasks, data analytics tasks, and ML tasks. Data engineering can be crucial to the success of the analytics and \\nML initiatives. If an organization does not have robust data engineering processes and technologies, it might not be \\nset up for success with downstream business intelligence, advanced analytics, or ML projects.\\nML models are built and deployed in production using curated data that is usually created by the data engineering \\nteam. The models do not operate in silos; they are components of, and support, a large range of application systems, \\nsuch as business intelligence systems, line of business applications, process control systems, and embedded sys -', '‚Ä¢ Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -\\ntory might contain an entity called customer, which includes features like age group, postal code, and gender. On the \\nother hand, a dataset repository might include a customer churn dataset, which includes features from the customer \\nand product entities, as well as purchase- and web-activity event logs.\\nML metadata and artifact tracking\\nVarious types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive \\nstatistics and data schemas, trained models, and evaluation results. ML metadata is the information about these \\nartifacts, including their location, types, properties, and associations to experiments and runs. The ML metadata and', 'subset of MLOps capability services.\\nML development\\nExperimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for \\ndata preparation and ML modeling. Experimentation starts when the ML use case is well defined, meaning that the \\nfollowing questions have been answered:\\n‚Ä¢ What is the task?\\n‚Ä¢ How can we measure business impact?\\n‚Ä¢ What is the evaluation metric?\\nFigure 5. The ML development process\\n17\\n‚Ä¢ What is the relevant data?\\n‚Ä¢ What are the training and serving requirements?\\nExperimentation aims to arrive at an effective prototype model for the ML use case at hand. In addition to experimen -\\ntation, data scientists need to formalize their ML training procedures. They do this by implementing an end-to-end \\npipeline, so that the procedures can be operationalized and run in production. Figure 5 shows the process of ML \\ndevelopment. \\nDuring experimentation, data scientists typically perform the following steps:', 'rather than ML-specific metrics alone like MAP (P5, P7, P15, P16,\\nP11, P17, P18, P19). The need to evaluate product-critical metrics\\nstemmed from close collaboration with other stakeholders, such\\nas product managers and business operators. P11 felt that a key\\nreason many ML projects fail is that they don‚Äôt measure metrics\\nthat will yield the organization value:\\nTying to the business‚Äôs KPIs (key\\nperformance indicators) is really important. But it‚Äôs a\\nprocess‚Äîyou need to figure out what are, and\\nfrankly I think that‚Äôs how people should be doing AI. It\\n like: hey, let‚Äôs do these experiments and\\nget cool numbers and show off these nice precision-recall\\ncurves to our bosses and call it a day. It should be like:\\nhey, let‚Äôs actually show the same business metrics that\\neveryone else is held accountable to to our bosses at the\\nend of the day.\\nSince product-specific metrics are, by definition, different for\\ndifferent ML models, it was important for engineers to treat choos-']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 0.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=542003;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44.</span>22s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m44.\u001b[0m22s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.6787301587301586, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.68 because irrelevant nodes, such as those discussing effort recognition and role distinctions in AI projects, are ranked lower than relevant nodes that directly address CI/CD concepts, like automation of tests and validation, packaging, and deployment of models., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5111111111111111, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.51 because the contextual recall score indicates that there are some relevant sentences in the expected output that can be attributed to nodes in the retrieval context, but not all of them, suggesting a moderate level of alignment between the two., error: None)\n",
      "  - ‚ùå Contextual Relevancy (score: 0.3, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.30 because the retrieval context contains irrelevant information about Google's AI Adoption Framework, digital transformation, pilots, and proofs of concept, which are not directly related to CI/CD applied to ML. The relevant statements in the context only briefly touch on the topic, but do not provide substantial information., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about CI/CD applied to Machine Learning, making all statements highly relevant., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.8, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.80 because the actual output mentions 'implanta√ß√£o de pipelines de treinamento', which is not directly mentioned in the retrieval context, but it's a common practice in ML., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© CI/CD aplicado a ML?\n",
      "  - actual output: No contexto do Machine Learning (ML), o CI/CD (Continuous Integration/Continuous Delivery) √© adaptado para lidrar com as particularidades da √°rea, como dados e modelos. Veja as principais diferen√ßas:\n",
      "\n",
      "### **CI no ML**  \n",
      "Al√©m de testar e validar c√≥digo e componentes, o CI inclui:  \n",
      "- **Valida√ß√£o de dados**: Verifica√ß√£o de qualidade, esquemas e integridade dos dados.  \n",
      "- **Testes de modelos**: Garantir que os modelos atinjam os requisitos de desempenho e generaliza√ß√£o.  \n",
      "\n",
      "### **CD no ML**  \n",
      "Diferente do CD tradicional (que foca na entrega de um pacote/software), no ML a automa√ß√£o √© voltada para:  \n",
      "- **Implanta√ß√£o de pipelines de treinamento**: O sistema automatiza o reentrenamento e a servifica√ß√£o dos modelos.  \n",
      "\n",
      "### **CT (Continuous Training)**  \n",
      "√â uma propriedade √∫nica do ML, que garante que os modelos sejam reentrenados e servidos automaticamente, conforme necess√°rio.  \n",
      "\n",
      "Essas adapta√ß√µes s√£o essenciais para garantir a opera√ß√£o eficiente e eficaz de sistemas de ML em produ√ß√£o.\n",
      "  - expected output: CI/CD em ML automatiza testes, valida√ß√£o, empacotamento e implanta√ß√£o de modelos, garantindo ciclos mais r√°pidos e confi√°veis.\n",
      "  - context: None\n",
      "  - retrieval context: [\"testing, integration testing, and continuous delivery of the software module or the package.\\nHowever, in ML, there are a few notable differences:\\nCI is no longer only about testing and validating code and components, but also\\ntesting and validating data, data schemas, and models.\\nCD is no longer about a single software package or a service, but a system (an ML\\ntraining pipeline) that should automatically deploy another service (model prediction\\nservice).\\nCT is a new property, unique to ML systems, that's concerned with automatically\\nretraining and serving the models.\\nThe following section discusses the typical steps for training and evaluating an ML model\\nto serve as a prediction service.\\nData science steps for ML\\nIn any ML project, after you define the business use case and establish the success criteria,\\nthe process of delivering an ML model to production involves the following steps. These\\nsteps can be completed manually or can be completed by an automatic pipeline.\", 'and automate themes from Google‚Äôs AI Adoption Framework. The decision about whether (or to which degree) to \\nadopt each of these processes and capabilities in your organization depends on your business context. For exam -\\nple, you must determine the business value that the framework creates when compared to the cost of purchasing or \\nbuilding capabilities (for example, the cost in engineering hours).\\nOverview of MLOps lifecycle \\nand core capabilities\\nDespite the growing recognition of AI/ML as a crucial pillar of digital transformation, successful deployments and \\neffective operations are a bottleneck for getting value from AI. Only one in two organizations has moved beyond \\npilots and proofs of concept. Moreover, 72% of a cohort of organizations that began AI pilots before 2019 have not \\nbeen able to deploy even a single application in production.1 Algorithmia‚Äôs survey of the state of enterprise machine', 'achieved by a shift in team culture. Recognizing, prioritiz ing, and rewarding this effort is important\\nfor the long term health of successful ML teams.\\nAcknowledgments\\nThis paper owes much to the important lessons learned day to d ay in a culture that values both\\ninnovative ML research and strong engineering practice. Ma ny colleagues have helped shape our\\nthoughts here, and the beneÔ¨Åt of accumulated folk wisdom can not be overstated. We would like\\nto speciÔ¨Åcally recognize the following: Roberto Bayardo, L uis Cobo, Sharat Chikkerur, Jeff Dean,\\nPhilip Henderson, Arnar Mar Hrafnkelsson, Ankur Jain, Joe K ovac, Jeremy Kubica, H. Brendan\\nMcMahan, Satyaki Mahalanabis, Lan Nie, Michael Pohl, Abdul Salem, Sajid Siddiqi, Ricky Shan,\\nAlan Skelly, Cory Williams, and Andrew Young.\\nA short version of this paper was presented at the SE4ML works hop in 2014 in Montreal, Canada.\\n8', 'rather than ML-specific metrics alone like MAP (P5, P7, P15, P16,\\nP11, P17, P18, P19). The need to evaluate product-critical metrics\\nstemmed from close collaboration with other stakeholders, such\\nas product managers and business operators. P11 felt that a key\\nreason many ML projects fail is that they don‚Äôt measure metrics\\nthat will yield the organization value:\\nTying to the business‚Äôs KPIs (key\\nperformance indicators) is really important. But it‚Äôs a\\nprocess‚Äîyou need to figure out what are, and\\nfrankly I think that‚Äôs how people should be doing AI. It\\n like: hey, let‚Äôs do these experiments and\\nget cool numbers and show off these nice precision-recall\\ncurves to our bosses and call it a day. It should be like:\\nhey, let‚Äôs actually show the same business metrics that\\neveryone else is held accountable to to our bosses at the\\nend of the day.\\nSince product-specific metrics are, by definition, different for\\ndifferent ML models, it was important for engineers to treat choos-', \"team. Each role contributes significantly to the success of AI and ML\\nprojects but has unique skill sets and areas of focus. By understanding and\\nappreciating these distinctions, organizations can more effectively allocate\\nresources, encourage collaboration, and drive innovation in their machine\\nlearning initiatives.\\nIf you‚Äôre looking to become an ML Engineer check out our article about\\nthe 5 skills y ou need t o be successful.\\nWant t o become an ML Ops mast er? Sign up t o the ML Ops Now\\nnewslett er to get w eekly ML Ops insights.\\nUnlock your future in ML Ops with Navigating ML Ops: A\\nBeginner' s Bluepr int.\\nOther ar ticles y ou might be int erested in:\\nYour Ultimat e Machine Learning Engineer R oadmap\\n3 ways t o learn ML Ops quickly\\nML Engineer vs Data Scientist: What' s the differ ence?\\nMLOps Engineer vs Data Scientist: What' s the differ ence?\\nMLOps Engineer vs ML Engineer : What' s the differ ence?\"]\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 0.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=687050;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65.</span>06s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m65.\u001b[0m06s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the relevant nodes (ranked 2nd and 4th) are correctly ranked higher than irrelevant nodes (ranked 1st and 3rd), but not all 'no' verdicts are consistently ranked lower, as some are still relatively close to the top-ranked 'yes' verdict., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5357142857142857, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.54 because the contextual recall score indicates that there are some mismatches between the expected output and the nodes in the retrieval context, but overall, the model is still able to capture most of the relevant information., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.875, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.88 because despite the retrieval context containing information unrelated to monitoring a model in production, it still provides relevant statements such as 'Monit oring identifies model drift over time.' and 'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.', which are directly related to the input question., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about monitoring a model in production, making it highly relevant., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Por que monitorar um modelo em produ√ß√£o?\n",
      "  - actual output: Monitorar um modelo em produ√ß√£o √© essencial por v√°rias raz√µes:\n",
      "\n",
      "1.  **Identificar Drift do Modelo:** O monitoramento detecta mudan√ßas no desempenho ou comportamento do modelo ao longo do tempo (drift). Sem monitoramento, os sistemas operam \"flying blind\" (cegos), sem saber se o modelo ainda est√° funcionando corretamente.\n",
      "\n",
      "2.  **Garantir Performance e Lideran√ßa:** Ele garante que o modelo continue a alcan√ßar a precis√£o e confiabilidade necess√°rias no ambiente de produ√ß√£o. Isso √© crucial para manter a qualidade das previs√µes e a lideran√ßa do sistema.\n",
      "\n",
      "3.  **Trabalhar de Forma Proativa:** Ao monitorar, a equipe de data science pode identificar problemas antes que eles causem falhas. Isso permite um trabalho proativo, corrigindo ou ajustando o modelo antes que os usu√°rios ou o sistema sejam afetados negativamente, em vez de aguardar problemas ocorrerem e ent√£o reagir de forma reativa.\n",
      "\n",
      "4.  **Validar Previs√µes e Dados:** O monitoramento inclui a valida√ß√£o tanto das previs√µes do modelo quanto dos dados de entrada utilizados. Isso garante que tanto o modelo quanto os dados continuem relevantes e adequados para as tarefas em produ√ß√£o.\n",
      "\n",
      "5.  **Prevenir Problemas e Ajustes:** Ao identificar problemas como desempenho declinante ou mudan√ßas necess√°rias no modelo, o monitoramento permite que voc√™ tome a√ß√µes corretivas ou de reentrenamento antes que os problemas se tornem cr√≠ticos ou causem consequ√™ncias indesejadas.\n",
      "\n",
      "Em resumo, o monitoramento transforma a data science de uma atividade de desenvolvimento em uma pr√°tica cont√≠nua de manuten√ß√£o e otimiza√ß√£o de modelos em produ√ß√£o, garantindo sua confiabilidade e efic√°cia no longo prazo.\n",
      "  - expected output: Para detectar quedas de performance, drifts, falhas de pipeline, mudan√ßas de distribui√ß√£o e problemas de lat√™ncia ou disponibilidade.\n",
      "  - context: None\n",
      "  - retrieval context: ['Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track', 'dation system has on click-throughs and on conversation rates. The results of online experimentation should be \\nintegrated with the model registry capability to facilitate the decision about releasing the model to production. Online \\nexperimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models \\nand to promote well-performing ones. Key functionalities in online experimentation include the following:\\n‚Ä¢ Support canary and shadow deployments.\\n‚Ä¢ Support traffic splitting and A/B tests.\\n‚Ä¢ Support multi-armed bandit (MAB) tests.\\nModel monitoring\\nThe model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production \\nto ensure predictive quality and business continuity. This capability informs you if your models are stale and need to \\nbe investigated and updated. Key functionalities in model monitoring include the following:', '‚Ä¢ Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\n‚Ä¢ Information about training, validation, and testing data splits that were used. \\n‚Ä¢ Model evaluation metrics and the validation procedure that was used.\\nIf there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\\ntion is submitted to the model registry. The model is then ready to be reviewed, approved, and deployed to the target \\n18\\nserving environment. In addition, all the relevant metadata and artifacts \\nthat were produced during model development are tracked in the metadata \\ntracking repository.\\nHowever, in most cases, ML models need to be retrained on a regular basis \\nwhen new data is available or when the code changes. In this case, the \\noutput of the ML development process is not the model to be deployed in \\nproduction. Instead, the output is the implementation of the continuous', 'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes. Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.', \"Monitoring and optimization\\n\\nIn the lifecycle of a deployed machine learning model, continuous vigilance ensures effectiveness and fairness over time. Model monitoring forms the cornerstone of this phase, involving the ongoing scrutiny of the model's performance in the production environment. This step helps identify emerging issues, such as accuracy drift, bias and concerns around fairness, which could compromise the model's utility or ethical standing. Monitoring is about overseeing the model's current performance and anticipating potential problems before they escalate.\"]\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=261232;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63.</span>73s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m63.\u001b[0m73s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7555555555555555, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.76 because irrelevant nodes (nodes 2 and 4) are correctly ranked lower than relevant nodes (nodes 1, 3), as they don't provide information about what a model registry is, only describing its capabilities., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.6875, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.69 because the contextual recall score indicates that most of the expected output sentences are supported by relevant information in the retrieval context, with some minor discrepancies., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.6486486486486487, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.65 because the retrieval context provides statements about various aspects of machine learning, such as training, evaluation, deployment, and monitoring, but none of these statements directly relate to what a model registry is or its purpose., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the answer perfectly addresses the question about what a model registry is, with no irrelevant information present., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© um model registry?\n",
      "  - actual output: Um **model registry** √© uma capacidade t√©cnica centralizada que permite gerenciar o ciclo de vida dos modelos de Machine Learning (ML) em um √∫nico reposit√≥rio. Suas principais funcionalidades incluem:\n",
      "\n",
      "1. **Registro, organiza√ß√£o, rastreamento e versionamento** dos modelos treinados e implantados.  \n",
      "2. **Armazenamento de metadados e depend√™ncias de execu√ß√£o** para garantir a reutiliza√ß√£o e a portabilidade dos modelos.  \n",
      "3. **Manuten√ß√£o de documenta√ß√£o e relat√≥rios** (como cards de modelos).  \n",
      "4. **Integra√ß√£o com processos de avalia√ß√£o e implanta√ß√£o**, permitindo o rastreamento de m√©tricas offline e online.  \n",
      "5. **Governan√ßa do processo de lan√ßamento de modelos**: revis√£o, aprova√ß√£o, libera√ß√£o e recesso (rollback) com base em m√©tricas de desempenho e experimenta√ß√£o online.  \n",
      "\n",
      "Essa capacidade √© essencial para garantir a qualidade e o descobrimento dos modelos em produ√ß√£o.\n",
      "  - expected output: Reposit√≥rio central para armazenar vers√µes de modelos, m√©tricas e hist√≥rico.\n",
      "  - context: None\n",
      "  - retrieval context: ['processing, model training, model evaluation, model serving, online experimentation, model monitoring, ML pipeline, \\nand model registry. Finally, two cross-cutting capabilities that enable integration and interaction are an ML metadata \\nand artifact repository and an ML dataset and feature repository.\\nFigure 4. Core MLOps technical capabilities\\n11\\nThe following sections outline the characteristics of each of the MLOps capabilities.\\nExperimentation \\nThe experimentation capability lets your data scientists and ML researchers collaboratively perform exploratory data \\nanalysis, create prototype model architectures, and implement training routines. An ML environment should also let \\nthem write modular, reusable, and testable source code that is version controlled. Key functionalities in experimenta -\\ntion include the following:\\n‚Ä¢ Provide notebook environments that are integrated with version control tools like Git.', '‚Ä¢ Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\n‚Ä¢ Information about training, validation, and testing data splits that were used. \\n‚Ä¢ Model evaluation metrics and the validation procedure that was used.\\nIf there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\\ntion is submitted to the model registry. The model is then ready to be reviewed, approved, and deployed to the target \\n18\\nserving environment. In addition, all the relevant metadata and artifacts \\nthat were produced during model development are tracked in the metadata \\ntracking repository.\\nHowever, in most cases, ML models need to be retrained on a regular basis \\nwhen new data is available or when the code changes. In this case, the \\noutput of the ML development process is not the model to be deployed in \\nproduction. Instead, the output is the implementation of the continuous', 'following:\\n‚Ä¢ Register, organize, track, and version your trained and deployed ML models.\\n‚Ä¢ Store model metadata and runtime dependencies for deployability.\\n‚Ä¢ Maintain model documentation and reporting‚Äîfor example, using model cards .\\n‚Ä¢ Integrate with the model evaluation and deployment capability and track online and offline evaluation metrics \\nfor the models.\\n‚Ä¢ Govern the model launching process: review, approve, release, and roll back. These decisions are based on a \\nnumber of offline performance and fairness metrics and on online experimentation results.\\nDataset and feature repository\\nThe dataset and feature repository capability lets you unify the definition and the storage of the ML data assets. \\nHaving a central repository of fresh, high-quality data assets enables shareability, discoverability, and reusability. The \\nrepository also provides data consistency for training and inference. This helps data scientists and ML researchers', 'dation system has on click-throughs and on conversation rates. The results of online experimentation should be \\nintegrated with the model registry capability to facilitate the decision about releasing the model to production. Online \\nexperimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models \\nand to promote well-performing ones. Key functionalities in online experimentation include the following:\\n‚Ä¢ Support canary and shadow deployments.\\n‚Ä¢ Support traffic splitting and A/B tests.\\n‚Ä¢ Support multi-armed bandit (MAB) tests.\\nModel monitoring\\nThe model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production \\nto ensure predictive quality and business continuity. This capability informs you if your models are stale and need to \\nbe investigated and updated. Key functionalities in model monitoring include the following:', '‚Ä¢ Trigger pipelines on demand, on a schedule, or in response to specified events.\\n‚Ä¢ Enable local interactive execution for debugging during ML development.\\n‚Ä¢ Integrate with the ML metadata tracking capability to capture pipeline execution parameters and to produce \\nartifacts.\\n‚Ä¢ Provide a set of built-in components for common ML tasks and also allow custom components.\\n‚Ä¢ Run on different environments, including local machines and scalable cloud platforms.\\n‚Ä¢ Optionally, provide GUI-based tools for designing and building pipelines.\\nModel registry\\nThe model registry capability lets you govern the lifecycle of the ML models in a central repository. This ensures the \\nquality of the production models and enables model discovery. Key functionalities in the model registry include the \\nfollowing:\\n‚Ä¢ Register, organize, track, and version your trained and deployed ML models.\\n‚Ä¢ Store model metadata and runtime dependencies for deployability.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=233961;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.</span>53s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m48.\u001b[0m53s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.6565175565175564, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.66 because the relevant nodes (nodes 1, 3, 5, and 7) are ranked higher than irrelevant nodes (nodes 2, 4, 6, and 8-10), with a good balance between 'yes' verdicts and 'no' verdicts. The irrelevant nodes mostly provide information about ML Ops phases or techniques that don't directly relate to data validation., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5384615384615384, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.54 because the contextual recall score indicates that most of the expected output can be attributed to the nodes in the retrieval context, with some minor inconsistencies., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.7435897435897436, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.74 because the input question about data validation in MLOps doesn't seem to be directly related to the statements in the retrieval context, which primarily discuss model training, evaluation, deployment, and maintenance. The relevant statements focus on iterative processes, hyperparameter optimisation, cross-validation, and regularisation, whereas data validation is not explicitly mentioned., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about data validation in MLOps, providing a relevant and accurate response., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.8571428571428571, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.86 because the actual output slightly deviates from the retrieval context by mentioning identifying failures in subgroups of users, which was not explicitly stated but can be inferred., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© data validation em MLOps?\n",
      "  - actual output: **Data Validation em MLOps**\n",
      "\n",
      "Data validation em MLOps √© o processo de garantir que os dados utilizados pelos modelos de machine learning sejam precisos, consistentes e adequados para o prop√≥sito do projeto. Esse processo √© essencial para evitar erros e garantir que os modelos funcionem corretamente em produ√ß√£o.\n",
      "\n",
      "### Principais pontos sobre data validation em MLOps:\n",
      "\n",
      "1. **Valida√ß√£o de Dados em Produ√ß√£o**:  \n",
      "   Durante o ciclo de vida do ML, √© importante validar os dados constantemente, especialmente quando h√° mudan√ßas no ambiente de produ√ß√£o. Ferramentas como CI/CD adaptadas para ML podem ser usadas para automatizar testes de valida√ß√£o, como verificar overfitting ou problemas de desempenho em subpopula√ß√µes espec√≠ficas.\n",
      "\n",
      "2. **Desafios**:  \n",
      "   Um dos desafios √© identificar falhas em subgrupos de usu√°rios que podem impactar o desempenho do modelo. Ferramentas e processos de valida√ß√£o din√¢mica s√£o necess√°rios para monitorar esses cen√°rios.\n",
      "\n",
      "3. **Ferramentas e Pr√°ticas**:  \n",
      "   Ferramentas como ease.ml/ci permitem realizar testes unit√°rios para validar dados e garantir que o modelo mantenha sua precis√£o ao longo do tempo.\n",
      "\n",
      "Em resumo, a data validation em MLOps √© uma pr√°tica essencial para garantir que os dados utilizados pelos modelos ML sejam confi√°veis e que o sistema continue funcionando corretamente ap√≥s implementa√ß√µes ou mudan√ßas no ambiente de produ√ß√£o.\n",
      "  - expected output: √â o processo automatizado de verificar integridade, schema, ranges e consist√™ncia de dados antes de alimentar o pipeline de ML.\n",
      "  - context: None\n",
      "  - retrieval context: ['this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps', 'needs to support data scientists. Without their feedback, the system won‚Äôt\\nmeet user needs. R egular feedback sessions with data scientists can\\nstimulate open communication and improve outcomes.\\xa0\\nUse collaboration t ools t o help communication. Collaboration tools assist\\nin enhancing communication and project management, mitigating\\ntechnical debt, and facilitating continuous delivery.\\n2. Aut omating Pr ocesses\\nAutomation is a cornerstone of ML Ops, improving efficiency and accuracy.\\nHere are some best practices for it:11/11/25, 10:04 PM MLOps Now - MLOps Best Practices and Challenges\\nhttps://mlopsnow.com/blog/mlops-best-practices-and-challenges/ 2/7\\nAutomat e data collection, cleaning and pr eparation. One significant\\naspect of automation in ML Ops is the handling of data. Automating\\ncollection, cleaning, and preparation improves efficiency drastically when\\nimproving models. It‚Äôs also an important practice for ensuring data\\nvalidation and managing new data.', 'data collection and processing, experimentation, evaluation and de-\\nployment, and monitoring and response, as shown in Figure 1. Sev-\\neral research papers and companies have proposed tools to accom-\\nplish various tasks in the workflow, such as data pre-processing [ 22,\\n58,60] and experiment tracking . Crankshaw et al. stud-\\nied the problem of model deployment and low-latency prediction\\nserving . With regards to validating changes in production sys-\\ntems, some researchers have studied CI (Continuous Integration) for\\nML and proposed preliminary solutions‚Äîfor example, ease.ml/ci\\nstreamlines data management and proposes unit tests for overfit-\\nting , Garg et al. survey different MLOps tools , and some\\npapers introduce tools to perform validation and monitoring in\\nproduction ML pipelines .\\nMLOps Challenges. Sculley et al. were early proponents that pro-\\nduction ML systems raise special challenges and can be hard tomaintain over time, based on their experience at Google . Since', 'different failure modes in the offline validation phase‚Äîe.g., perfor-\\nmance drops in subpopulations users might care deeply about‚ÄîlikeP11 did, P8 offered a reactive strategy of spawning a new dataset\\nfor each observed live failure: ‚ÄúEvery gets into\\nthe same queue, and 3 of us sit down once a week and go through\\nthe queue...then our collect more data.‚Äù This\\nnew dataset was then used in the offline validation phase in future\\niterations of the production ML lifecycle.\\nWhile processes to dynamically update the validation datasets\\nranged from human-in-the-loop to frequent synthetic data con-\\nstruction (P6), we found that higher-stakes applications of ML (e.g.,\\nautonomous vehicles), created separate teams to manage the dy-\\nnamic evaluation process. P1 said:\\nWe had to move away from only aggregate metrics like\\nMAP towards the ability to curate scenarios of interest,\\nand then validate model performance on them specifi-\\ncally. So, as an example, you can‚Äôt hit pedestrians, right.', 'https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=163852;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53.</span>79s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m53.\u001b[0m79s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because irrelevant nodes, such as those discussing model explainability and logging of prediction serving requests (ranked 3), or model monitoring and abstractions for machine learning systems (ranked 5), are correctly ranked lower than the relevant nodes that discuss batch inference and online inference (ranks 1 and 2)., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5454545454545454, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.55 because the contextual recall score indicates a moderate level of accuracy in attributing sentences from the expected output to corresponding nodes in the retrieval context, with some sentences matching well and others not fitting as closely., error: None)\n",
      "  - ‚ùå Contextual Relevancy (score: 0.2857142857142857, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.29 because the retrieval context contains information about machine learning abstractions, model behavior, and feedback loops that have no relation to the difference between batch inference and online inference., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about the difference between batch inference and online inference, making it highly relevant., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Diferen√ßa entre batch inference e online inference?\n",
      "  - actual output: A diferen√ßa entre **batch inference** e **online inference** est√° principalmente no **modo como as previs√µes s√£o realizadas e os dados s√£o processados**:\n",
      "\n",
      "1. **Batch Inference (Infer√™ncia em Lote)**:\n",
      "   - Consiste em processar grupos grandes de dados de uma vez (em lote).\n",
      "   - √â ideal para atualiza√ß√µes de modelos ou previs√µes em massa, onde n√£o √© necess√°rio tempo real.\n",
      "   - Exemplo: Atualizar um modelo com dados hist√≥ricos ou fazer previs√µes para milh√µes de registros de forma simult√¢nea.\n",
      "\n",
      "2. **Online Inference (Infer√™ncia Online)**:\n",
      "   - Envolve a obten√ß√£o de dados de forma cont√≠nua e process√°-los em tempo real.\n",
      "   - √â usada quando √© necess√°rio um resultado imediato, como em sistemas de recomenda√ß√£o ou detec√ß√£o de fraudes.\n",
      "   - Exemplo: Um sistema de recomenda√ß√£o que sugere produtos em tempo real com base no comportamento do usu√°rio.\n",
      "\n",
      "Em resumo:\n",
      "- **Batch**: Processamento em lote, ideal para atualiza√ß√µes e previs√µes em massa.\n",
      "- **Online**: Processamento em tempo real, ideal para aplica√ß√µes que exigem resposta instant√¢nea.\n",
      "  - expected output: Batch inference processa grandes volumes de dados periodicamente, enquanto online inference responde em tempo real para requisi√ß√µes individuais.\n",
      "  - context: None\n",
      "  - retrieval context: ['store to run their experiments.\\nFor continuous training, the automated ML training pipeline can fetch a batch of\\nthe up-to-date feature values of the dataset that are used for the training task.\\nFor online prediction, the prediction service can fetch in a batch of the feature\\nvalues related to the requested entity, such as customer demographic features,\\nproduct features, and current session aggregation features.\\nFor online prediction and feature retrieval, the prediction service identifies the\\nrelevant features for an entity. For example, if the entity is a customer, relevant\\nfeatures might include age, purchase history, and browsing behavior. The service\\nbatches these feature values together and retrieves all the needed features for\\nthe entity at once, rather than individually. This retrieval method helps with\\nefficiency, especially when you need to manage multiple entities.', '‚Ä¢ Enable composite prediction routines, where multiple models are invoked hierarchically or simultaneously \\nbefore the results are aggregated, in addition to any required pre- or post-processing routines.\\n‚Ä¢ Allow efficient use of ML inference accelerators with autoscaling to match spiky workloads and to balance \\n13\\ncost with latency.\\n‚Ä¢ Support model explainability using techniques like feature attributions for a given model prediction.\\n‚Ä¢ Support logging of prediction serving requests and responses for analysis. \\nOnline experimentation\\nThe online experimentation capability lets you understand how newly trained models perform in production settings \\ncompared to the current models (if any) before you release the new model to production. For example, using a small \\nsubset of the serving population, you use online experimentation to understand the impact that a new recommen -\\ndation system has on click-throughs and on conversation rates. The results of online experimentation should be', 'dation system has on click-throughs and on conversation rates. The results of online experimentation should be \\nintegrated with the model registry capability to facilitate the decision about releasing the model to production. Online \\nexperimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models \\nand to promote well-performing ones. Key functionalities in online experimentation include the following:\\n‚Ä¢ Support canary and shadow deployments.\\n‚Ä¢ Support traffic splitting and A/B tests.\\n‚Ä¢ Support multi-armed bandit (MAB) tests.\\nModel monitoring\\nThe model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production \\nto ensure predictive quality and business continuity. This capability informs you if your models are stale and need to \\nbe investigated and updated. Key functionalities in model monitoring include the following:', 'behavior of a given model before it is released. These feedba ck loops can take different forms, but\\nthey are all more difÔ¨Åcult to detect and address if they occur gradually over time, as may be the case\\nwhen models are updated infrequently.\\nDirect Feedback Loops. A model may directly inÔ¨Çuence the selection of its own future training\\ndata. It is common practice to use standard supervised algor ithms, although the theoretically correct\\nsolution would be to use bandit algorithms. The problem here is that bandit algorithms (such as\\ncontextual bandits ) do not necessarily scale well to the size of action spaces typically required for\\nreal-world problems. It is possible to mitigate these effec ts by using some amount of randomization\\n, or by isolating certain parts of data from being inÔ¨Çuenc ed by a given model.\\nHidden Feedback Loops. Direct feedback loops are costly to analyze, but at least the y pose a', 'stractions to support ML systems. Zheng recently made a comp elling comparison of the state ML\\nabstractions to the state of database technology , maki ng the point that nothing in the machine\\nlearning literature comes close to the success of the relati onal database as a basic abstraction. What\\nis the right interface to describe a stream of data, or a model , or a prediction?\\nFor distributed learning in particular, there remains a lac k of widely accepted abstractions. It could\\nbe argued that the widespread use of Map-Reduce in machine le arning was driven by the void of\\nstrong distributed learning abstractions. Indeed, one of t he few areas of broad agreement in recent\\nyears appears to be that Map-Reduce is a poor abstraction for iterative ML algorithms.\\n5\\nThe parameter-server abstraction seems much more robust, b ut there are multiple competing speci-\\nÔ¨Åcations of this basic idea . The lack of standard abst ractions makes it all too easy to blur the\\nlines between components.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 0.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=206454;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.</span>76s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m50.\u001b[0m76s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.625, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.62 because irrelevant nodes, such as those discussing legacy features and configuration systems, are correctly ranked lower than relevant nodes that mention 'feature drift' or provide specific examples, like Covid-19 and fairy tales., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the contextual recall score indicates that there are some supportive reasons for attributing sentences to nodes in the retrieval context, but also some unsupportive reasons where sentences cannot be attributed, suggesting a moderate level of alignment between the expected output and the retrieval context., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5641025641025641, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.56 because the retrieval context contained general information about configuration and irrelevant statements, but one statement in the context ('It involves tracking and managing different versions of the data...') is actually relevant to the input question 'O que √© feature drift?', error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the answer perfectly addresses the question about feature drift, with no irrelevant information present., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the actual output contradicts the retrieval context by making a claim unrelated to data or machine learning, despite the context not mentioning these topics., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© feature drift?\n",
      "  - actual output: Ol√°! üòä Vamos entender o que √© **feature drift**.\n",
      "\n",
      "No contexto de machine learning, **feature drift** (tamb√©m conhecido como *drift de dados*) ocorre quando as caracter√≠sticas (features) dos dados de entrada mudam ao longo do tempo, afetando a performance do modelo. Isso pode acontecer por v√°rias raz√µes, como:\n",
      "\n",
      "- **Defini√ß√µes inconsistentes**: Por exemplo, uma mesma palavra pode ter significados diferentes em diferentes contextos, dificultando a previs√£o do modelo.\n",
      "- **Varia√ß√£o regional**: Dados de usu√°rios de uma regi√£o espec√≠fica podem ter padr√µes diferentes dos demais.\n",
      "- **Corrup√ß√£o de dados**: O formato dos dados pode mudar, como tabelas sem headers consistentes.\n",
      "- **Mudan√ßas no comportamento dos dados**: Mesmo varia√ß√µes lentas e naturais ao longo do tempo (como mudan√ßas na forma como os dados s√£o coletados) podem impactar o modelo.\n",
      "\n",
      "Al√©m disso, o contexto menciona que, embora alguns possam se preocupar com o chamado *drift natural* (mudan√ßas lentas e esperadas nos dados), muitos projetos resolvem isso retrainando os modelos com frequ√™ncia (como diariamente). No entanto, √© importante monitorar e lidar com o drift para garantir que o modelo continue preciso e eficiente.\n",
      "\n",
      "Espero que tenha entendido melhor! Se tiver mais d√∫vidas, √© s√≥ perguntar. üòä\n",
      "  - expected output: √â a mudan√ßa na distribui√ß√£o estat√≠stica das features usadas pelo modelo ao longo do tempo.\n",
      "  - context: None\n",
      "  - retrieval context: ['Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis. It involves tracking and managing different versions of the data, allowing for traceability of results and the ability to revert to previous states if necessary. Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\\n\\nThe concept of a feature store is then introduced as a centralized repository for storing and managing features used in model training. Feature stores promote consistency and reusability of features across different models and projects. By having a dedicated system for feature management, teams can ensure they use the most relevant and up-to-date features.\\n\\nModel development', 'some products. A year later, the code that stops populating t he database with the old numbers is\\ndeleted. This will not be a good day for the maintainers of the ML system.\\nUnderutilized data dependencies can creep into a model in se veral ways.\\n‚Ä¢Legacy Features. The most common case is that a feature Fis included in a model early in\\nits development. Over time, Fis made redundant by new features but this goes undetected.\\n‚Ä¢Bundled Features. Sometimes, a group of features is evaluated and found to be be neÔ¨Åcial.\\nBecause of deadline pressures or similar effects, all the fe atures in the bundle are added to\\nthe model together, possibly including features that add li ttle or no value.\\n‚Ä¢«´-Features. As machine learning researchers, it is tempting to improve m odel accuracy\\neven when the accuracy gain is very small or when the complexi ty overhead might be high.\\n‚Ä¢Correlated Features. Often two features are strongly correlated, but one is more d irectly', 'Consider the following examples. Feature Awas incorrectly logged from 9/14 to 9/17. Feature Bis\\nnot available on data before 10/7. The code used to compute fe atureChas to change for data before\\nand after 11/1 because of changes to the logging format. Feat ureDis not available in production, so\\na substitute features D‚Ä≤andD‚Ä≤‚Ä≤must be used when querying the model in a live setting. If feat ure\\nZis used, then jobs for training must be given extra memory due to lookup tables or they will train\\ninefÔ¨Åciently. Feature Qprecludes the use of feature Rbecause of latency constraints.\\nAll this messiness makes conÔ¨Åguration hard to modify correc tly, and hard to reason about. How-\\never, mistakes in conÔ¨Åguration can be costly, leading to ser ious loss of time, waste of computing\\nresources, or production issues. This leads us to articulat e the following principles of good conÔ¨Ågu-\\nration systems:\\n‚Ä¢It should be easy to specify a conÔ¨Åguration as a small change f rom a previous conÔ¨Åguration.', 'participants cited Covid as an example, but there are other\\n(better) everyday instances of unnatural data drift. P6 de-\\nscribed a bug where users had inconsistent definitions of the\\nsame word, complicating the deployment of a service to a\\nnew user. P7 mentioned a bug where data from users in a\\ncertain geographic region arrived more sporadically than\\nusual. P10 discussed a bug where the format of raw data was\\noccasionally corrupted: ‚ÄúTables didn‚Äôt always have headers\\nin the same place, even though they were the same tables.‚Äù\\n‚Ä¢Natural data drift: Surprisingly, participants didn‚Äôt seem\\ntoo worried about slower, expected natural data drift over\\ntime‚Äîthey noted that frequent model retrains solved this\\nproblem (P6, P7, P8, P12, P15, P16, P17). As an anecdote, we\\nasked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:', 'asked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:\\n5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\ncharacter, looks for things that are not too big or not too small, things that are ‚Äújust\\nright.‚Äù\\nOperationalizing Machine Learning: An Interview Study\\nThe model gets retrained every day, so we don‚Äôt have the\\nscenario of like: Oh, our models got stale and we need to re-\\ntrain it because it‚Äôs starting to make mistakes because data\\nhas drifted...fortunately we‚Äôve never had to deal with [such\\na] scenario. Sometimes there are bad jobs, but\\nwe can always effectively roll back to a different .\\nHowever, a few engineers mentioned that natural data shift\\ncould cause some hand-curated features and data quality\\nchecks to corrupt (P3, P6, P8). P6 discussed a histogram used']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=883704;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69.</span>89s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m69.\u001b[0m89s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the irrelevant nodes (nodes 1, 3, and 5) are correctly ranked lower than the relevant nodes (nodes 2 and 4), but there's still room for improvement as some relevant nodes (node 6) are not ranked higher than others., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the contextual recall score indicates that there are some supportive reasons for attributing sentences in the expected output to nodes in the retrieval context, but also some unsupportive reasons where sentences cannot be attributed to any parts of the retrieval context., error: None)\n",
      "  - ‚ùå Contextual Relevancy (score: 0.43243243243243246, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.43 because the retrieval context contains irrelevant information about natural data drift, legacy features, and bugs, which are not related to concept drift, as stated in reasons such as 'don‚Äôt have natural data drift problems' and ', error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the answer perfectly addresses the question about concept drift, with no irrelevant statements present., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.8, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.80 because although there are no direct contradictions with the retrieval context, the actual output mentions potential issues with poor predictions and system failures due to concept drift, which is indirectly addressed in the context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© concept drift?\n",
      "  - actual output: O **concept drift** (tamb√©m conhecido como **drift de conceito**) √© um fen√¥meno em sistemas de machine learning onde as **mudan√ßas significativas nos dados** ou na **distribui√ß√£o das caracter√≠sticas** (features) que o modelo utiliza para fazer previs√µes indicam que o modelo est√° ficando obsoleto ou menos preciso.\n",
      "\n",
      "### Explica√ß√£o simples:\n",
      "Imagine que voc√™ treina um modelo para prever o tempo do dia com base em dados hist√≥ricos. Se, por algum motivo, os padr√µes de dados mudarem (por exemplo, devido a mudan√ßas na esta√ß√£o ou em fatores ambientais), o modelo antigo pode come√ßar a dar respostas menos precisas. O concept drift √© quando essas mudan√ßas s√£o detectadas, indicando que √© necess√°rio **reatrinar o modelo** com novos dados para mant√™-lo preciso e eficiente.\n",
      "\n",
      "### Por que √© importante?\n",
      "No contexto de sistemas de machine learning, o concept drift √© um dos principais desafios para garantir que os modelos continuem funcionando bem ao longo do tempo. Se n√£o for detectado e corrigido, pode levar a **p√©ssimas previs√µes** e at√© mesmo a falhas no sistema.\n",
      "\n",
      "### Exemplo no contexto:\n",
      "No texto mencionado, h√° uma refer√™ncia a esse problema quando se fala sobre a necessidade de **reatrinar os modelos** quando h√° mudan√ßas significativas nos dados. Isso √© essencial para evitar que o modelo fique \"desatualizado\" e perca sua capacidade de previs√£o.\n",
      "\n",
      "Se precisar de mais detalhes ou exemplos, √© s√≥ perguntar! üòä\n",
      "  - expected output: √â quando a rela√ß√£o entre as features e a vari√°vel alvo muda, tornando o modelo menos eficaz.\n",
      "  - context: None\n",
      "  - retrieval context: ['some products. A year later, the code that stops populating t he database with the old numbers is\\ndeleted. This will not be a good day for the maintainers of the ML system.\\nUnderutilized data dependencies can creep into a model in se veral ways.\\n‚Ä¢Legacy Features. The most common case is that a feature Fis included in a model early in\\nits development. Over time, Fis made redundant by new features but this goes undetected.\\n‚Ä¢Bundled Features. Sometimes, a group of features is evaluated and found to be be neÔ¨Åcial.\\nBecause of deadline pressures or similar effects, all the fe atures in the bundle are added to\\nthe model together, possibly including features that add li ttle or no value.\\n‚Ä¢«´-Features. As machine learning researchers, it is tempting to improve m odel accuracy\\neven when the accuracy gain is very small or when the complexi ty overhead might be high.\\n‚Ä¢Correlated Features. Often two features are strongly correlated, but one is more d irectly', 'object recognition, probabilities or likelihoods as embeddings). P1\\ndescribed a push at their company to rely more on neural networks:\\nA general trend is to try to move more into the neural\\nnetwork, and to combine models wherever possible so\\nthere are fewer bigger models. Then you don‚Äôt have\\nthese intermediate dependencies that cause drift and\\nperformance regressions...you eliminate entire classes of\\nbugs and and issues by consolidating all these different\\npiecemeal stacks.\\n4.5.6 Organizationally Supporting ML Engineers Requires Delib-\\nerate Practices. Our interviewees reported various organizational\\nprocesses for sustaining models as part of their ML infrastructure.\\nP6, P12, P14, P16, P18, and P19 described on-call processes for su-\\npervising production ML models. For each model, at any point in\\ntime, some ML engineer would be on call, or primarily responsible\\nfor it. Any bug or incident observed (e.g., user complaint, pipeline', 'participants cited Covid as an example, but there are other\\n(better) everyday instances of unnatural data drift. P6 de-\\nscribed a bug where users had inconsistent definitions of the\\nsame word, complicating the deployment of a service to a\\nnew user. P7 mentioned a bug where data from users in a\\ncertain geographic region arrived more sporadically than\\nusual. P10 discussed a bug where the format of raw data was\\noccasionally corrupted: ‚ÄúTables didn‚Äôt always have headers\\nin the same place, even though they were the same tables.‚Äù\\n‚Ä¢Natural data drift: Surprisingly, participants didn‚Äôt seem\\ntoo worried about slower, expected natural data drift over\\ntime‚Äîthey noted that frequent model retrains solved this\\nproblem (P6, P7, P8, P12, P15, P16, P17). As an anecdote, we\\nasked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:', 'asked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:\\n5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\ncharacter, looks for things that are not too big or not too small, things that are ‚Äújust\\nright.‚Äù\\nOperationalizing Machine Learning: An Interview Study\\nThe model gets retrained every day, so we don‚Äôt have the\\nscenario of like: Oh, our models got stale and we need to re-\\ntrain it because it‚Äôs starting to make mistakes because data\\nhas drifted...fortunately we‚Äôve never had to deal with [such\\na] scenario. Sometimes there are bad jobs, but\\nwe can always effectively roll back to a different .\\nHowever, a few engineers mentioned that natural data shift\\ncould cause some hand-curated features and data quality\\nchecks to corrupt (P3, P6, P8). P6 discussed a histogram used', \"On availability of new training data: New data isn't systematically available for the ML\\nsystem and instead is available on an ad hoc basis when new data is collected and\\nmade available in the source databases.11/13/25, 11:39 PM MLOps: Continuous delivery and automation pipelines in machine learning | Cloud Architecture Center | Google Cloud Do‚Ä¶\\nhttps://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning 12/18\\nOn model performance degradation: The model is retrained when there is noticeable\\nperformance degradation.\\nOn significant changes in the data distributions (concept drift\\n\\xa0(https://en.wikipedia.org/wiki/Concept_drift)). It's hard to assess the complete\\nperformance of the online model, but you notice significant changes on the data\\ndistributions of the features that are used to perform the prediction. These changes\\nsuggest that your model has gone stale, and that needs to be retrained on fresh data.\\nChallenges\"]\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 0.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=742787;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76.</span>39s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m76.\u001b[0m39s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7095238095238094, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.71 because irrelevant nodes, such as those discussing data quality issues (node 3) and minimizing bias in ML models (node 7), should be ranked lower than relevant nodes like those mentioning MLflow's orchestration capabilities (node 1) and experimentation importance (nodes 2 and 5)., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5333333333333333, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.53 because the contextual recall score indicates that most of the expected output sentences can be attributed to specific nodes in the retrieval context, but there are some sentences that do not have a clear connection to any node., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5806451612903226, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.58 because the retrieval context contains statements about machine learning operations (MLOps) and architecture, which are unrelated to the input question 'Para que serve o MLflow?' that asks about the purpose of MLflow. The relevant statements in the retrieval context focus on topics like data collection, orchestration, and model management, whereas MLflow is a tool for tracking and managing machine learning experiments., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the answer directly addresses the question about the purpose of MLflow, making it highly relevant., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Para que serve o MLflow?\n",
      "  - actual output: O **MLflow** √© uma ferramenta de c√≥digo aberto projetada para acelerar o desenvolvimento, implanta√ß√£o e monitoramento de pipelines de machine learning. Suas principais funcionalidades incluem:\n",
      "\n",
      "1. **Gest√£o de Experimentos**:  \n",
      "   Ajuda a organizar e comparar diferentes experimentos de modelos, controlando par√¢metros, m√©tricas e vers√µes de dados.\n",
      "\n",
      "2. **Modelagem e Implanta√ß√£o**:  \n",
      "   Facilita a empacotamento e implanta√ß√£o de modelos em produ√ß√£o, integrando-se com infraestruturas como Docker e Kubernetes.\n",
      "\n",
      "3. **Documenta√ß√£o Autom√°tica**:  \n",
      "   Gera documenta√ß√£o para pipelines de ML, tornando mais f√°cil a colabora√ß√£o entre equipes.\n",
      "\n",
      "4. **Integra√ß√£o com Ferramentas de Orquestra√ß√£o**:  \n",
      "   Combina-se com outros frameworks como **Kubeflow** e **Apache Airflow** para gerenciar workflows complexos.\n",
      "\n",
      "Em resumo, o MLflow √© essencial para tornar o processo de ML mais eficiente, estruturado e repet√≠vel, especialmente em ambientes de produ√ß√£o.\n",
      "  - expected output: Gerenciar experimentos, registrar m√©tricas e armazenar modelos.\n",
      "  - context: None\n",
      "  - retrieval context: ['https://mlopsnow.com/blog/what-is-mlops/ 7/11\\ndesigned architecture ensures smooth collaboration between different\\nteams and streamlines the entire machine learning lifecycle.\\nData Collection and Data Pr ep play a critical role in the ML Ops\\narchitecture. T o build accurate and reliable machine learning models, it is\\nessential to have high-quality data from various sources. Data engineers\\nand data scientists work together, leveraging tools like Google Cloud\\nStorage and BigQuer y to collect, store, and preprocess the data, making it\\nsuitable for model training.\\nOrchestration and T esting T ools\\nOrchestration in ML Ops involves managing and automating the end-to-\\nend machine learning pipeline. It plays a significant role in simplifying\\ncomplex workflows and facilitating collaboration. Some widely-used\\norchestration tools include Kubeflow , Apache Air flow, and MLflow .\\nIn addition to orchestration tools, ML Ops practices also focus on testing', 'workflow must be capable of scaling seamlessly. The infrastructure\\nsupporting ML applications ought to be elastic, adjusting resources based\\non the workload automatically.\\nOptimisation plays a crucial role in maximising the performance and\\nefficiency of machine learning models. T echniques such as hyperparameter\\ntuning, model pruning, and implementation of efficient algorithms enable\\nthe creation of highly performant models without sacrificing accuracy.\\nAdditionally, monitoring tools can provide insights into model11/11/25, 9:50 PM MLOps Now - The MLOps Platform: Revolutionising Machine Learning Efficiency\\nhttps://mlopsnow.com/blog/mlops-platforms-revolutionising-machine-learning/ 5/10\\nperformance, allowing for proactive optimisation to maintain satisfactory\\nresults.\\nLeveraging Open Sour ce Tools and\\nFramew orks\\nMLflow and Kubeflow\\nLeveraging open source tools and frameworks such as MLflow and\\nKubeflow can play a significant role in accelerating the development and', '8\\n‚Ä¢ Prediction serving is about serving the model that is deployed in production for inference.\\n‚Ä¢ Continuous monitoring is about monitoring the effectiveness and efficiency of a deployed model.\\n‚Ä¢ Data and model management is a central, cross-cutting function for governing ML artifacts to support audit -\\nability, traceability, and compliance. Data and model management can also promote shareability, reusability, \\nand discoverability of ML assets.\\nMLOps: An end-to-end workflow\\nFigure 3 shows a simplified but canonical flow for how the MLOps processes interact with each other, focusing on \\nhigh-level flow of control and on key inputs and outputs.\\nThis is not a waterfall workflow that has to sequentially pass through all the processes. The processes can be \\nskipped, or the flow can repeat a given phase or a subsequence of the processes. The diagram shows the following \\nflow:\\n1. The core activity during this ML development phase is experimentation. As data scientists and ML research -', 'on Kandel et al.‚Äôs work, exploring aspects such as collaboration,\\ncode practices, and tools , all centered on gen-\\neral data analysis and data science, as opposed to transitioning\\nworkflows in ML to production. Many ML-related interview stud-\\nies focus on a single tool, task, or challenge in the workflow‚Äîfor\\nexample, AutoML , data iteration , model training ,\\nminimizing bias in ML models , and building infras-\\ntructure for ML pipelines . Sambasivan et al. study data\\nquality issues during machine learning, as opposed to challenges\\nin MLOps. Other ML-related interview studies focus on specific\\napplications of ML, such as medicine , customer service ,\\nand interview processing . Some interview studies report on\\nsoftware engineering practices for ML development; however, they\\nfocus only on a few applications and primarily on engineering, not\\noperational, challenges . Our interview study aims to be both\\nbroad and focused: we consider many applications and companies,', 'Takeaway. The MLOps anti-patterns described in this section re-\\nveal that ML engineering, as a field, is changing faster than educa-\\ntional resources can keep up. We see this as opportunities for new\\nresources, such as classroom material (e.g., textbooks, courses) to\\nprescribe the right engineering practices and rigor for the highly\\nexperimental discipline that is production ML, and automated doc-\\numentation assistance for ML pipelines in organizations.\\n5.3 Characterizing the ‚ÄúMLOps Stack‚Äù for Tool\\nBuilders\\nMLOps tool builders may be interested in an organization of the\\ndozens of tools, libraries, and services MLEs use to run ML and\\ndata processing pipelines. Although multiple MLEs reported hav-\\ning to ‚Äúglue‚Äù open-source solutions together and having to build\\n‚Äúhomegrown‚Äù infrastructure as part of their work (P1, P2, P5, P6,\\nP10, P12), an analysis of the various deployments reveals that tools\\nShreya Shankar‚àó, Rolando Garcia‚àó, Joseph M. Hellerstein, Aditya G. Parameswaran\\nRun Layer']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=338105;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49.</span>3s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m49.\u001b[0m3s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7555555555555555, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.76 because irrelevant nodes like 'MLOps level 0' and 'seamless integration of ML into existing processes' are correctly ranked lower than relevant nodes that discuss canary deployment strategies, such as the first node mentioning 'canary deployment', and the third node highlighting the importance of monitoring model performance., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the contextual recall score indicates that half of the expected output can be attributed to nodes in the retrieval context, while the other half appears to be original statements that do not match any part of the provided context., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the retrieval context provides information about deployment, monitoring, and management of machine learning models, which is not directly relevant to understanding what a canary deployment in ML is. The relevant statements focus on the process of deploying models, whereas the input question seeks a definition or explanation of canary deployment., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the answer directly addresses the question about what a canary deployment is in Machine Learning, making it highly relevant and accurate., error: None)\n",
      "  - ‚ùå Faithfulness (score: 0.25, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.25 because the actual output does not directly address the concept of canary deployment discussed in the claims, nor does it explicitly mention the specific approach to deploying machine learning models mentioned in the claims., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© canary deployment em ML?\n",
      "  - actual output: Canary deployment em ML √© uma abordagem de lan√ßamento gradual de um novo modelo ou vers√£o de um modelo de machine learning. Nessa abordagem, uma pequena parte da carga de trabalho (por exemplo, 5% ou 10%) √© redirecionada para a nova vers√£o do modelo. Isso permite que voc√™ teste a nova vers√£o em um ambiente de produ√ß√£o controlado antes de promov√™-la para todo o tr√°fego.\n",
      "\n",
      "Essa t√©cnica √© frequentemente usada em conjunto com A/B testing ou experimentos online para comparar o desempenho da nova vers√£o com a vers√£o anterior e garantir que ela n√£o introduza problemas antes de ser expandida para todos os usu√°rios.\n",
      "  - expected output: √â uma estrat√©gia onde uma nova vers√£o do modelo √© implantada para uma pequena parcela do tr√°fego para validar performance antes do rollout completo.\n",
      "  - context: None\n",
      "  - retrieval context: [\"Deployment refers to the prediction service: The process is concerned only with\\ndeploying the trained model as a prediction service (for example, a microservice with\\na REST API), rather than deploying the entire ML system.\\nLack of active performance monitoring: The process doesn't track or log the model\\npredictions and actions, which are required in order to detect model performance\\ndegradation and other model behavioral drifts.\\nThe engineering team might have their own complex setup for API configuration, testing,\\nand deployment, including security, regression, and load and canary testing. In addition,\\nproduction deployment of a new version of an ML model usually goes through A/B testing\\nor online experiments before the model is promoted to serve all the prediction request\\ntraffic.\\nChallenges\\nMLOps level 0 is common in many businesses that are beginning to apply ML to their use\\ncases. This manual, data-scientist-driven process might be sufficient when models are\", 'seamless and efficient integration of ML into existing processes.\\nMLOps is more than just the technical side of ML lifecycle management; it\\nalso incorporates best practices and methods used in software\\ndevelopment and DevOps. Bridging the gap between data scientists, ML\\nengineers, and DevOps, ML Ops enables a more coordinated approach to\\nML projects. T eams can more easily track, reproduce, and iterate on\\nmodels, ensuring stability and performance in production environments.\\nBy adopting an ML Ops approach, organisations not only position\\nthemselves for better scalability and faster deployment of ML models, but\\nalso optimise resources and reduce risk. As a result, businesses can\\nleverage data more effectively, enhancing their decision-making processes\\nand achieving better outcomes in the competitive marketplace.\\nFundamentals o f ML Ops\\nMachine Learning Operations\\nMLOps stands for Machine L earning Oper ations . It is an IT practice that', 'from their investments in ML. Capgemini Research noted that the top three challenges faced by organizations in \\nachieving deployments at scale are lack of mid- to senior-level talent, lack of change-management processes, and \\nlack of strong governance models for achieving scale.\\nThe common theme in these and other studies is that ML systems cannot be built in an ad hoc manner, isolated from \\nother IT initiatives like DataOps and DevOps. They also cannot be built without adopting and applying sound software \\nengineering practices, while taking into account the factors that make operationalizing ML different from operational -\\nizing other types of software.\\nOrganizations need an automated and streamlined ML process. This process does not just help the organization \\nsuccessfully deploy ML models in production. It also helps manage risk when organizations scale the number of', 'ly, they can be created by combining vendor tools that each are best suited to particular tasks, developed as custom \\nservices, or created as a combination of these approaches.\\nIn most cases, the processes are deployed in stages rather than all at once in a single deployment. An organization‚Äôs \\nplan for adopting these processes and capabilities should align with business priorities and with the organization‚Äôs \\ntechnical and skills maturity. For example, many organizations start by focusing on the processes for ML develop -\\nment, model deployment, and prediction serving. For these organizations, continuous training and continuous moni -\\ntoring might not be necessary if they are piloting a relatively small number of ML systems.\\nFigure 4 shows the core set of technical capabilities that are generally required for MLOps. They are abstracted as \\nfunctional components that can have many-to-many mappings to specific products and technologies.\\n10', 'tween tasks, the key artifacts created by the tasks, and the relationship of tasks to other upstream and downstream \\nprocesses. In this section, you learn about concrete details of tasks like running a continuous training pipeline, de -\\nploying a model, and monitoring predictive performance of the model.\\n16\\nMLOps processes take place on an integrated ML platform that has the required development and operations capa -\\nbilities (described later). Infrastructure engineers can provision this type of platform in different environments (like \\ndevelopment, test, staging, and production) using configuration management and infrastructure-as-code (IaC) tools \\nlike Terraform . Each environment is configured with its own set of required compute resources, data access, and \\nsubset of MLOps capability services.\\nML development\\nExperimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=107420;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.</span>88s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m52.\u001b[0m88s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7555555555555555, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.76 because irrelevant nodes, such as those discussing serving trained models (ranked 3) or not providing information about training models (ranked 2), are correctly ranked lower than the relevant nodes that explain what a pipeline is and how it relates to machine learning (ranked 1 and 4)., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the expected output seems to be related to the development and experimentation stage (1st node) and model continuous delivery stage (5th node), but lacks clear connections to other nodes in the retrieval context, resulting in a moderate recall score., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.6333333333333333, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.63 because the retrieval context contains statements about pipeline jungles, difficulties in making changes, and the importance of thinking holistically about data collection and feature extraction, which are all relevant to the concept of a pipeline de-retraining model, but not directly related to the definition of what it is., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about what a pipeline of retraining a model is, making it highly relevant to the input., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© pipeline de retreinamento de modelo?\n",
      "  - actual output: Ol√°! O **pipeline de retreinamento de modelo** √© um conjunto de etapas automatizadas que permite atualizar e reentrenar um modelo de machine learning existente com novos dados ou diferentes par√¢metros, garantindo que ele continue eficiente ao longo do tempo.\n",
      "\n",
      "No contexto apresentado, isso faz parte da **Model Continuous Delivery**, onde o modelo √© servido como um servi√ßo de predi√ß√£o e, posteriormente, gerenciado pelo **Model Registry** para governan√ßa e descoberta. O retreinamento √© uma forma de atualizar o modelo sem precisar recriar todo o pipeline do zero, evitando assim a complexidade da \"jungle de pipelines\" mencionada.\n",
      "\n",
      "Em resumo, o pipeline de retreinamento √© uma parte essencial para manter os modelos atualizados e eficientes, especialmente quando h√° novos dados ou mudan√ßas no ambiente de produ√ß√£o. üòä\n",
      "\n",
      "Se voc√™ tiver mais d√∫vidas sobre algum passo espec√≠fico, √© s√≥ perguntar!\n",
      "  - expected output: Pipeline autom√°tico que treina novamente o modelo com novos dados ou drift.\n",
      "  - context: None\n",
      "  - retrieval context: ['1. Development and experimentation: You iteratively try out new ML algorithms and new\\nmodeling where the experiment steps are orchestrated. The output of this stage is the\\nsource code of the ML pipeline steps that are then pushed to a source repository.\\n2. Pipeline continuous integration: You build source code and run various tests. The\\noutputs of this stage are pipeline components (packages, executables, and artifacts)\\nto be deployed in a later stage.\\n3. Pipeline continuous delivery: You deploy the artifacts produced by the CI stage to the\\ntarget environment. The output of this stage is a deployed pipeline with the new\\nimplementation of the model.\\n4. Automated triggering: The pipeline is automatically executed in production based on a\\nschedule or in response to a trigger. The output of this stage is a trained model that is\\npushed to the model registry.\\n5. Model continuous delivery: You serve the trained model as a prediction service for the', 'P10 mentioned that there were parts of a pipeline that no one\\ntouched because it was already running in production, and the\\nprincipal developer who knew most about it had left the company.\\nP16 said that ‚Äúmost of the, like, actual models were trained before\\n time.‚Äù P14 described a ‚Äúpipeline jungle‚Äù that was difficult to\\nmaintain:\\nYou end up with this pipeline jungle where everything‚Äôs\\nsuper entangled, and it‚Äôs really hard to make changes,\\nbecause just to make one single change, you have to\\nhold so much context in your brain. You‚Äôre trying to\\nthink about like, okay this one change is gonna affect\\nthis system which affects this system, [which\\ncreates]...the pipeline got to the point where it was very\\ndifficult to make even simple changes.\\nWhile writing down institutional knowledge can be straightfor-\\nward to do once, P6 discussed that in the ML setting, they learn\\nfaster than they can document; moreover, people don‚Äôt want to\\nread so many different versions of documentation:', 'aging these pipelines, detecting errors and recovering fro m failures are all difÔ¨Åcult and costly .\\nTesting such pipelines often requires expensive end-to-en d integration tests. All of this adds to\\ntechnical debt of a system and makes further innovation more costly.\\nPipeline jungles can only be avoided by thinking holistical ly about data collection and feature ex-\\ntraction. The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground\\nup is indeed a major investment of engineering effort, but on e that can dramatically reduce ongoing\\ncosts and speed further innovation.\\nGlue code and pipeline jungles are symptomatic of integrati on issues that may have a root cause in\\noverly separated ‚Äúresearch‚Äù and ‚Äúengineering‚Äù roles. When M L packages are developed in an ivory-\\ntower setting, the result may appear like black boxes to the t eams that employ them in practice. A\\nhybrid research approach where engineers and researchers a re embedded together on the same teams', '‚Ä¢ Trigger pipelines on demand, on a schedule, or in response to specified events.\\n‚Ä¢ Enable local interactive execution for debugging during ML development.\\n‚Ä¢ Integrate with the ML metadata tracking capability to capture pipeline execution parameters and to produce \\nartifacts.\\n‚Ä¢ Provide a set of built-in components for common ML tasks and also allow custom components.\\n‚Ä¢ Run on different environments, including local machines and scalable cloud platforms.\\n‚Ä¢ Optionally, provide GUI-based tools for designing and building pipelines.\\nModel registry\\nThe model registry capability lets you govern the lifecycle of the ML models in a central repository. This ensures the \\nquality of the production models and enables model discovery. Key functionalities in the model registry include the \\nfollowing:\\n‚Ä¢ Register, organize, track, and version your trained and deployed ML models.\\n‚Ä¢ Store model metadata and runtime dependencies for deployability.', 'this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=689294;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46.</span>82s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m46.\u001b[0m82s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.8541666666666666, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.85 because the relevant nodes (nodes 1, 2, 4 and 6) that discuss 'MLOps', versioning, pipelines, monitoring, managing data science projects, and maintaining ML models are ranked higher than irrelevant nodes (nodes 3 and 5) that don't provide information about logging, data validation, reproducible processes, continuous training pipelines, or data acquisition/preprocessing., error: None)\n",
      "  - ‚ùå Contextual Recall (score: 0.4444444444444444, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.44 because the contextual recall score indicates that some sentences in the expected output can be attributed to specific nodes in the retrieval context, while others do not have a clear connection to these nodes., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.7586206896551724, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.76 because, despite the lack of direct mentions of 'Data Science' or 'Machine Learning', the retrieval context provides relevant information about MLOps characteristics, such as its lifecycle stages (data acquisition, preprocessing, feature engineering, model training, evaluation, deployment, and monitoring) and concerns like model fairness and adversarial attacks. These statements demonstrate a clear understanding of MLOps principles, making the retrieval context partially relevant to the input., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about what characterizes a good environment for MLOps, making all statements highly relevant to the input., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que caracteriza um bom ambiente de MLOps?\n",
      "  - actual output: Um bom ambiente de MLOps √© caracterizado por:\n",
      "\n",
      "üîπ **Integra√ß√£o completa do ciclo de vida**: Agrupa todas as fases do desenvolvimento e implanta√ß√£o de modelos ML em uma √∫nica plataforma, facilitando a colabora√ß√£o entre equipes e a automa√ß√£o de processos.\n",
      "\n",
      "üîπ **Automatiza√ß√£o de processos**: Utiliza ferramentas como Terraform e pipelines automatizados para gerenciar desde a infraestrutura at√© o monitoramento, reduzindo erros e aumentando a efici√™ncia.\n",
      "\n",
      "üîπ **Reprodutibilidade de experimentos**: Garante que cada teste seja replic√°vel, com controle de vers√µes de dados, modelos e c√≥digo, evitando problemas de irreprodutibilidade.\n",
      "\n",
      "üîπ **Monitoramento em tempo real**: Detecta mudan√ßas no desempenho do modelo e coleta m√©tricas de neg√≥cios para garantir a sustentabilidade do sistema.\n",
      "\n",
      "üîπ **Operacionaliza√ß√£o em diferentes ambientes**: Suporta desde desenvolvimento at√© produ√ß√£o, com configura√ß√µes espec√≠ficas para cada fase do projeto.\n",
      "\n",
      "Essas caracter√≠sticas permitem que equipes de dados e opera√ß√µes trabalhem de forma alinhada, otimizando o desenvolvimento e implanta√ß√£o de modelos ML. Quer explorar algum desses pontos em mais detalhes? üòä\n",
      "  - expected output: Um ambiente com versionamento consistente, pipelines automatizados, monitoramento cont√≠nuo, logging estruturado, valida√ß√£o de dados e processos reprodut√≠veis.\n",
      "  - context: None\n",
      "  - retrieval context: ['tween tasks, the key artifacts created by the tasks, and the relationship of tasks to other upstream and downstream \\nprocesses. In this section, you learn about concrete details of tasks like running a continuous training pipeline, de -\\nploying a model, and monitoring predictive performance of the model.\\n16\\nMLOps processes take place on an integrated ML platform that has the required development and operations capa -\\nbilities (described later). Infrastructure engineers can provision this type of platform in different environments (like \\ndevelopment, test, staging, and production) using configuration management and infrastructure-as-code (IaC) tools \\nlike Terraform . Each environment is configured with its own set of required compute resources, data access, and \\nsubset of MLOps capability services.\\nML development\\nExperimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for', '6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.\\nMLOps helps manage the lifecycle of data science projects and ensures\\nthat best practices are followed at each stage. This allows data scientists to\\nfocus on their core tasks while IT professionals handle operational aspects,\\ncreating a more effective and efficient workflow.\\nFor a more in-depth comparison of Data Science and ML Ops check out\\nour other blog post.\\nMLOps and DevOps\\nThe DevOps P aradigm\\nDevOps is a combination of development (Dev) and operations (Ops)\\npractices, aimed at unifying software development and IT operations. The\\nprimary goal of DevOps is to reduce the time taken from code changes to\\noperational deployment. This is achieved by embracing automation for11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations', 'https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.', '‚Ä¢ Handling concerns about model fairness and adversarial attacks.\\nMLOps is a methodology for ML engineering that unifies ML system development (the ML element) with ML system \\noperations (the Ops element). It advocates formalizing and (when beneficial) automating critical steps of ML system \\nconstruction. MLOps provides a set of standardized processes and technology capabilities for building, deploying, \\nand operationalizing ML systems rapidly and reliably.\\nMLOps supports ML development and deployment in the way that DevOps and DataOps support application engi -\\nneering and data engineering (analytics). The difference is that when you deploy a web service, you care about resil -\\nience, queries per second, load balancing, and so on. When you deploy an ML model, you also need to worry about \\nchanges in the data, changes in the model, users trying to game the system, and so on. This is what MLOps is about.', 'such as business intelligence systems, line of business applications, process control systems, and embedded sys -\\ntems. Integrating an ML model into an application is a critical task that involves making sure first that the deployed \\nmodel is used effectively by the applications, and then monitoring model performance. In addition to this, you should \\nalso collect and monitor relevant business KPIs (for example, click-through rate, revenue uplift, and user experience). \\nThis information helps you understand the impact of the ML model on the business and adapt accordingly.\\nFigure 1. The relationship of data engineering, ML engineering, and app engineering\\n7\\nThe MLOps lifecycle\\nThe MLOps lifecycle encompasses seven integrated and iterative processes, as shown in figure 2.\\nThe processes can consist of the following:\\n‚Ä¢ ML development concerns experimenting and developing a robust and reproducible model training proce -']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 0.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=256065;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.</span>24s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m43.\u001b[0m24s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.9166666666666666, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.92 because irrelevant nodes (nodes 3) are correctly ranked lower than relevant nodes, with the first two nodes providing direct explanations of what a machine learning model is, while node 3 focuses on the process of developing and managing models without defining what they are., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.6, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.60 because the model's ability to partially match the expected output with relevant concepts in the retrieval context, such as machine learning model lifecycle and model development, indicates a decent recall but still leaves some room for improvement., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.8787878787878788, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.88 because the retrieval context provides relevant information about machine learning models, such as their development lifecycle, training, evaluation, deployment, and ongoing management, which are all closely related to the input question 'What is a machine learning model?' The statements in the retrieval context that are actually relevant to the input include phrases like 'Model development', 'Model training', 'Model evaluation', and 'Model deployment', which provide insight into the process of creating and managing machine learning models. These connections demonstrate the contextual relevance between the input question and the retrieval context, resulting in a score of 0.88., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about what a machine learning model is, making all statements highly relevant., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© um modelo de machine learning?\n",
      "  - actual output: Um modelo de machine learning √© um algoritmo ou conjunto de regras criado a partir de dados, que tem a capacidade de aprender padr√µes e fazer previs√µes ou tomar decis√µes. Durante o processo de desenvolvimento, ele √© treinado com dados para reconhecer esses padr√µes e, posteriormente, pode ser aplicado a novos dados para gerar resultados confi√°veis.\n",
      "\n",
      "Ele √© constru√≠do a partir de t√©cnicas como aprendizado de m√°quina, onde o modelo √© ajustado iterativamente durante o treinamento, utilizando m√©todos como otimiza√ß√£o de hiperpar√¢metros, valida√ß√£o cruzada e regulariza√ß√£o para melhorar sua precis√£o e efic√°cia.\n",
      "  - expected output: Um modelo de machine learning √© um algoritmo treinado com dados para fazer previs√µes ou classifica√ß√µes.\n",
      "  - context: None\n",
      "  - retrieval context: ['\"MLOps emphasizes the comprehensive management of the machine learning model lifecycle, covering everything from deploying models into production environments to monitoring their performance. When necessary, models are updated to ensure that they continue to function effectively. The goal is to streamline the deployment process, guarantee models operate at their peak efficiency and foster an environment of continuous improvement. By focusing on these areas, MLOps ensures that machine learning models meet the immediate needs of their applications and adapt over time to maintain relevance and effectiveness in changing conditions.\\n\\nWhile ML focuses on the technical creation of models, MLOps focuses on the practical implementation and ongoing management of those models in a real-world setting.', 'Model development\\n\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks. The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\n\\nAn essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments. Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.', 'more expensive to analyze improvements to that model in the f uture. The cost increases when\\ncorrection models are cascaded, with a model for problem A‚Ä≤‚Ä≤learned on top of m‚Ä≤\\na, and so on,\\nfor several slightly different test distributions. Once in place, a correction cascade can create an\\nimprovement deadlock, as improving the accuracy of any indi vidual component actually leads to\\nsystem-level detriments. Mitigation strategies are to aug mentmato learn the corrections directly\\nwithin the same model by adding features to distinguish amon g the cases, or to accept the cost of\\ncreating a separate model for A‚Ä≤.\\nUndeclared Consumers. Oftentimes, a prediction from a machine learning model mais made\\nwidely accessible, either at runtime or by writing to Ô¨Åles or logs that may later be consumed by\\nother systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,', 'this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps', 'https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=355902;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.</span>01s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m43.\u001b[0m01s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the relevant nodes (2nd and 4th) are ranked higher than irrelevant nodes (1st and 3rd), which do not provide definitions for 'treinamento de modelo'. The first node's reason is that it doesn't mention the term at all, while the third node talks about machine learning models but doesn't define 'treinamento de modelo'., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5614035087719298, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.56 because the contextual recall score indicates that the expected output sentence about Treinamento being the process of adjusting model parameters using labeled or unlabeled data can be attributed to the node(s) in retrieval context, but not all sentences can be attributed., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.9354838709677419, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.94 because the retrieval context discusses machine learning models, their development, evaluation, and monitoring, which are all relevant topics to training a machine learning model. For example, statements like 'Model development is a core phase in the data science process...' and 'Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment.' demonstrate a clear connection to the input question about training a machine learning model., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about what training a model means, making all statements highly relevant., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© treinamento de modelo?\n",
      "  - actual output: O treinamento de modelo √© o primeiro passo do desenvolvimento de modelos, onde os dados preparados s√£o utilizados para ensinar o modelo a fazer previs√µes ou decis√µes. Durante esse processo, o modelo aprende padr√µes e rela√ß√µes nos dados para se tornar eficaz em suas tarefas.\n",
      "  - expected output: Treinamento √© o processo de ajustar os par√¢metros do modelo usando dados rotulados ou n√£o rotulados.\n",
      "  - context: None\n",
      "  - retrieval context: ['more expensive to analyze improvements to that model in the f uture. The cost increases when\\ncorrection models are cascaded, with a model for problem A‚Ä≤‚Ä≤learned on top of m‚Ä≤\\na, and so on,\\nfor several slightly different test distributions. Once in place, a correction cascade can create an\\nimprovement deadlock, as improving the accuracy of any indi vidual component actually leads to\\nsystem-level detriments. Mitigation strategies are to aug mentmato learn the corrections directly\\nwithin the same model by adding features to distinguish amon g the cases, or to accept the cost of\\ncreating a separate model for A‚Ä≤.\\nUndeclared Consumers. Oftentimes, a prediction from a machine learning model mais made\\nwidely accessible, either at runtime or by writing to Ô¨Åles or logs that may later be consumed by\\nother systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,', 'Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track', 'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes. Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.', 'Model development\\n\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks. The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\n\\nAn essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments. Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.', 'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios. Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment. Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\n\\nModel deployment']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=984239;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58.</span>98s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m58.\u001b[0m98s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7095238095238094, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.71 because irrelevant nodes (nodes 2 and 5) were correctly ranked lower than relevant nodes (nodes 1, 3, 4, and 6), with reasons such as 'overfitting' and 'prototype smells or configuration debt' not being directly related to the topic of separating training and testing., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the original expected output sentence 'A separa√ß√£o evita overfitting e garante avalia√ß√£o imparcial da performance.' cannot be attributed to any node in the retrieval context, making it an unsupportive reason., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.7368421052631579, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.74 because the retrieval context discusses software module or package, continuous delivery, and testing, whereas the input asks about separating training and test, which are distinct concepts., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the response directly addresses the input question, providing a clear and relevant answer., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Por que separar treino e teste?\n",
      "  - actual output: Ol√°! Separar os dados de treino e teste √© uma pr√°tica essencial em machine learning por uma raz√£o muito importante: **evitar que o modelo memorize os dados, em vez de aprender padr√µes √∫teis para fazer previs√µes novas.**\n",
      "\n",
      "Imagine que voc√™ est√° estudando para um teste. Se voc√™ s√≥ estudar as quest√µes que vai ter na prova, voc√™ vai aprender muito bem aquelas quest√µes espec√≠ficas, mas n√£o vai saber responder outras quest√µes diferentes. Da mesma forma, se voc√™ usar todos os dados para treinar o modelo, ele pode simplesmente decorar as caracter√≠sticas desses dados.\n",
      "\n",
      "Quando voc√™ separa uma parte dos dados para teste, voc√™ est√° criando uma \"prova\" que o modelo nunca viu antes. Assim, voc√™ pode verificar se o modelo realmente aprendeu algo √∫til e se ele √© capaz de generalizar, ou seja, fazer bom desempenho em novos dados que n√£o foram usados durante o treino.\n",
      "\n",
      "Isso √© crucial porque, em sistemas de produ√ß√£o, o modelo precisa lidar com novas entradas que nunca foram vistas antes. Se ele tivesse sido validado apenas com os dados de treino, voc√™ n√£o saberia se ele funcionaria bem no mundo real.\n",
      "\n",
      "Portanto, separar treino e teste √© como garantir que o seu modelo seja um bom aluno antes de lev√°-lo para a sala de aula (ou para a produ√ß√£o)!\n",
      "  - expected output: A separa√ß√£o evita overfitting e garante avalia√ß√£o imparcial da performance.\n",
      "  - context: None\n",
      "  - retrieval context: [', in which thresholds are learned via simple evaluation on heldout validation data.\\nMonitoring and Testing. Unit testing of individual components and end-to-end tests of running\\nsystems are valuable, but in the face of a changing world such tests are not sufÔ¨Åcient to provide\\nevidence that a system is working as intended. Comprehensiv e live monitoring of system behavior\\nin real time combined with automated response is critical fo r long-term system reliability.\\nThe key question is: what to monitor? Testable invariants ar e not always obvious given that many\\nML systems are intended to adapt over time. We offer the follo wing starting points.\\n‚Ä¢Prediction Bias. In a system that is working as intended, it should usually be t he case that\\nthe distribution of predicted labels is equal to the distrib ution of observed labels. This is\\nby no means a comprehensive test, as it can be met by a null mode l that simply predicts', 'a given language, especially when that language has a conven ient library or syntax for the\\ntask at hand. However, using multiple languages often incre ases the cost of effective testing\\nand can increase the difÔ¨Åculty of transferring ownership to other individuals.\\n‚Ä¢Prototype Smell. It is convenient to test new ideas in small scale via prototyp es. How-\\never, regularly relying on a prototyping environment may be an indicator that the full-scale\\nsystem is brittle, difÔ¨Åcult to change, or could beneÔ¨Åt from i mproved abstractions and inter-\\nfaces. Maintaining a prototyping environment carries its o wn cost, and there is a signiÔ¨Åcant\\ndanger that time pressures may encourage a prototyping syst em to be used as a production\\nsolution. Additionally, results found at small scale rarel y reÔ¨Çect the reality at full scale.\\n6 ConÔ¨Åguration Debt\\nAnother potentially surprising area where debt can accumul ate is in the conÔ¨Åguration of machine', 'Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track', \"testing, integration testing, and continuous delivery of the software module or the package.\\nHowever, in ML, there are a few notable differences:\\nCI is no longer only about testing and validating code and components, but also\\ntesting and validating data, data schemas, and models.\\nCD is no longer about a single software package or a service, but a system (an ML\\ntraining pipeline) that should automatically deploy another service (model prediction\\nservice).\\nCT is a new property, unique to ML systems, that's concerned with automatically\\nretraining and serving the models.\\nThe following section discusses the typical steps for training and evaluating an ML model\\nto serve as a prediction service.\\nData science steps for ML\\nIn any ML project, after you define the business use case and establish the success criteria,\\nthe process of delivering an ML model to production involves the following steps. These\\nsteps can be completed manually or can be completed by an automatic pipeline.\", \"Continuous integration\\nIn this setup, the pipeline and its components are built, tested, and packaged when new\\ncode is committed or pushed to the source code repository. Besides building packages,\\ncontainer images, and executables, the CI process can include the following tests:\\nUnit testing your feature engineering logic.\\nUnit testing the different methods implemented in your model. For example, you have\\na function that accepts a categorical data column and you encode the function as a\\none-hot\\xa0(https://en.wikipedia.org/wiki/One-hot) feature.\\nTesting that your model training converges (that is, the loss of your model goes down\\nby iterations and overfits\\xa0(https://en.wikipedia.org/wiki/Overfitting) a few sample records).\\nTesting that your model training doesn't produce NaN\\xa0(https://en.wikipedia.org/wiki/NaN)\\nvalues due to dividing by zero or manipulating small or large values.\\nTesting that each component in the pipeline produces the expected artifacts.\"]\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=615683;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85.</span>99s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m85.\u001b[0m99s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Contextual Precision (score: 0.2, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.20 because irrelevant nodes (nodes 1-4) are correctly ranked lower than the relevant node (node 5), with a clear distinction between topics such as software engineering, ML system smells, data management, and ML Ops, which do not relate to inference, allowing the correct context mentioning 'infer√™ncia √© o uso de um modelo treinado para gerar previs√µes em novos dados' to rank higher., error: None)\n",
      "  - ‚ùå Contextual Recall (score: 0.48936170212765956, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.49 because the original expected output does not match well with the nodes in the retrieval context, indicating a moderate level of contextual recall., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.6136363636363636, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.61 because the retrieval context contains statements about software engineering and design smells, which are unrelated to the input question 'O que √© infer√™ncia?' that asks for a definition of inference. The relevant statements in the retrieval context are mostly about machine learning and data management, whereas the input question is focused on a general concept., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 0.8, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.80 because although the answer is mostly relevant, it contains one irrelevant statement about the lack of information on inference concept in the context provided., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the actual output appears to be discussing the development lifecycle of data science projects and ML Ops, whereas the context does not mention inference, indicating a mismatch between the two., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© infer√™ncia?\n",
      "  - actual output: Infelizmente, n√£o h√° informa√ß√µes no contexto fornecido sobre o conceito de infer√™ncia. \n",
      "\n",
      "Posso ajudar com outros t√≥picos relacionados ao contexto, como MLOps, ciclo de vida de projetos de ci√™ncia de dados ou padr√µes de design em sistemas de aprendizado de m√°quina?\n",
      "  - expected output: Infer√™ncia √© o uso de um modelo treinado para gerar previs√µes em novos dados.\n",
      "  - context: None\n",
      "  - retrieval context: ['Ô¨Åcations of this basic idea . The lack of standard abst ractions makes it all too easy to blur the\\nlines between components.\\nCommon Smells. In software engineering, a design smell may indicate an underlying problem in\\na component or system . We identify a few ML system smells, not hard-and-fast rules, but as\\nsubjective indicators.\\n‚Ä¢Plain-Old-Data Type Smell. The rich information used and produced by ML systems is\\nall to often encoded with plain data types like raw Ô¨Çoats and i ntegers. In a robust system,\\na model parameter should know if it is a log-odds multiplier o r a decision threshold, and a\\nprediction should know various pieces of information about the model that produced it and\\nhow it should be consumed.\\n‚Ä¢Multiple-Language Smell. It is often tempting to write a particular piece of a system in\\na given language, especially when that language has a conven ient library or syntax for the\\ntask at hand. However, using multiple languages often incre ases the cost of effective testing', 'a given language, especially when that language has a conven ient library or syntax for the\\ntask at hand. However, using multiple languages often incre ases the cost of effective testing\\nand can increase the difÔ¨Åculty of transferring ownership to other individuals.\\n‚Ä¢Prototype Smell. It is convenient to test new ideas in small scale via prototyp es. How-\\never, regularly relying on a prototyping environment may be an indicator that the full-scale\\nsystem is brittle, difÔ¨Åcult to change, or could beneÔ¨Åt from i mproved abstractions and inter-\\nfaces. Maintaining a prototyping environment carries its o wn cost, and there is a signiÔ¨Åcant\\ndanger that time pressures may encourage a prototyping syst em to be used as a production\\nsolution. Additionally, results found at small scale rarel y reÔ¨Çect the reality at full scale.\\n6 ConÔ¨Åguration Debt\\nAnother potentially surprising area where debt can accumul ate is in the conÔ¨Åguration of machine', 'privilege of working with real data in development. This privilege comes\\nwith a lot of responsibility.\\nUse encr yption t o protect data in transit and at r est. Encrypting data\\nensures that the data sets used in the training pipeline are secure, even if\\nleaked.\\xa0\\nAccess contr ols to contr ol access t o data and models. An extra layer on\\ntop of encryption is access controls to ensure only relevant users can view\\ndata and models.\\xa0\\nRegular audits t o confirm compliance with r egulations such as GDPR and\\nHIPAA. When working with customer data it is imperative that it is done in\\nan ethical manner. Liase with your Cyber Security and Ethics teams to\\nensure you meet these requirements.\\xa0\\nChallenges\\nWhile it is crucial to follow best practices in ML Ops, it is also important to\\nunderstand and prepare for the challenges\\n1. Data Management\\nOne of the most common challenges in ML Ops is data management.\\xa0\\nMLOps Engineers aren‚Äôt directly responsible for ingestion and processing', 'https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.', 'ful and reasonable for why things should be good, but\\nthe most defining characteristic of [my most productive\\ncolleague] is that he has the highest pace of experi-\\nmentation out of anyone. He‚Äôs always running exper-\\niments, always trying everything. I think this is rel-\\natively common‚Äîpeople just try everything and then\\nbackfit some nice-sounding explanation for why it works.\\nWe wondered, why was it even necessary to have an expla-\\nnation for why something worked? Why not simply accept that,\\nunlike in software, we may not have elegant, principled reasons for\\nsuccessful ML experiments? P2 hypothesized that such retrofitted\\nexplanations could guide future experiment ideas over a longer hori-\\nzon. Alternatively, P7 mentioned that their customers sometimes\\ndemanded explanations for certain predictions:\\nDo I know why? No idea. I have to convince people that,\\nokay, we try our best. We try to correlations.\\nWe try to similarities. Why is it different? I\\nhave to make conjectures.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 0.00% pass rate\n",
      "Contextual Recall: 0.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=843839;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65.</span>08s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m65.\u001b[0m08s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.6787301587301586, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score of 0.68 is because, although irrelevant nodes (nodes 2, 4, 6, and 8) are ranked lower than relevant nodes (nodes 1, 3, 5, and 9), there's still room for improvement in ranking the most relevant nodes higher up the list., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5217391304347826, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.52 because the contextual recall score indicates that the expected output is partially supported by the nodes in the retrieval context, with some sentences having clear connections to specific nodes and others not being directly attributed to any node., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5813953488372093, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.58 because the retrieval context contains statements about machine learning operations, model training, and data management, which are not relevant to the input question 'O que √© um dataset?' that asks for a definition of what a dataset is., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about what a dataset is, making all statements highly relevant., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.7777777777777778, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.78 because the actual output does not align with the context due to the lack of mention of specific terms like 'Gerenciamento em n√≠vel de dados' or 'Gerenciamento em n√≠vel de recursos', and also lacks information about specific datasets, such as *customer churn*, which are mentioned in the claim., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© um dataset?\n",
      "  - actual output: Um **dataset** √© um conjunto estruturado de dados usado em projetos de Machine Learning (ML) e an√°lise de dados. Ele cont√©m informa√ß√µes organizadas de forma a permitir que modelos de IA aprendam padr√µes e fa√ßam previs√µes.\n",
      "\n",
      "No contexto da MLOps, um dataset pode ser gerenciado de duas formas principais:\n",
      "\n",
      "1. **Gerenciamento em n√≠vel de dados**:  \n",
      "   Trata-se de um conjunto completo de dados, como um arquivo de dados tabulares ou multim√≠dia (imagens, texto, etc.). Exemplo: um dataset de *customer churn* (rotatividade de clientes) que inclui dados de clientes, produtos e eventos de atividade web.\n",
      "\n",
      "2. **Gerenciamento em n√≠vel de recursos**:  \n",
      "   Divide-se em partes menores, como caracter√≠sticas (features) ou entidades. Exemplo: um reposit√≥rio de dados pode conter uma entidade chamada *customer* com caracter√≠sticas como idade, c√≥digo postal e g√™nero.\n",
      "\n",
      "Al√©m disso, os datasets s√£o essenciais para garantir a qualidade, consist√™ncia e seguran√ßa dos dados, conforme mencionado no contexto. Eles s√£o armazenados em reposit√≥rios centralizados para facilitar seu uso em diferentes est√°gios do pipeline de ML.\n",
      "  - expected output: Dataset √© uma cole√ß√£o estruturada de dados utilizada para treinamento, valida√ß√£o ou teste.\n",
      "  - context: None\n",
      "  - retrieval context: ['privilege of working with real data in development. This privilege comes\\nwith a lot of responsibility.\\nUse encr yption t o protect data in transit and at r est. Encrypting data\\nensures that the data sets used in the training pipeline are secure, even if\\nleaked.\\xa0\\nAccess contr ols to contr ol access t o data and models. An extra layer on\\ntop of encryption is access controls to ensure only relevant users can view\\ndata and models.\\xa0\\nRegular audits t o confirm compliance with r egulations such as GDPR and\\nHIPAA. When working with customer data it is imperative that it is done in\\nan ethical manner. Liase with your Cyber Security and Ethics teams to\\nensure you meet these requirements.\\xa0\\nChallenges\\nWhile it is crucial to follow best practices in ML Ops, it is also important to\\nunderstand and prepare for the challenges\\n1. Data Management\\nOne of the most common challenges in ML Ops is data management.\\xa0\\nMLOps Engineers aren‚Äôt directly responsible for ingestion and processing', 'this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps', 'following:\\n‚Ä¢ Register, organize, track, and version your trained and deployed ML models.\\n‚Ä¢ Store model metadata and runtime dependencies for deployability.\\n‚Ä¢ Maintain model documentation and reporting‚Äîfor example, using model cards .\\n‚Ä¢ Integrate with the model evaluation and deployment capability and track online and offline evaluation metrics \\nfor the models.\\n‚Ä¢ Govern the model launching process: review, approve, release, and roll back. These decisions are based on a \\nnumber of offline performance and fairness metrics and on online experimentation results.\\nDataset and feature repository\\nThe dataset and feature repository capability lets you unify the definition and the storage of the ML data assets. \\nHaving a central repository of fresh, high-quality data assets enables shareability, discoverability, and reusability. The \\nrepository also provides data consistency for training and inference. This helps data scientists and ML researchers', 'repository also provides data consistency for training and inference. This helps data scientists and ML researchers \\nsave time on data preparation and feature engineering, which typically take up a significant amount of their time. Key \\nfunctionalities in the data and feature repository include the following:\\n15\\n‚Ä¢ Enable shareability, discoverability, reusability, and versioning of data assets.\\n‚Ä¢ Allow real-time ingestion and low-latency serving for event streaming and online prediction workloads. \\n‚Ä¢ Allow high-throughput batch ingestion and serving for extract, transform, load (ETL) processes and model \\ntraining, and for scoring workloads.\\n‚Ä¢ Enable feature versioning for point-in-time queries.\\n‚Ä¢ Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -', '‚Ä¢ Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -\\ntory might contain an entity called customer, which includes features like age group, postal code, and gender. On the \\nother hand, a dataset repository might include a customer churn dataset, which includes features from the customer \\nand product entities, as well as purchase- and web-activity event logs.\\nML metadata and artifact tracking\\nVarious types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive \\nstatistics and data schemas, trained models, and evaluation results. ML metadata is the information about these \\nartifacts, including their location, types, properties, and associations to experiments and runs. The ML metadata and']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=790025;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62.</span>94s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m62.\u001b[0m94s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.6396524110809825, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.64 because irrelevant nodes like 'institutional knowledge', 'research' and 'engineering' roles, 'classroom material', 'textbooks', and 'data scientists' are ranked lower than relevant nodes that discuss pipelines, reproducibility, scalability, and their importance in ML tasks., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the contextual recall score indicates that half of the expected output can be attributed to the nodes in the retrieval context, with some sentences strongly relating to specific nodes (e.g., sentence 2 relates to node 2) and others not containing any relevant information (unsupportive reasons)., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5135135135135135, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.51 because the retrieval context contains relevant statements about the challenges of using pipelines in Machine Learning (ML), such as poorly documented pipelines forcing practitioners to treat them as black boxes and the need for automated documentation assistance, which aligns with the input 'Por que usar pipelines em ML?', error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the answer directly addresses the question about using pipelines in Machine Learning, making it highly relevant and accurate., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the actual output only partially aligns with the retrieval context, as it acknowledges the potential issue of poorly documented pipelines being treated as black boxes, which is a subtle contradiction to the original claim that pipelines are essential., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Por que usar pipelines em ML?\n",
      "  - actual output: Pipelines no ML s√£o essenciais porque ajudam a organizar e automatizar o fluxo de dados e processos, garantindo que modelos sejam reproduz√≠veis e eficientes. Eles evitam a confus√£o de m√∫ltiplas ferramentas soltas (conhecido como \"jungle of pipelines\") e permitem que equipes mantenham pipelines bem documentadas e integradas. No entanto, sem uma boa documenta√ß√£o e integra√ß√£o, pipelines podem se tornar um problema (um anti-pattern), dificultando a manuten√ß√£o e a inova√ß√£o. üòä\n",
      "\n",
      "Se quiser, posso detalhar mais sobre algum aspecto espec√≠fico!\n",
      "  - expected output: Pipelines organizam e automatizam as etapas do ciclo de vida de ML, garantindo reprodutibilidade e escalabilidade.\n",
      "  - context: None\n",
      "  - retrieval context: ['ward to do once, P6 discussed that in the ML setting, they learn\\nfaster than they can document; moreover, people don‚Äôt want to\\nread so many different versions of documentation:\\nThere are people in the team, myself included, that\\nhave been on it for several years now, and so there‚Äôs\\nsome institutional knowledge embodied on the team\\nthat sometimes gets written down. But you know, even\\nwhen it does get written down, maybe you will read\\nthem, but then, they kind of disappear to the ether.\\nFinally, P17 realized that poorly documented pipelines forced\\nthem to treat pipelines as black boxes: ‚ÄúSome of our models are\\npretty old and not well documented, so I don‚Äôt have great expec-\\ntations for what they should be doing.‚Äù Without intuition for how\\npipelines should perform, practitioner productivity can be stunted.\\nTakeaway. The MLOps anti-patterns described in this section re-\\nveal that ML engineering, as a field, is changing faster than educa-', 'aging these pipelines, detecting errors and recovering fro m failures are all difÔ¨Åcult and costly .\\nTesting such pipelines often requires expensive end-to-en d integration tests. All of this adds to\\ntechnical debt of a system and makes further innovation more costly.\\nPipeline jungles can only be avoided by thinking holistical ly about data collection and feature ex-\\ntraction. The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground\\nup is indeed a major investment of engineering effort, but on e that can dramatically reduce ongoing\\ncosts and speed further innovation.\\nGlue code and pipeline jungles are symptomatic of integrati on issues that may have a root cause in\\noverly separated ‚Äúresearch‚Äù and ‚Äúengineering‚Äù roles. When M L packages are developed in an ivory-\\ntower setting, the result may appear like black boxes to the t eams that employ them in practice. A\\nhybrid research approach where engineers and researchers a re embedded together on the same teams', 'Takeaway. The MLOps anti-patterns described in this section re-\\nveal that ML engineering, as a field, is changing faster than educa-\\ntional resources can keep up. We see this as opportunities for new\\nresources, such as classroom material (e.g., textbooks, courses) to\\nprescribe the right engineering practices and rigor for the highly\\nexperimental discipline that is production ML, and automated doc-\\numentation assistance for ML pipelines in organizations.\\n5.3 Characterizing the ‚ÄúMLOps Stack‚Äù for Tool\\nBuilders\\nMLOps tool builders may be interested in an organization of the\\ndozens of tools, libraries, and services MLEs use to run ML and\\ndata processing pipelines. Although multiple MLEs reported hav-\\ning to ‚Äúglue‚Äù open-source solutions together and having to build\\n‚Äúhomegrown‚Äù infrastructure as part of their work (P1, P2, P5, P6,\\nP10, P12), an analysis of the various deployments reveals that tools\\nShreya Shankar‚àó, Rolando Garcia‚àó, Joseph M. Hellerstein, Aditya G. Parameswaran\\nRun Layer', 'ing environments varies depending on standards that are established in a \\ngiven organization. Most organizations have at least one testing environ -\\nment before production; some have more.\\nThe specifics of the pipeline deployment process depend on the technol -\\nogy that is used to implement the pipeline. With some no-code solutions, \\ndata scientists and ML engineers don‚Äôt handle or even see the details.\\nAlternatively, if you use a code-first technology to have more flexibility and \\ncontrol over the ML pipelines, ML engineers can deploy the pipeline using \\nstandard CI/CD processes and tools. This approach is what the diagram \\ndepicts. The diagram shows a standard CI/CD workflow, which consists of \\nthese stages:\\n1. In the CI stage, the source code is unit-tested, and the training pipe -\\nline is built and integration-tested. Any artifacts that are \\ncreated by the build are stored in an artifact repository.\\nFigure 6. The training operationalization process\\nTraining \\nOperationalization', 'tion 4.4, we discuss organizational efforts to effectively evaluate\\nmodels. Finally, in Section 4.5, we investigate the hacks ML engi-\\nneers use to sustain high performance in productions ML pipelines.\\n4.1 Tasks in the Production ML Lifecycle\\nWe characterized ML engineers‚Äô workflows into four high-level\\ntasks, each of which employ a wide variety of tools. We briefly\\ndescribe each task in turn, and elaborate on them as they arise in\\nour findings below.\\nData Collection and Labeling. Data collection spans sourcing\\nnew data, wrangling data from sources into a centralized reposi-\\ntory, and cleaning data. Data labeling can be outsourced (e.g., Me-\\nchanical Turk) or performed in-house with teams of annotators.\\nSince descriptions and interview studies of data collection, anal-\\nysis, wrangling and labeling activities can be found in related pa-\\npers , we focus our summary of findings on the other\\nthree tasks.\\nFeature Engineering and Model Experimentation. ML engi-']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=545082;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58.</span>31s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m58.\u001b[0m31s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the relevant nodes (ranked 2 and 4) are correctly ranked higher than irrelevant nodes, but there's still room for improvement as some 'no' verdicts are not properly distinguished from the top-ranked 'yes' verdicts., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5185185185185185, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.52 because most sentences in the expected output can be attributed to specific nodes in the retrieval context, indicating a decent level of relevance and recall., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5405405405405406, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.54 because the retrieval context statements are not directly related to the input 'O que s√£o m√©tricas de avalia√ß√£o?' which asks about evaluation metrics, but instead discuss broader topics such as ML systems interacting with the external world and evaluating model performance using various metrics., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 0.8333333333333334, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.83 because the actual output contains one irrelevant statement that slightly detracts from its relevance to addressing the concept of evaluation metrics, specifically a suggestion on how to show metrics to stakeholders rather than directly discussing the topic., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.8333333333333334, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.83 because the actual output only partially aligns with the retrieval context, as it acknowledges the importance of choosing the right metrics but lacks a clear explanation on how to do so., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que s√£o m√©tricas de avalia√ß√£o?\n",
      "  - actual output: M√©tricas de avalia√ß√£o s√£o formas de mensurar o desempenho de um modelo de Machine Learning (ML). Elas ajudam a verificar se o modelo est√° funcionando bem e atingindo os objetivos do projeto.\n",
      "\n",
      "No contexto fornecido, vemos que essas m√©tricas s√£o essenciais para garantir que o modelo seja eficaz e traga valor √†s organiza√ß√µes. √â importante escolher as m√©tricas certas, pois muitos projetos de ML falham porque as pessoas se concentram apenas em m√©tricas t√©cnicas como precis√£o e recall, em vez de m√©tricas que realmente importam para o neg√≥cio.\n",
      "\n",
      "Al√©m disso, o contexto menciona que √© crucial alinhar as m√©tricas com os objetivos do neg√≥cio e dos stakeholders. Por exemplo, P11 sugere que √© importante mostrar aos gestores as mesmas m√©tricas que outros departamentos usam para serem responsabilizados.\n",
      "  - expected output: S√£o medidas num√©ricas que indicam a qualidade do modelo, como accuracy, F1 e RMSE.\n",
      "  - context: None\n",
      "  - retrieval context: ['ration systems:\\n‚Ä¢It should be easy to specify a conÔ¨Åguration as a small change f rom a previous conÔ¨Åguration.\\n‚Ä¢It should be hard to make manual errors, omissions, or oversi ghts.\\n‚Ä¢It should be easy to see, visually, the difference in conÔ¨Ågur ation between two models.\\n‚Ä¢It should be easy to automatically assert and verify basic fa cts about the conÔ¨Åguration:\\nnumber of features used, transitive closure of data depende ncies, etc.\\n‚Ä¢It should be possible to detect unused or redundant settings .\\n‚Ä¢ConÔ¨Ågurations should undergo a full code review and be check ed into a repository.\\n6\\n7 Dealing with Changes in the External World\\nOne of the things that makes ML systems so fascinating is that they often interact directly with the\\nexternal world. Experience has shown that the external worl d is rarely stable. This background rate\\nof change creates ongoing maintenance cost.\\nFixed Thresholds in Dynamic Systems. It is often necessary to pick a decision threshold for a', 'cloud platforms or on-premises infrastructure.\\nIt is crucial to consider aspects such as scalability, security, and\\nperformance during the deployment phase. Ensuring that the model can\\nhandle multiple concurrent requests, protect sensitive data, and provide\\nlow-latency responses is essential.\\nMonit oring\\nOnce the model is deployed, it is essential to monitor its performance\\ncontinuously. Monit oring plays a vital role in identifying any degradation\\nin model performance and detecting errors or anomalies in the\\npredictions.\\nSeveral metrics can be used to evaluate model performance, such as\\naccuracy, precision, recall, and F1 score. Additionally, it is crucial to\\nmonitor infrastructure-related metrics ‚Äì like latency, throughput, and\\nresource consumption ‚Äì to guarantee the system‚Äôs stability and efficiency.\\nBy actively monitoring the model and its surrounding infrastructure, it is\\npossible to identify any issues early and swiftly address them. This process', 'rather than ML-specific metrics alone like MAP (P5, P7, P15, P16,\\nP11, P17, P18, P19). The need to evaluate product-critical metrics\\nstemmed from close collaboration with other stakeholders, such\\nas product managers and business operators. P11 felt that a key\\nreason many ML projects fail is that they don‚Äôt measure metrics\\nthat will yield the organization value:\\nTying to the business‚Äôs KPIs (key\\nperformance indicators) is really important. But it‚Äôs a\\nprocess‚Äîyou need to figure out what are, and\\nfrankly I think that‚Äôs how people should be doing AI. It\\n like: hey, let‚Äôs do these experiments and\\nget cool numbers and show off these nice precision-recall\\ncurves to our bosses and call it a day. It should be like:\\nhey, let‚Äôs actually show the same business metrics that\\neveryone else is held accountable to to our bosses at the\\nend of the day.\\nSince product-specific metrics are, by definition, different for\\ndifferent ML models, it was important for engineers to treat choos-', 'end of the day.\\nSince product-specific metrics are, by definition, different for\\ndifferent ML models, it was important for engineers to treat choos-\\ning the metrics as an explicit step in their workflow and align with\\nother stakeholders to make sure the right metrics were chosen. For\\nexample, P16 said that for every new ML project they work on, their\\n‚Äúfirst task is to figure out, what are customers actually interested\\nin, or what‚Äôs the metric that they care about.‚Äù P17 said that every\\nmodel change in production is validated by the product team: ‚Äúif\\nwe can get a statistically significant greater percentage people\\nto subscribe to , then .‚Äù\\nFor some organizations, a consequence of tightly coupling eval-\\nuation to product metrics was an additional emphasis on important\\ncustomers during evaluation (P6, P10). P6 described how, at their\\ncompany, experimental changes that increased aggregate metrics\\ncould sometimes be prevented from going to production:', 'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios. Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment. Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\n\\nModel deployment']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=43079;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59.</span>4s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m59.\u001b[0m4s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7555555555555555, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.76 because irrelevant nodes (nodes 2 and 4) are correctly ranked lower than relevant nodes (nodes 1, 3, and 5), with the first node being a strong match ('model development' is mentioned)., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.9411764705882353, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.94 because the contextual recall score indicates a high degree of accuracy, suggesting that most sentences in the expected output are correctly attributed to nodes in the retrieval context., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.6551724137931034, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.66 because most of the statements in the retrieval context are about model training, evaluation, and development, which are relevant to understanding what a baseline model is. For example, 'Model Training Once the model has been created, it is trained using a suitable dataset.' and 'This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks.' provide context about how a baseline model is created and refined., error: None)\n",
      "  - ‚ùå Answer Relevancy (score: 0.6666666666666666, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.67 because the model failed to provide relevant information about what a baseline model is, instead providing an irrelevant statement about the lack of context., error: None)\n",
      "  - ‚ùå Faithfulness (score: 0.3333333333333333, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.33 because the actual output does not align with the information presented in the retrieval context due to the absence of AI output being not explicitly mentioned, and there is no mention of a model baseline that would support this claim., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© um modelo baseline?\n",
      "  - actual output: Ol√°! Sobre o que voc√™ est√° estudando hoje?\n",
      "\n",
      "Infelizmente, no contexto fornecido, n√£o h√° informa√ß√µes sobre o que √© um modelo baseline.\n",
      "\n",
      "Se voc√™ tiver mais detalhes ou outro contexto, posso tentar ajudar melhor! üòä\n",
      "  - expected output: √â um modelo simples usado como refer√™ncia para comparar modelos mais complexos.\n",
      "  - context: None\n",
      "  - retrieval context: ['this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps', '‚Ä¢ Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\n‚Ä¢ Information about training, validation, and testing data splits that were used. \\n‚Ä¢ Model evaluation metrics and the validation procedure that was used.\\nIf there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\\ntion is submitted to the model registry. The model is then ready to be reviewed, approved, and deployed to the target \\n18\\nserving environment. In addition, all the relevant metadata and artifacts \\nthat were produced during model development are tracked in the metadata \\ntracking repository.\\nHowever, in most cases, ML models need to be retrained on a regular basis \\nwhen new data is available or when the code changes. In this case, the \\noutput of the ML development process is not the model to be deployed in \\nproduction. Instead, the output is the implementation of the continuous', 'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes. Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.', 'Model development\\n\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks. The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\n\\nAn essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments. Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.', 'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios. Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment. Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\n\\nModel deployment']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 0.00% pass rate\n",
      "Faithfulness: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=989812;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53.</span>96s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m53.\u001b[0m96s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7555555555555555, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.76 because irrelevant nodes are ranked lower than relevant ones, as seen from the first 'no' verdict (node 2) being placed after the second 'yes' verdict (node 3), indicating that the system correctly prioritized the context mentioning monitoring and testing in real-time over the node discussing data testing debt., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the contextual recall score indicates that half of the expected output sentences can be attributed to specific nodes in the retrieval context, while the other half do not have a clear connection to these nodes., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5714285714285714, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.57 because the retrieval context contains statements about monitoring system behavior in real-time, prediction bias, and automated response, which are not directly related to monitoring latency of inference., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about monitoring inference latency, making all statements highly relevant to the input., error: None)\n",
      "  - ‚ùå Faithfulness (score: 0.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.00 because the actual output claims there is no information available about monitoring latency, but a contradiction reveals that the retrieval context actually discusses monitoring and testing of individual components and end-to-end tests, which implies some level of monitoring latency., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que significa monitorar lat√™ncia de infer√™ncia?\n",
      "  - actual output: Infelizmente, n√£o h√° informa√ß√µes dispon√≠veis no contexto sobre o significado de \"monitorar lat√™ncia de infer√™ncia\".\n",
      "  - expected output: Monitorar lat√™ncia garante que o modelo responda dentro dos limites necess√°rios para uso real.\n",
      "  - context: None\n",
      "  - retrieval context: [', in which thresholds are learned via simple evaluation on heldout validation data.\\nMonitoring and Testing. Unit testing of individual components and end-to-end tests of running\\nsystems are valuable, but in the face of a changing world such tests are not sufÔ¨Åcient to provide\\nevidence that a system is working as intended. Comprehensiv e live monitoring of system behavior\\nin real time combined with automated response is critical fo r long-term system reliability.\\nThe key question is: what to monitor? Testable invariants ar e not always obvious given that many\\nML systems are intended to adapt over time. We offer the follo wing starting points.\\n‚Ä¢Prediction Bias. In a system that is working as intended, it should usually be t he case that\\nthe distribution of predicted labels is equal to the distrib ution of observed labels. This is\\nby no means a comprehensive test, as it can be met by a null mode l that simply predicts', 'the distribution of predicted labels is equal to the distrib ution of observed labels. This is\\nby no means a comprehensive test, as it can be met by a null mode l that simply predicts\\naverage values of label occurrences without regard to the in put features. However, it is a\\nsurprisingly useful diagnostic, and changes in metrics suc h as this are often indicative of\\nan issue that requires attention. For example, this method c an help to detect cases in which\\nthe world behavior suddenly changes, making training distr ibutions drawn from historical\\ndata no longer reÔ¨Çective of current reality. Slicing predic tion bias by various dimensions\\nisolate issues quickly, and can also be used for automated al erting.\\n‚Ä¢Action Limits. In systems that are used to take actions in the real world, suc h as bidding\\non items or marking messages as spam, it can be useful to set an d enforce action limits as a\\nsanity check. These limits should be broad enough not to trig ger spuriously. If the system', 'their control planes if at all possible.\\nBecause external changes occur in real-time, response must also occur in real-time as well. Relying\\non human intervention in response to alert pages is one strat egy, but can be brittle for time-sensitive\\nissues. Creating systems to that allow automated response w ithout direct human intervention is often\\nwell worth the investment.\\n8 Other Areas of ML-related Debt\\nWe now brieÔ¨Çy highlight some additional areas where ML-rela ted technical debt may accrue.\\nData Testing Debt. If data replaces code in ML systems, and code should be tested , then it seems\\nclear that some amount of testing of input data is critical to a well-functioning system. Basic sanity\\nchecks are useful, as more sophisticated tests that monitor changes in input distributions.\\n7\\nReproducibility Debt. As scientists, it is important that we can re-run experiment s and get similar', 'on values), P6 talked about monitoring completeness (i.e., fraction\\nof non-null values) for features, P16 mentioned embedding their\\npipelines with \"common sense checks,\" implemented as hard con-\\nstraints on columns, and P8 described schema checks‚Äîmaking sure\\neach data item adheres to an expected set of columns and their\\ntypes.\\nWhile rudimentary data checks were embedded in most systems,\\nP6 discussed that it was hard to figure out what higher-order data\\nchecks to compute:\\nMonitoring is both metrics and then a predicate over\\nthose metrics that triggers alerts. That second piece\\ndoesn‚Äôt exist‚Äînot because the infrastructure is hard,\\nbut because no one knows how to set those predicate\\nvalues...for a lot of this stuff now, there‚Äôs engineering\\nheadcount to support a team doing this stuff. This is\\npeople‚Äôs jobs now; this constant, periodic evaluation of\\nmodels.\\nSome participants discussed using black-box data monitoring\\nservices but lamented that their alerts did not prevent failures (P7,', \"Setting up robust alerting and notification systems is essential to complement the monitoring efforts. These systems serve as an early warning mechanism, flagging any signs of performance degradation or emerging issues with the deployed models. By receiving timely alerts, data scientists and engineers can quickly investigate and address these concerns, minimizing their impact on the model's performance and the end-users' experience.\"]\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=103749;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41.</span>13s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m41.\u001b[0m13s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because irrelevant nodes (nodes 1 and 4) are ranked lower than relevant nodes (nodes 2 and 3), as they do not provide information about model validation, whereas nodes 2 and 3 explicitly mention 'validation datasets' and 'offline validation phase', making them more relevant to the topic., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the contextual recall score indicates a moderate level of matching between the expected output and the nodes in the retrieval context, but there are some sentences in the expected output that do not contain any parts that can be attributed to these nodes., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5357142857142857, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.54 because most of the retrieval context statements describe deployment methods, hyperparameter optimization, and regularisation techniques, which are not directly related to validation or quality assessment, as stated by the reasons for irrelevancy., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about what validation cross is, making all statements highly relevant., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the actual output mentions Valida√ß√£o Cruzada, which can be inferred from the retrieval context, but provides more detail than what's mentioned in the context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© valida√ß√£o cruzada?\n",
      "  - actual output: **Valida√ß√£o Cruzada** √© uma t√©cnica utilizada durante o treinamento de modelos de machine learning para avaliar o desempenho do modelo e garantir que ele generalize bem para novos dados. \n",
      "\n",
      "Ela consiste em dividir o conjunto de dados em v√°rias parti√ß√µes (geralmente tr√™s: treino, valida√ß√£o e teste) e realizar m√∫ltiplas itera√ß√µes de treinamento e avalia√ß√£o. Isso ajuda a evitar overfitting (ajuste excessivo ao conjunto de treino) e fornece uma estimativa mais precisa da capacidade preditiva do modelo.\n",
      "\n",
      "Essa t√©cnica √© frequentemente aplicada em conjunto com outras abordagens, como otimiza√ß√£o de hiperpar√¢metros e regulariza√ß√£o, durante o processo de treinamento.\n",
      "  - expected output: √â uma t√©cnica que divide os dados em m√∫ltiplos subconjuntos para avaliar melhor a generaliza√ß√£o.\n",
      "  - context: None\n",
      "  - retrieval context: ['other systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,\\nthese issues are referred to as visibility debt .\\nUndeclared consumers are expensive at best and dangerous at worst, because they create a hidden\\ntight coupling of model mato other parts of the stack. Changes to mawill very likely impact these\\nother parts, potentially in ways that are unintended, poorl y understood, and detrimental. In practice,\\nthis tight coupling can radically increase the cost and difÔ¨Å culty of making any changes to maat all,\\neven if they are improvements. Furthermore, undeclared con sumers may create hidden feedback\\nloops, which are described more in detail in section 4.\\n2\\nUndeclared consumers may be difÔ¨Åcult to detect unless the sy stem is speciÔ¨Åcally designed to guard', 'this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps', 'ported processes to analyze live failure modes and update the vali-\\ndation datasets to prevent similar failures from happening again (P1,\\nP2, P5, P6, P8, P11, P15, P16, P17, P18). P1 described this process as\\na departure from what they had learned in academia: ‚ÄúYou have this\\nclassic issue where most researchers are evaluat against fixed\\ndata sets... most industry methods change their datasets.‚Äù We\\nfound that these dynamic validation sets served two purposes: (1)\\nthe obvious goal of making sure the validation set reflects live data\\nas much as possible, given new learnings about the problem and\\nshifts in the aggregate data distribution, and (2) the more subtle goal\\nof addressing localized shifts that subpopulations may experience\\n(e.g., low accuracy for a specific label).\\nThe challenge with (2) is that many subpopulations are typically\\nunforeseen; many times they are discovered post-deployment. To\\nenumerate them, P11 discussed how they systematically bucketed', 'different failure modes in the offline validation phase‚Äîe.g., perfor-\\nmance drops in subpopulations users might care deeply about‚ÄîlikeP11 did, P8 offered a reactive strategy of spawning a new dataset\\nfor each observed live failure: ‚ÄúEvery gets into\\nthe same queue, and 3 of us sit down once a week and go through\\nthe queue...then our collect more data.‚Äù This\\nnew dataset was then used in the offline validation phase in future\\niterations of the production ML lifecycle.\\nWhile processes to dynamically update the validation datasets\\nranged from human-in-the-loop to frequent synthetic data con-\\nstruction (P6), we found that higher-stakes applications of ML (e.g.,\\nautonomous vehicles), created separate teams to manage the dy-\\nnamic evaluation process. P1 said:\\nWe had to move away from only aggregate metrics like\\nMAP towards the ability to curate scenarios of interest,\\nand then validate model performance on them specifi-\\ncally. So, as an example, you can‚Äôt hit pedestrians, right.', '(https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets#Holdout_dataset) to evaluate\\nthe model quality. The output of this step is a set of metrics to assess the quality of\\nthe model.\\n6. Model validation: The model is confirmed to be adequate for deployment‚Äîthat its\\npredictive performance is better than a certain baseline.\\n7. Model serving: The validated model is deployed to a target environment to serve\\npredictions. This deployment can be one of the following:\\nMicroservices with a REST API to serve online predictions.\\nAn embedded model to an edge or mobile device.\\nPart of a batch prediction system.\\n8. Model monitoring: The model predictive performance is monitored to potentially\\ninvoke a new iteration in the ML process.\\nThe level of automation of these steps defines the maturity of the ML process, which\\nreflects the velocity of training new models given new data or training new models given']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=211764;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.</span>92s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m47.\u001b[0m92s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.5666666666666667, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.57 because irrelevant nodes (nodes 1 and 3) are correctly ranked lower than the relevant nodes (nodes 2, 4, and 5), with the first 'yes' verdict at node 2, indicating that model drift detection is a topic of interest in natural data drift and unnatural data drift., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5454545454545454, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.55 because the contextual recall score indicates that some sentences from the expected output are correctly attributed to nodes in the retrieval context, while others do not have a clear match., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.6428571428571429, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.64 because the retrieval context contains irrelevant information about Goldilocks and the Three Bears, The model gets retrained, bad jobs, and P6 discussed a histogram, which have no connection to model drift detection. However, some relevant statements in the context mention natural data drift, model retrains, and monitoring model performance for accuracy drift, bias, and other potential issues, indicating that the context is not entirely irrelevant., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about model drift detection, providing a relevant and accurate answer., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© model drift detection?\n",
      "  - actual output: Model drift detection √© o processo de identificar quando um modelo de machine learning come√ßa a funcionar de maneira diferente do esperado ap√≥s ser implantado em produ√ß√£o. Isso pode acontecer devido a mudan√ßas no ambiente operacional ou na qualidade dos dados, que n√£o eram previstas durante o desenvolvimento do modelo.\n",
      "\n",
      "No contexto fornecido, h√° duas formas principais de drift:\n",
      "1. **Drift natural**: Mudan√ßas lentas e esperadas nos dados ao longo do tempo, que s√£o resolvidas por retrainamentos frequentes dos modelos.\n",
      "2. **Drift acidental**: Problemas inesperados, como formatos de dados inconsistentes ou corrup√ß√µes em dados espec√≠ficos de certas regi√µes.\n",
      "\n",
      "A detec√ß√£o de drift √© uma parte crucial da manuten√ß√£o de modelos de ML, garantindo que eles continuem eficientes e relevantes mesmo ap√≥s a implanta√ß√£o.\n",
      "  - expected output: √â o processo automatizado de identificar mudan√ßas na distribui√ß√£o ou rela√ß√£o dos dados que afetam a performance do modelo.\n",
      "  - context: None\n",
      "  - retrieval context: ['participants cited Covid as an example, but there are other\\n(better) everyday instances of unnatural data drift. P6 de-\\nscribed a bug where users had inconsistent definitions of the\\nsame word, complicating the deployment of a service to a\\nnew user. P7 mentioned a bug where data from users in a\\ncertain geographic region arrived more sporadically than\\nusual. P10 discussed a bug where the format of raw data was\\noccasionally corrupted: ‚ÄúTables didn‚Äôt always have headers\\nin the same place, even though they were the same tables.‚Äù\\n‚Ä¢Natural data drift: Surprisingly, participants didn‚Äôt seem\\ntoo worried about slower, expected natural data drift over\\ntime‚Äîthey noted that frequent model retrains solved this\\nproblem (P6, P7, P8, P12, P15, P16, P17). As an anecdote, we\\nasked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:', 'asked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:\\n5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\ncharacter, looks for things that are not too big or not too small, things that are ‚Äújust\\nright.‚Äù\\nOperationalizing Machine Learning: An Interview Study\\nThe model gets retrained every day, so we don‚Äôt have the\\nscenario of like: Oh, our models got stale and we need to re-\\ntrain it because it‚Äôs starting to make mistakes because data\\nhas drifted...fortunately we‚Äôve never had to deal with [such\\na] scenario. Sometimes there are bad jobs, but\\nwe can always effectively roll back to a different .\\nHowever, a few engineers mentioned that natural data shift\\ncould cause some hand-curated features and data quality\\nchecks to corrupt (P3, P6, P8). P6 discussed a histogram used', 'dation system has on click-throughs and on conversation rates. The results of online experimentation should be \\nintegrated with the model registry capability to facilitate the decision about releasing the model to production. Online \\nexperimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models \\nand to promote well-performing ones. Key functionalities in online experimentation include the following:\\n‚Ä¢ Support canary and shadow deployments.\\n‚Ä¢ Support traffic splitting and A/B tests.\\n‚Ä¢ Support multi-armed bandit (MAB) tests.\\nModel monitoring\\nThe model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production \\nto ensure predictive quality and business continuity. This capability informs you if your models are stale and need to \\nbe investigated and updated. Key functionalities in model monitoring include the following:', 'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes. Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.', 'A pivotal aspect of MLOps is the maintenance and management of data, models and code. By maintaining distinct versions of these components, teams can effectively keep aware of changes over time, which is essential for troubleshooting issues, ensuring reproducibility of results and facilitating easier rollbacks when necessary. This approach aids in maintaining the integrity of the development process and enables auditability in ML projects.\\n\\nMonitoring the performance and health of ML models is critical to ensure that they continue to meet the intended objectives after deployment. This process involves regularly assessing for model drift, bias and other potential issues that could compromise their effectiveness. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=735636;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.</span>18s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m50.\u001b[0m18s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.6396524110809825, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.64 because irrelevant nodes (nodes ranked 2-11) are correctly ranked lower than relevant nodes (nodes ranked 1 and 3-12), as they do not provide information about the importance of a lineage tracker in MLOps, whereas the top-ranked nodes and most nodes after that do., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the contextual recall score indicates a moderate level of accuracy in attributing sentences from the expected output to corresponding nodes in the retrieval context, with some sentences having clear connections and others not being directly linked., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.7073170731707317, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.71 because the retrieval context contains statements that directly relate to the importance of a lineage tracker in MLOps, such as 'Provide traceability and lineage tracking of ML artifacts.' and 'ML metadata and artifact tracking capability is foundational to all other MLOps capabilities.', which are highly relevant to the input question., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about the importance of a lineage tracker in MLOps, making all statements highly relevant., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Qual a import√¢ncia de um lineage tracker em MLOps?\n",
      "  - actual output: Um **lineage tracker** (ou rastreador de linhagem) √© uma funcionalidade fundamental dentro de um **ML Ops (MLOps)**. Sua import√¢ncia reside principalmente em:\n",
      "\n",
      "1.  **Traceabilidade:** Ele permite rastrear a origem e a evolu√ß√£o de todos os artefatos criados ao longo do ciclo de vida do projeto de Machine Learning. Isso inclui dados de entrada, pr√©-processamentos, modelos treinados, resultados de avalia√ß√£o e muito mais. Saber exatamente de onde veio um dado ou um modelo √© crucial.\n",
      "\n",
      "2.  **Reprodutibilidade:** Com o rastreamento da linhagem, √© poss√≠vel replicar exatamente as mesmas condi√ß√µes e passos que levaram √† cria√ß√£o de um artefato espec√≠fico (como um modelo ou um conjunto de dados processado). Isso √© vital para valida√ß√£o, auditoria e para tentar corrigir problemas em sistemas j√° implementados.\n",
      "\n",
      "3.  **Depura√ß√£o:** Se um modelo come√ßa a falhar ou produzir resultados inesperados, o lineage tracker ajuda a entender por onde ele passou. Voc√™ pode verificar qual conjunto de dados foi usado, quais pr√©-processamentos foram aplicados, qual foi a vers√£o do modelo e at√© mesmo o ambiente de treinamento. Isso facilita enormemente a identifica√ß√£o de problemas.\n",
      "\n",
      "Em resumo, o lineage tracker √© uma pe√ßa fundamental para garantir que os processos de MLOps sejam confi√°veis, audit√°veis e eficientes, permitindo um melhor gerenciamento de projetos e uma maior capacidade de depurar problemas.\n",
      "  - expected output: Lineage tracking permite rastrear dados, modelos, experimentos e artefatos para auditoria e reprodutibilidade.\n",
      "  - context: None\n",
      "  - retrieval context: ['artifacts, including their location, types, properties, and associations to experiments and runs. The ML metadata and \\nartifact tracking capability is foundational to all other MLOps capabilities. Such a capability enables reproducibility \\nand debugging of complex ML tasks and pipelines. Key functionalities in ML metadata and artifact tracking include \\nthe following:\\n‚Ä¢ Provide traceability and lineage tracking of ML artifacts.\\n‚Ä¢ Share and track experimentation and pipeline parameter configurations.\\n‚Ä¢ Store, access, investigate, visualize, download, and archive ML artifacts.\\n‚Ä¢ Integrate with all other MLOps capabilities.\\nDeep dive of MLOps processes\\nThis section describes each of the core MLOps processes in detail. It describes key tasks and flow of control be -\\ntween tasks, the key artifacts created by the tasks, and the relationship of tasks to other upstream and downstream', 'bridge the gap between machine learning development and the\\nimplementation of ML systems in a production environment. The platform\\nhelps streamline the process of building, deploying, and monitoring\\nmodels, by providing a standardised and automated workflow.\\nThe ML Ops platform typically includes multiple components such as:11/11/25, 9:50 PM MLOps Now - The MLOps Platform: Revolutionising Machine Learning Efficiency\\nhttps://mlopsnow.com/blog/mlops-platforms-revolutionising-machine-learning/ 2/10\\nAutomat ed Training : Automating the training of machine learning\\nmodels on a scheduled basis to keep them updated with fresh data.\\nModel V ersioning : Keeping track of different versions of models and\\nsimplifying the management of those models.\\nContinuous Int egration and Deployment : Ensuring continuous\\nintegration (CI) and automatic deployment of ML models in the\\nproduction environment.\\nMonit oring : Tracking model performance, identifying drifts, and\\nproviding alerts for potential issues.', '‚Ä¢ Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -\\ntory might contain an entity called customer, which includes features like age group, postal code, and gender. On the \\nother hand, a dataset repository might include a customer churn dataset, which includes features from the customer \\nand product entities, as well as purchase- and web-activity event logs.\\nML metadata and artifact tracking\\nVarious types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive \\nstatistics and data schemas, trained models, and evaluation results. ML metadata is the information about these \\nartifacts, including their location, types, properties, and associations to experiments and runs. The ML metadata and', 'Proper data management in an ML Ops platform ensures that datasets are:\\nCleaned and preprocessed efficiently.\\nEasily accessible and shareable among users or teams.\\nVersion-controlled to keep track of changes and updates.\\nCompliance and Monit oring\\nCompliance and monitoring play crucial roles in maintaining governance\\nand security in ML Ops platforms. Monitoring tools provide essential\\ninsights to detect and mitigate potential security threats. These tools help\\nin:\\nIdentifying vulnerabilities and generating alerts in real-time.\\nEnsuring data protection and regulatory compliance.\\nTracking user activities, thus allowing auditing and accountability.\\nMLOps platforms should implement policies and best practices to maintain\\ncompliance with data protection laws and industrial regulations. This11/11/25, 9:50 PM MLOps Now - The MLOps Platform: Revolutionising Machine Learning Efficiency\\nhttps://mlopsnow.com/blog/mlops-platforms-revolutionising-machine-learning/ 7/10', 'processing, model training, model evaluation, model serving, online experimentation, model monitoring, ML pipeline, \\nand model registry. Finally, two cross-cutting capabilities that enable integration and interaction are an ML metadata \\nand artifact repository and an ML dataset and feature repository.\\nFigure 4. Core MLOps technical capabilities\\n11\\nThe following sections outline the characteristics of each of the MLOps capabilities.\\nExperimentation \\nThe experimentation capability lets your data scientists and ML researchers collaboratively perform exploratory data \\nanalysis, create prototype model architectures, and implement training routines. An ML environment should also let \\nthem write modular, reusable, and testable source code that is version controlled. Key functionalities in experimenta -\\ntion include the following:\\n‚Ä¢ Provide notebook environments that are integrated with version control tools like Git.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=915139;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61.</span>69s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m61.\u001b[0m69s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.7095238095238094, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.71 because the relevant nodes (nodes 1, 3, and 5) are ranked higher than irrelevant nodes (nodes 2, 4, and 6-8), with the reasons being that these irrelevant nodes only provide superficial information about CT without explaining what it is or how it works., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.6, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.60 because the expected output partially matches with nodes in retrieval context, particularly with sentences related to machine learning development phases and processes, such as experimentation, model training, and continuous integration., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the retrieval context contains irrelevant information about Figure 3, while relevant statements mention continuous training (CT) as a unique property concerned with automatically retraining and serving models, and repeatedly executing the training pipeline in response to new data or code changes., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly answers the question about what continuous training (CT) is, without any irrelevant information., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.6666666666666666, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.67 because the actual output contradicts the retrieval context by stating that the model is retrained automatically or replaced in production, which goes against the focus on experimentation and prototype development mentioned in the context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© continuous training (CT)?\n",
      "  - actual output: Okay, vamos esclarecer! üòä\n",
      "\n",
      "**Continuous Training (CT)** √© uma propriedade √∫nica das sistemas de Machine Learning que garante que os modelos de ML sejam **ree treinados automaticamente** para manterem seu desempenho ao longo do tempo.\n",
      "\n",
      "Aqui est√° o que isso significa na pr√°tica:\n",
      "\n",
      "1.  **Reentrenamento Autom√°tico:** O pipeline de treinamento (que foi formalizado no est√°gio anterior) √© executado repetidamente.\n",
      "2.  **Gatilhos:** Essas execu√ß√µes autom√°ticas s√£o acionadas por diferentes gatilhos, como:\n",
      "    *   Disponibilidade de novos dados.\n",
      "    *   Detec√ß√£o de decaimento do desempenho do modelo (performance decay).\n",
      "    *   Altera√ß√µes no c√≥digo do modelo ou nos dados.\n",
      "    *   Cronogramas pr√©-definidos.\n",
      "\n",
      "3.  **Sa√≠da:** A cada execu√ß√£o, um **novo modelo** √© gerado e substitui o modelo antigo no ambiente de produ√ß√£o.\n",
      "\n",
      "**Por que √© diferente do CI/CD tradicional?**\n",
      "\n",
      "*   **CI/CD (Integra√ß√£o e Entrega Continuas):** Trabalha com software tradicional. O foco √© testar e validar mudan√ßas no c√≥digo e componentes, e entregar pacotes ou servi√ßos.\n",
      "*   **CT (Continuous Training):** √â espec√≠fico de ML. O foco √© testar e validar dados, modelos e pipelines de treinamento, e **ree treinar o modelo** para que ele continue servindo previs√µes precisas com os dados mais recentes.\n",
      "\n",
      "Em resumo, o **Continuous Training** garante que seu modelo ML seja sempre atualizado e relevante, aprendendo com novas informa√ß√µes ou ajustando-se quando seu desempenho come√ßa a declinar. √â como ter um modelo que \"estuda\" sozinho para se manter atualizado! üìö‚ú®\n",
      "  - expected output: CT √© a pr√°tica de treinar novamente modelos automaticamente com novos dados conforme regras definidas.\n",
      "  - context: None\n",
      "  - retrieval context: ['flow:\\n1. The core activity during this ML development phase is experimentation. As data scientists and ML research -\\ners prototype model architectures and training routines, they create labeled datasets, and they use features \\nand other reusable ML artifacts that are governed through the data and model management process. The \\nFigure 3. The MLOps process\\n9\\nprimary output of this process is a formalized training procedure, which includes data preprocessing, model \\narchitecture, and model training settings. \\n2. If the ML system requires continuous training (repeated retraining of the model), the training procedure is \\noperationalized as a training pipeline. This requires a CI/CD routine to build, test, and deploy the pipeline to \\nthe target execution environment.\\n3. The continuous training pipeline is executed repeatedly based on retraining triggers, and it produces a model \\nas output. The model is retrained as new data becomes available, or if model performance decay is detected.', \"testing, integration testing, and continuous delivery of the software module or the package.\\nHowever, in ML, there are a few notable differences:\\nCI is no longer only about testing and validating code and components, but also\\ntesting and validating data, data schemas, and models.\\nCD is no longer about a single software package or a service, but a system (an ML\\ntraining pipeline) that should automatically deploy another service (model prediction\\nservice).\\nCT is a new property, unique to ML systems, that's concerned with automatically\\nretraining and serving the models.\\nThe following section discusses the typical steps for training and evaluating an ML model\\nto serve as a prediction service.\\nData science steps for ML\\nIn any ML project, after you define the business use case and establish the success criteria,\\nthe process of delivering an ML model to production involves the following steps. These\\nsteps can be completed manually or can be completed by an automatic pipeline.\", 'The processes can consist of the following:\\n‚Ä¢ ML development concerns experimenting and developing a robust and reproducible model training proce -\\ndure (training pipeline code), which consists of multiple tasks from data preparation and transformation to \\nmodel training and evaluation.\\n‚Ä¢ Training operationalization concerns automating the process of packaging, testing, and deploying repeat -\\nable and reliable training pipelines.\\n‚Ä¢ Continuous training concerns repeatedly executing the training pipeline in response to new data or to code \\nchanges, or on a schedule, potentially with new training settings.\\n‚Ä¢ Model deployment concerns packaging, testing, and deploying a model to a serving environment for online \\nexperimentation and production serving.\\nFigure 2 . The MLOps lifecycle\\n8\\n‚Ä¢ Prediction serving is about serving the model that is deployed in production for inference.\\n‚Ä¢ Continuous monitoring is about monitoring the effectiveness and efficiency of a deployed model.', \"Continuous integration\\nIn this setup, the pipeline and its components are built, tested, and packaged when new\\ncode is committed or pushed to the source code repository. Besides building packages,\\ncontainer images, and executables, the CI process can include the following tests:\\nUnit testing your feature engineering logic.\\nUnit testing the different methods implemented in your model. For example, you have\\na function that accepts a categorical data column and you encode the function as a\\none-hot\\xa0(https://en.wikipedia.org/wiki/One-hot) feature.\\nTesting that your model training converges (that is, the loss of your model goes down\\nby iterations and overfits\\xa0(https://en.wikipedia.org/wiki/Overfitting) a few sample records).\\nTesting that your model training doesn't produce NaN\\xa0(https://en.wikipedia.org/wiki/NaN)\\nvalues due to dividing by zero or manipulating small or large values.\\nTesting that each component in the pipeline produces the expected artifacts.\", 'pipeline; this lets you achieve continuous delivery of model prediction service. To automate\\nthe process of using new data to retrain models in production, you need to introduce\\nautomated data and model validation steps to the pipeline, as well as pipeline triggers and\\nmetadata management.\\nThe following figure is a schematic representation of an automated ML pipeline for CT.11/13/25, 11:39 PM MLOps: Continuous delivery and automation pipelines in machine learning | Cloud Architecture Center | Google Cloud Do‚Ä¶\\nhttps://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning 8/18\\nFigure 3. ML pipeline automation for CT.\\nCharacteristics\\nThe following list highlights the characteristics of the MLOps level 1 setup, as shown in\\nFigure 3:\\nRapid experiment: The steps of the ML experiment are orchestrated. The transition\\nbetween steps is automated, which leads to rapid iteration of experiments and better']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=328233;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.</span>36s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m52.\u001b[0m36s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Contextual Precision (score: 0.25, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.25 because the first four nodes are irrelevant to understanding how a system of AB testing works for models, as they discuss unrelated topics such as MLOps capabilities and version control. The fifth node, however, mentions A/B testing and its relevance to introducing new models, indicating that it should be ranked higher than the other 'no' verdicts., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.52, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.52 because the contextual recall score indicates that the expected output sentence partially matches with nodes in the retrieval context, but not perfectly, suggesting a moderate level of relevance between the two., error: None)\n",
      "  - ‚ùå Contextual Relevancy (score: 0.3793103448275862, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.38 because the retrieval context contains general information about MLOps capabilities and typical assets produced in an MLOps process, but none of these statements have any relevance to how a system of AB testing for models works., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about how a system of A/B testing works for models, with no irrelevant statements., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.875, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.88 because the actual output does not align with the information presented in the retrieval context due to a contradiction that the retrieval context does not mention A/B testing for models, which is the main topic of this claim., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Como funciona um sistema de AB testing para modelos?\n",
      "  - actual output: Um sistema de A/B testing para modelos funciona da seguinte forma:\n",
      "\n",
      "1. **Introdu√ß√£o Gradual do Novo Modelo**:  \n",
      "   Em vez de substituir imediatamente o modelo antigo, ele √© introduzido ao lado dele. Dados de entrada s√£o divididos aleatoriamente entre os dois modelos (antigo e novo).\n",
      "\n",
      "2. **Coleta de M√©tricas**:  \n",
      "   O desempenho de ambos os modelos √© monitorado em tempo real. S√£o coletadas m√©tricas relevantes, como precis√£o, recall, taxa de convers√£o ou qualquer outro crit√©rio definido pelo projeto.\n",
      "\n",
      "3. **Compara√ß√£o Estat√≠stica**:  \n",
      "   Os resultados s√£o analisados estatisticamente para determinar se a diferen√ßa no desempenho do novo modelo √© significativa e melhor do que o modelo antigo.\n",
      "\n",
      "4. **Decis√£o**:  \n",
      "   - Se o novo modelo demonstrar melhor desempenho estatisticamente significativo, ele pode ser promovido para produ√ß√£o.  \n",
      "   - Caso contr√°rio, o modelo antigo permanece como padr√£o.\n",
      "\n",
      "**Exemplo Pr√°tico**:  \n",
      "Imagine que voc√™ tem um sistema de recomenda√ß√£o. O modelo antigo est√° em produ√ß√£o e o novo modelo foi desenvolvido. Durante o A/B testing:  \n",
      "- 10% dos usu√°rios recebem recomenda√ß√µes do novo modelo.  \n",
      "- 90% continuam usando o modelo antigo.  \n",
      "Se o novo modelo resultar em uma taxa de cliques 10% maior, ele pode ser adotado completamente.\n",
      "\n",
      "**Benef√≠cios**:  \n",
      "- Reduz o risco de implementar um modelo ruim diretamente em produ√ß√£o.  \n",
      "- Fornece dados concretos para validar melhorias antes de expandir a escala.  \n",
      "\n",
      "Essa abordagem √© essencial para garantir que os modelos atendam aos requisitos de neg√≥cio de forma confi√°vel e eficiente.\n",
      "  - expected output: O sistema divide tr√°fego entre modelos diferentes para comparar performance estatisticamente.\n",
      "  - context: None\n",
      "  - retrieval context: ['Typical assets produced in this \\nprocess include the following:\\n‚Ä¢ Notebooks for experimentation \\nand visualization\\n‚Ä¢ Metadata and artifacts of the \\nexperiments\\n‚Ä¢ Data schemas\\n‚Ä¢ Query scripts for the training data\\n‚Ä¢ Source code and configurations for \\ndata validation and transformation\\n‚Ä¢ Source code and configurations for \\ncreating, training, and evaluating \\nmodels\\n‚Ä¢ Source code and configurations for \\nthe training-pipeline workflow\\n‚Ä¢ Source code for unit tests and \\nintegration tests\\nCore MLOps capabilities:\\n‚Ä¢ Dataset & feature repository\\n‚Ä¢ Data processing\\n‚Ä¢ Experimentation\\n‚Ä¢ Model training\\n‚Ä¢ Model registry\\n‚Ä¢ ML metadata & artifact repository\\n19\\nA pipeline typically goes through a series of testing and staging environ -\\nments before it is released to production. The number of testing and stag -\\ning environments varies depending on standards that are established in a \\ngiven organization. Most organizations have at least one testing environ -\\nment before production; some have more.', \"Data changes\\nModel training code changes\\nApplication code changes.\\nAutomated testing helps you discover problems early for fast error Ô¨Åxes and learnings. Automation is more\\neÔ¨Écient with infrastructure as code (IaC). You can use tools to deÔ¨Åne and manage infrastructure. This helps\\nensure it's reproducible and can be consistently deployed across various environments.\\nRead about IaC ¬ª\\nContinuous X\\nThrough automation, you can continuously run tests and deploy code across your ML pipeline.\\nIn MLOps, continuous refers to four activities that happen continuously if any change is made anywhere in\\nthe system:\\nContinuous integration extends the validation and testing of code to data and models in the pipeline\\nContinuous delivery automatically deploys the newly trained model or model prediction service\\nContinuous training automatically retrains ML models for redeployment\\nContinuous monitoring concerns data monitoring and model monitoring using metrics related to\\nbusiness\\nModel governance\", \"testing, integration testing, and continuous delivery of the software module or the package.\\nHowever, in ML, there are a few notable differences:\\nCI is no longer only about testing and validating code and components, but also\\ntesting and validating data, data schemas, and models.\\nCD is no longer about a single software package or a service, but a system (an ML\\ntraining pipeline) that should automatically deploy another service (model prediction\\nservice).\\nCT is a new property, unique to ML systems, that's concerned with automatically\\nretraining and serving the models.\\nThe following section discusses the typical steps for training and evaluating an ML model\\nto serve as a prediction service.\\nData science steps for ML\\nIn any ML project, after you define the business use case and establish the success criteria,\\nthe process of delivering an ML model to production involves the following steps. These\\nsteps can be completed manually or can be completed by an automatic pipeline.\", 'Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track', \"Verifying that models meet the predictive performance targets before they are\\ndeployed.\\nAutomated deployment to a test environment, for example, a deployment that is\\ntriggered by pushing code to the development branch.\\nSemi-automated deployment to a pre-production environment, for example, a\\ndeployment that is triggered by merging code to the main branch after reviewers\\napprove the changes.\\nManual deployment to a production environment after several successful runs of the\\npipeline on the pre-production environment.\\nTo summarize, implementing ML in a production environment doesn't only mean deploying\\nyour model as an API for prediction. Rather, it means deploying an ML pipeline that can\\nautomate the retraining and deployment of new models. Setting up a CI/CD system lets you\\nautomatically test and deploy new pipeline implementations. This system lets you cope\\nwith rapid changes in your data and business environment. You don't have to immediately\"]\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 0.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 0.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=219294;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72.</span>21s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m72.\u001b[0m21s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama3:latest </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama3:latest \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because irrelevant nodes (nodes 1 and 3) are ranked lower than relevant nodes (nodes 2 and 4), indicating that the model correctly prioritizes contexts with information about 'champion' and 'challenger' models., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 0.8888888888888888, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.89 because the contextual recall accurately captures the relationships between sentences in the expected output, with most sentences being attributed to nodes in the retrieval context, except for one standalone statement that doesn't require specific context., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.7567567567567568, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.76 because the retrieval context contains relevant statements about machine learning models, specifically discussing topics like model monitoring, validation, and evaluation, which are closely related to champion vs challenger models. For example, statements like 'By monitoring for model drift the data science team is able to proactively work rather than reactively.' and 'Evaluation is critical to ensure that the models perform well in real-world scenarios.' demonstrate a connection between the retrieval context and the input question., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.8, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 1.00 because the actual output directly addresses the question about the difference between a Champion and Challenger model, making all statements highly relevant to the input., error: None)\n",
      "  - ‚úÖ Faithfulness (score: 0.5, threshold: 0.5, strict: False, evaluation model: llama3:latest (Ollama), reason: The score is 0.50 because the actual output contradicts the retrieval context by discussing specific approaches to managing machine learning models, Champion-Challenger model validation, monitoring and evaluation of performance, scenarios where new models replace existing ones, minimizing risks when introducing new models, and critical environments for changes, which are not mentioned in the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: O que √© um modelo champion vs challenger?\n",
      "  - actual output: Um **modelo Champion vs Challenger** √© uma abordagem estrat√©gica utilizada para gerenciar modelos de machine learning em produ√ß√£o. Nessa abordagem, existem dois modelos:\n",
      "\n",
      "1. **Modelo Champion (Campe√£o)**: O modelo atualmente em produ√ß√£o, que √© confi√°vel e est√° sendo monitorado. Ele √© mantido at√© que seja comprovado que o modelo Challenger ofere√ßa melhorias significativas.\n",
      "\n",
      "2. **Modelo Challenger**: Um novo modelo que est√° sendo testado em paralelo com o Champion. O objetivo √© validar seu desempenho em dados de produ√ß√£o antes de substituir completamente o modelo Champion.\n",
      "\n",
      "### Como funciona?\n",
      "- **Introdu√ß√£o Gradual**: O modelo Challenger √© lan√ßado inicialmente em uma fra√ß√£o de tr√°fego (ou dados) para minimizar riscos.\n",
      "- **Avalia√ß√£o em Produ√ß√£o**: Seu desempenho √© monitorado cuidadosamente usando m√©tricas como precis√£o, recall e m√©tricas de neg√≥cios relevantes.\n",
      "- **Decis√£o Bin√°ria**: Se o Challenger demonstrar consistentemente melhor desempenho, ele pode ser promovido ao papel de Champion. Caso contr√°rio, o Champion permanece como modelo principal.\n",
      "\n",
      "### Por que essa abordagem?\n",
      "- **Redu√ß√£o de Riscos**: Evita impactos negativos imediatos ao mudar repentinamente para um modelo inacredit√°vel.\n",
      "- **Valida√ß√£o Pr√°tica**: Garante que o modelo funcione bem em condi√ß√µes reais, e n√£o apenas em dados de treino.\n",
      "\n",
      "Essa pr√°tica √© especialmente √∫til em ambientes cr√≠ticos, onde mudan√ßas indireitas podem ter consequ√™ncias severas.\n",
      "  - expected output: O modelo champion √© o atual em produ√ß√£o, enquanto challengers s√£o avaliados como potenciais substitutos.\n",
      "  - context: None\n",
      "  - retrieval context: ['more expensive to analyze improvements to that model in the f uture. The cost increases when\\ncorrection models are cascaded, with a model for problem A‚Ä≤‚Ä≤learned on top of m‚Ä≤\\na, and so on,\\nfor several slightly different test distributions. Once in place, a correction cascade can create an\\nimprovement deadlock, as improving the accuracy of any indi vidual component actually leads to\\nsystem-level detriments. Mitigation strategies are to aug mentmato learn the corrections directly\\nwithin the same model by adding features to distinguish amon g the cases, or to accept the cost of\\ncreating a separate model for A‚Ä≤.\\nUndeclared Consumers. Oftentimes, a prediction from a machine learning model mais made\\nwidely accessible, either at runtime or by writing to Ô¨Åles or logs that may later be consumed by\\nother systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,', 'other systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,\\nthese issues are referred to as visibility debt .\\nUndeclared consumers are expensive at best and dangerous at worst, because they create a hidden\\ntight coupling of model mato other parts of the stack. Changes to mawill very likely impact these\\nother parts, potentially in ways that are unintended, poorl y understood, and detrimental. In practice,\\nthis tight coupling can radically increase the cost and difÔ¨Å culty of making any changes to maat all,\\neven if they are improvements. Furthermore, undeclared con sumers may create hidden feedback\\nloops, which are described more in detail in section 4.\\n2\\nUndeclared consumers may be difÔ¨Åcult to detect unless the sy stem is speciÔ¨Åcally designed to guard', 'Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track', 'this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps', 'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios. Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment. Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\n\\nModel deployment']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 100.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
       "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
       "¬ª \u001b]8;id=766391;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53.</span>97s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m53.\u001b[0m97s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6396524110809825,\n",
       "    'reason': \"The score is 0.64 because irrelevant nodes (nodes 2, 4, 6, and 8) are correctly ranked lower than relevant nodes, as they lack direct connections to the expected output of defining MLOps. The first node's relevance is evident from its mention of 'MLOps', while subsequent 'yes' verdicts provide more specific explanations aligning with the expected output.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'MLOps\\' which is directly related to the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about what MLOps is, it only provides a definition and explanation of its importance.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that MLOps combines practices from Machine Learning, DevOps, and software engineering to manage the ML lifecycle, which aligns with the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the importance of MLOps in managing the ML lifecycle.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that MLOps enables a more seamless and efficient integration of ML into existing processes, which aligns with the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about how MLOps achieves this efficiency.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that MLOps incorporates best practices and methods used in software development and DevOps, which aligns with the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about how these best practices are applied in MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that MLOps enables a more coordinated approach to ML projects, which aligns with the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about how this coordination is achieved in MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that MLOps optimizes resources and reduces risk, which aligns with the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about how MLOps achieves this optimization.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that MLOps enables businesses to leverage data more effectively, enhancing their decision-making processes and achieving better outcomes in the competitive marketplace, which aligns with the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about how MLOps achieves this effectiveness.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5384615384615384,\n",
       "    'reason': 'The score is 0.54 because the contextual recall score indicates that most sentences can be attributed to nodes in the retrieval context, but not all, suggesting a good match between expected output and retrieval context, with some minor discrepancies.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 1st node in the retrieval context, which mentions \\'MLOps \\\\u00e9 a disciplina que combina pr\\\\u00e1ticas de Machine Learning, DevOps e engenharia de software para gerenciar o ciclo de vida completo de modelos...\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 2nd node in the retrieval context, which mentions \\'This integration ensures a streamlined and efficient development process, ultimately leading to more reliable AI applications and lower maintenance costs.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 3rd node in the retrieval context, which mentions \\'To summarise, ML Ops builds upon DevOps principles and customises them to suit the unique challenges of machine learning projects...\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 4th node in the retrieval context, which mentions \\'Model Development and Deployment\\'...\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 5th node in the retrieval context, which mentions \\'Want to become an ML Ops master? Sign up to the ML Ops Now newsletter...\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 6th node in the retrieval context, which mentions \\'Unlock your future in ML Ops with Navigating ML Ops: A Beginner\\'s Blueprint...\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 7th node in the retrieval context, which mentions \\'MLOps is more than just the technical side of ML lifecycle management; it also incorporates best practices and methods used in software development...\\' \"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7948717948717948,\n",
       "    'reason': 'The score is 0.79 because the retrieval context contains relevant statements that discuss the definition of MLOps, its relationship with DevOps, and its importance in managing machine learning projects, despite some irrelevant information present.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"What is ML Ops? Demystif ying Machine Learning Operations\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Unlock your future in ML Ops with Navigating ML Ops: A Beginner\\' s Bluepr int.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Mast ering ML Ops: The K ey to a Successful ML Ops Car eer\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The ML Ops Platform: R evolutionising Machine Learning Efficiency\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The ML Ops Lifecy cle: A Concise Guide t o Streamlining AI and Machine Learning Pr ojects\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Other ar ticles y ou might be int erested in:\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"\\\\\"ar ticles\\\\\" and \\\\\"int erested in\\\\\" are not relevant to the input \\'What is MLOps?\\'\"\\n            },\\n            {\\n                \"statement\": \"Follow me on Twitter: @huwdev \\\\u00a9 MLOps 2024 - Built by Huw Fulcher11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operationshttps://mlopsnow.com/blog/what-is-mlops/ 11/11\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"\\\\\"Follow me on Twitter\\\\\" and other irrelevant information\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"accommodate the ML lifecycle.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This integration ensures a streamlined and efficient development process, ultimately leading to more reliable AI applications and lower maintenance costs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML Ops builds upon DevOps principles and customises them to suit the unique challenges of machine learning projects, thus enabling a more seamless and efficient management of these projects throughout their lifecycle.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations https://mlopsnow.com/blog/what-is-mlops/ 4/11\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For a more in-depth look at ML Ops vs DevOps check out our other blog post.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model Development and Deployment\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model Creation\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model creation is an essential part of the ML Ops process, focused on developing machine learning models based on specific requirements.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In this phase, data engineers work together with data scientists to prepare and preprocess the data, performing feature engineering to ensure the\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"What is ML Ops? Demystifying Machine Learning Operations\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Mast ering ML Ops: The K ey to a Successful ML Ops Car eer\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The ML Ops Platform: R evolutionising Machine Learning Efficiency\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The ML Ops Lifecy cle: A Concise Guide t o Streamlining AI and Machine Learning Pr ojects\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Mast ering ML Ops: ML Ops Best Practices and Challenges\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Follow me on Twitter: @huwdev \\\\u00a9 MLOps 2024 - Built by Huw Fulcher11/11/25, 10:04 PM MLOps Now - MLOps Best Practices and Challengeshttps://mlopsnow.com/blog/mlops-best-practices-and-challenges/ 7/7\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"seamless and efficient integration of ML into existing processes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps is more than just the technical side of ML lifecycle management;\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"it also incorporates best practices and methods used in software development and DevOps.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Bridging the gap between data scientists, ML engineers, and DevOps, ML Ops enables a more coordinated approach to ML projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Teams can more easily track, reproduce, and iterate on models, ensuring stability and performance in production environments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By adopting an ML Ops approach, organisations not only position themselves for better scalability and faster deployment of ML models, but also optimise resources and reduce risk.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"As a result, businesses can leverage data more effectively, enhancing their decision-making processes and achieving better outcomes in the competitive marketplace.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Fundamentals of ML Ops\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Machine Learning Operations\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps stands for Machine L earning Oper ations . It is an IT practice that\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Handling concerns about model fairness and adversarial attacks.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps is a methodology for ML engineering that unifies ML system development (the ML element) with ML system operations (the Ops element).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It advocates formalizing and (when beneficial) automating critical steps of ML system construction.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps provides a set of standardized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps supports ML development and deployment in the way that DevOps and DataOps support application engineering and data engineering (analytics).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The difference is that when you deploy a web service, you care about resilience, queries per second, load balancing, and so on.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'resilience\\' when it has nothing to do with MLOps.\"\\n            },\\n            {\\n                \"statement\": \"When you deploy an ML model, you also need to worry about changes in the data, changes in the model, users trying to game the system, and so on.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the answer directly addresses the question about what MLOps is, making it highly relevant and leaving no room for improvement.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"MLOps is a set of practices and methodologies for managing the life cycle of Machine Learning projects.\",\\n    \"It emerged from the need to standardize and automate specific processes in ML, such as development, implementation, and maintenance of models.\",\\n    \"MLOps combines elements of DevOps and DataOps to ensure that ML systems are developed, implemented, and operated efficiently and reliably.\",\\n    \"This includes standardizing processes, automating critical tasks, and creating a more coordinated approach between data scientists, ML engineers, and DevOps teams.\",\\n    \"MLOps helps reduce risks, optimize resources, and ensure that ML models function stably in production environments, allowing organizations to better utilize their data and improve decision-making processes.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"MLOps stands for Machine Learning Operations.\",\\n    \"MLOps is an IT practice that unifies ML system development with ML system operations.\",\\n    \"MLOps advocates formalizing and automating critical steps of ML system construction.\",\\n    \"MLOps provides a set of standardized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably.\",\\n    \"MLOps supports ML development and deployment in the way that DevOps and DataOps support application engineering and data engineering (analytics).\",\\n    \"The difference between MLOps and other Ops practices is that MLOps also needs to worry about changes in the data, changes in the model, users trying to game the system, and so on.\",\\n    \"ML Ops builds upon DevOps principles and customises them to suit the unique challenges of machine learning projects.\",\\n    \"ML Ops enables a more coordinated approach to ML projects by bridging the gap between data scientists, ML engineers, and DevOps.\",\\n    \"ML Ops provides a seamless and efficient integration of ML into existing processes.\",\\n    \"ML Ops optimizes resources and reduces risk by adopting an ML Ops approach.\",\\n    \"Organisations can leverage data more effectively and enhance their decision-making processes by adopting an ML Ops approach.\",\\n    \"MLOps is not just the technical side of ML lifecycle management; it also incorporates best practices and methods used in software development and DevOps.\"\\n] \\n \\nClaims:\\n[\\n    \"MLOps is a set of practices and methodologies focused on managing the lifecycle of Machine Learning (ML) projects.\",\\n    \"The MLOps emerged from the need to standardize and automate specific ML processes, such as development, implementation, and maintenance of models, which are different from challenges faced in traditional software or data projects.\",\\n    \"MLOps combines elements of DevOps and DataOps to ensure that ML systems are developed, implemented, and operated efficiently and reliably.\",\\n    \"The MLOps includes standardization of processes, automation of critical tasks, and creation of a more coordinated approach between data science teams, ML engineers, and DevOps teams.\",\\n    \"MLOps helps reduce risks, optimize resources, and ensure that ML models function stably in production environments, allowing organizations to better utilize their data and improve decision-making processes.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© MLOps?',\n",
       "  'actual_output': 'MLOps √© um conjunto de pr√°ticas e metodologias voltadas para gerenciar o ciclo de vida dos projetos de Machine Learning (ML). Ele surgiu da necessidade de padronizar e automatizar processos espec√≠ficos do ML, como o desenvolvimento, implanta√ß√£o e manuten√ß√£o de modelos, que s√£o diferentes dos desafios enfrentados em projetos tradicionais de software ou dados.\\n\\nEm resumo, o MLOps une elementos de DevOps e DataOps para garantir que os sistemas de ML sejam desenvolvidos, implantados e operados de forma eficiente e confi√°vel. Isso inclui a padroniza√ß√£o de processos, automa√ß√£o de tarefas cr√≠ticas e a cria√ß√£o de uma abordagem mais coordenada entre equipes de cientistas de dados, engenheiros de ML e DevOps.\\n\\nAl√©m disso, o MLOps ajuda a reduzir riscos, otimizar recursos e garantir que os modelos ML funcionem de forma est√°vel em ambientes de produ√ß√£o, permitindo que organiza√ß√µes aproveitem melhor os dados e melhorem seus processos de decis√£o. üòä',\n",
       "  'expected_output': 'MLOps √© a disciplina que combina pr√°ticas de Machine Learning, DevOps e engenharia de software para gerenciar o ciclo de vida completo de modelos, desde desenvolvimento at√© monitoramento e manuten√ß√£o cont√≠nua.',\n",
       "  'context': None,\n",
       "  'retrieval_context': [\"Unlock your future in ML Ops with Navigating ML Ops: A\\nBeginner' s Bluepr int.\\nOther ar ticles y ou might be int erested in:\\nMast ering ML Ops: The K ey to a Successful ML Ops Car eer\\nThe ML Ops Platform: R evolutionising Machine Learning Efficiency\\nThe ML Ops Lifecy cle: A Concise Guide t o Streamlining AI and\\nMachine Learning Pr ojects\\nWhat is ML Ops? Demystif ying Machine Learning Operations11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations\\nhttps://mlopsnow.com/blog/what-is-mlops/ 10/11\\nMast ering ML Ops: ML Ops Best Practices and Challenges\\nFollow me on Twitter: @huwdev ¬© MLOps 2024 - Built by Huw Fulcher11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations\\nhttps://mlopsnow.com/blog/what-is-mlops/ 11/11\",\n",
       "   'accommodate the ML lifecycle. This integration ensures a streamlined and\\nefficient development process, ultimately leading to more reliable AI\\napplications and lower maintenance costs.\\nTo summarise, ML Ops builds upon DevOps principles and customises them\\nto suit the unique challenges of machine learning projects, thus enabling a\\nmore seamless and efficient management of these projects throughout\\ntheir lifecycle.11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations\\nhttps://mlopsnow.com/blog/what-is-mlops/ 4/11\\nFor a more in-depth look at ML Ops vs DevOps check out our other blog\\npost. .\\nModel Dev elopment and Deployment\\nModel Cr eation\\nModel creation is an essential part of the ML Ops process, focused on\\ndeveloping machine learning models based on specific requirements. In\\nthis phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the',\n",
       "   \"Want t o become an ML Ops mast er? Sign up t o the ML Ops Now\\nnewslett er to get w eekly ML Ops insights.11/11/25, 10:04 PM MLOps Now - MLOps Best Practices and Challenges\\nhttps://mlopsnow.com/blog/mlops-best-practices-and-challenges/ 6/7\\nUnlock your future in ML Ops with Navigating ML Ops: A\\nBeginner' s Bluepr int.\\nOther ar ticles y ou might be int erested in:\\nMast ering ML Ops: The K ey to a Successful ML Ops Car eer\\nThe ML Ops Platform: R evolutionising Machine Learning Efficiency\\nThe ML Ops Lifecy cle: A Concise Guide t o Streamlining AI and\\nMachine Learning Pr ojects\\nWhat is ML Ops? Demystif ying Machine Learning Operations\\nMast ering ML Ops: ML Ops Best Practices and Challenges\\nFollow me on Twitter: @huwdev ¬© MLOps 2024 - Built by Huw Fulcher11/11/25, 10:04 PM MLOps Now - MLOps Best Practices and Challenges\\nhttps://mlopsnow.com/blog/mlops-best-practices-and-challenges/ 7/7\",\n",
       "   'seamless and efficient integration of ML into existing processes.\\nMLOps is more than just the technical side of ML lifecycle management; it\\nalso incorporates best practices and methods used in software\\ndevelopment and DevOps. Bridging the gap between data scientists, ML\\nengineers, and DevOps, ML Ops enables a more coordinated approach to\\nML projects. T eams can more easily track, reproduce, and iterate on\\nmodels, ensuring stability and performance in production environments.\\nBy adopting an ML Ops approach, organisations not only position\\nthemselves for better scalability and faster deployment of ML models, but\\nalso optimise resources and reduce risk. As a result, businesses can\\nleverage data more effectively, enhancing their decision-making processes\\nand achieving better outcomes in the competitive marketplace.\\nFundamentals o f ML Ops\\nMachine Learning Operations\\nMLOps stands for Machine L earning Oper ations . It is an IT practice that',\n",
       "   '‚Ä¢ Handling concerns about model fairness and adversarial attacks.\\nMLOps is a methodology for ML engineering that unifies ML system development (the ML element) with ML system \\noperations (the Ops element). It advocates formalizing and (when beneficial) automating critical steps of ML system \\nconstruction. MLOps provides a set of standardized processes and technology capabilities for building, deploying, \\nand operationalizing ML systems rapidly and reliably.\\nMLOps supports ML development and deployment in the way that DevOps and DataOps support application engi -\\nneering and data engineering (analytics). The difference is that when you deploy a web service, you care about resil -\\nience, queries per second, load balancing, and so on. When you deploy an ML model, you also need to worry about \\nchanges in the data, changes in the model, users trying to game the system, and so on. This is what MLOps is about.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7555555555555555,\n",
       "    'reason': \"The score is 0.76 because irrelevant nodes (nodes 2 and 4) are correctly ranked lower than relevant nodes (nodes 1 and 3), as they don't provide information about the differences between a Data Scientist and an ML Engineer, which is crucial to understanding the question.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions MLOps and its relation to data science projects, which is relevant to understanding the difference between a Data Scientist and an ML Engineer.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the differences between a Data Scientist and an ML Engineer.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains the development lifecycle of data science projects, which is relevant to understanding MLOps and its role in the process.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the differences between a Data Scientist and an ML Engineer.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context provides examples of MLOps practices and challenges, which is relevant to understanding the role of an ML Engineer in the process.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the contextual recall score indicates that the expected output can be partially attributed to nodes in retrieval context, but not entirely, suggesting a moderate level of relevance between the two.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node (To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node (A typical data science project consists of several stages: ...)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node (MLOps Engineer vs Data Scientist: What\\'s the difference?)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node (Similarly, Xin et al. analyze ML pipelines at Google to understand typical model configurations and retraining patterns.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node (Polyzotis et al. survey challenges centric to data management for machine learning deployments.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node (Paleyes et al. re-view published reports of individual ML deployments and survey common challenges.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node (Our study instead focuses on issues across the production workflow (i.e., MLOps practices and challenges) as opposed to individual pain-points, identified by interviewing those who are most affected by it\\\\u2014the ML engineers.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"8th node (Kandel et al. interview data analysts at enterprises, focusing on broader organizational contexts like we do; however, MLOps workflows and challenges extend beyond data analysis.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"9th node (Other studies build on Kandel et al.\\\\u2019s work, exploring aspects such as collaboration, code practices, and tools, all centered on general data analysis and data science, as opposed to transitioning)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"10th node (Therefore, many businesses are investing in their data science teams and ML capabilities to develop predictive models that can deliver business value to their users.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"11th node (This document is for data scientists and ML engineers who want to apply DevOps principles to ML systems (MLOps). MLOps is an ML engineering culture and practice that aims at unifying ML system development (Dev) and ML system operation (Ops).)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"12th node (Practicing MLOps means that you advocate for automation and monitoring at all steps of ML system construction, including integration, testing, releasing, deployment and infrastructure management.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"13th node (Data scientists can implement and train an ML model with predictive performance on an offline holdout dataset, given relevant training data for their use case.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"14th node (However, the real challenge isn\\'t building an ML model, the challenge is building an integrated ML system and)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"15th node (ML development\\\\nExperimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for data preparation and ML modeling.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8,\n",
       "    'reason': \"The score is 0.80 because the input question about the difference between MLOps and Data Scientist is well-represented in the retrieval context statements that discuss the development lifecycle of data science projects, ML system construction, and the challenges faced by ML engineers. For example, statement 'To understand ML Ops, it‚Äôs essential to be familiar with the development lifecycle of data science projects.' directly relates to the input question, while other relevant statements like 'Practicing MLOps means that you advocate for automation and monitoring at all steps of ML system construction...' provide context on what MLOps entails. The contextual relevancy score is high because the retrieval context effectively addresses the input question's focus on the differences between MLOps and Data Scientist.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A typical data science project consists of several stages: 1. Data acquisition: Obtaining raw data from various sources, such as databases, sensors, or external APIs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"2. Data preprocessing: Cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"3. Feature engineering: Selecting the most relevant data attributes, or \\\\u201cfeatures,\\\\u201d and converting them into a suitable format for ML algorithms.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Model training: Applying ML algorithms to the preprocessed data to create a predictive model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"5. Model evaluation: Assessing the performance of the model and making adjustments to improve its accuracy.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"6. Model deployment: Implementing the ML model into a product, service, or system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"7. Monitoring and maintenance: Continuously monitoring the performance of the ML model and updating it as needed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"ML Engineer vs Data Scientist: What\\' s the differ ence?\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps Engineer vs Data Scientist: What\\' s the differ ence?\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps Engineer vs ML Engineer : What\\' s the differ ence?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"ML platform . Similarly, Xin et al. analyze ML pipelines at Google to understand typical model configurations and retraining patterns.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Polyzotis et al. survey challenges centric to data management for machine learning deployments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Paleyes et al. re-review published reports of individual ML deployments and survey common challenges .\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Our study instead focuses on issues across the production workflow (i.e., MLOps practices and challenges) as opposed to individual pain-points, identified by interviewing those who are most affected by it\\\\u2014the ML engineers.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data Science and ML-Related Interview Studies. Kandel et al. interview data analysts at enterprises, focusing on broader organizational contexts like we do; however, MLOps workflows and challenges extend beyond data analysis.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Other studies build on Kandel et al.\\\\u2019s work, exploring aspects such as collaboration, code practices, and tools , all centered on general data analysis and data science, as opposed to transitioning\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Therefore, many businesses are investing in their data science teams and ML capabilities\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This document is for data scientists and ML engineers who want to apply DevOps principles to ML systems (MLOps)\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Practicing MLOps means that you advocate for automation and monitoring at all steps of ML system construction, including integration, testing, releasing, deployment and infrastructure management.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data scientists can implement and train an ML model with predictive performance on an offline holdout dataset, given relevant training data for their use case.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"However, the real challenge isn\\'t building an ML model, the challenge is building an integrated ML system\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"subset of MLOps capability services.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML development\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Experimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for data preparation and ML modeling.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Experimentation starts when the ML use case is well defined, meaning that the following questions have been answered:\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 What is the task?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 How can we measure business impact?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 What is the evaluation metric?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 What is the relevant data?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 What are the training and serving requirements?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Figure 5. The ML development process\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"17\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 What is the task?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"During experimentation, data scientists typically perform the following steps:\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 0.8571428571428571,\n",
       "    'reason': 'The score is 0.86 because the response effectively addressed the main question, providing a clear distinction between MLOps and Data Scientist. Although there might be some minor tangents or unnecessary details, they do not significantly detract from the overall relevance of the answer.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"MLOps and Data Scientist are two distinct functions/areas in the Machine Learning ecosystem.\",\\n    \"MLOps is a practice of engineering focused on managing and operating Machine Learning systems in production.\",\\n    \"MLOps focuses on automation, maintenance, and infrastructure/deployment of models.\",\\n    \"MLOps ensures that models created by Data Scientists are operationalized, scalable, and monitored in production.\",\\n    \"A Data Scientist is a data scientist who concentrates on creating and validating Machine Learning models.\",\\n    \"Data Scientist\\'s main tasks include analyzing data, selecting features, developing and training predictive models, and evaluating model performance.\",\\n    \"The Data Scientist creates the \\'cheese\\' (model), while MLOps ensures that the model functions well in everyday life, like in a production system.\",\\n    \"MLOps and Data Scientist are complementary functions with different focuses: one on developing the model and another on maintaining and operating it.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement is about the role of a Data Scientist, but it does not directly address the difference between MLOps and Data Scientist.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5714285714285714,\n",
       "    'reason': \"The score is 0.57 because the actual output contradicts the retrieval context by defining a Data Scientist's role in terms of creating and validating Machine Learning models, which is not mentioned in the context, and also highlights differences between Data Scientists and MLOps that are unrelated to Einstein winning a Nobel Prize.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"Einstein won the noble prize for his discovery of the photoelectric effect in 1968.\",\\n    \"The photoelectric effect is a phenomenon that laid the foundation for quantum mechanics.\"\\n] \\n \\nClaims:\\n[\\n    \"MLOps is a practice of engineering focused on the management and operation of Machine Learning systems in production.\",\\n    \"MLOps automates processes such as integration, testing, deployment, and monitoring of models.\",\\n    \"MLOps ensures that models are maintained continuously to ensure they function well over time.\",\\n    \"MLOps provides infrastructure and deployment for models in real systems.\",\\n    \"A Data Scientist is a data scientist who focuses on creating and validating Machine Learning models.\",\\n    \"A Data Scientist\\'s main tasks include analyzing data, selecting features, developing and training predictive models, and evaluating model performance.\",\\n    \"A Data Scientist is responsible for creating the \\'model\\' (model), while MLOps ensures that the model functions well in everyday use, like a system in production.\",\\n    \"The main difference between Data Scientist and MLOps is that a Data Scientist creates the model, while MLOps ensures it works well in daily operation.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim defines a Data Scientist as someone who focuses on creating and validating Machine Learning models, which contradicts the retrieval context that does not mention this specific role.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim states that A Data Scientist is responsible for creating the \\'model\\', while MLOps ensures it works well in daily operation. This directly contradicts the retrieval context, which mentions Einstein winning a Nobel Prize and has no connection to Machine Learning or Data Science.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim highlights the main difference between Data Scientist and MLOps as creating the model versus ensuring it works well in daily operation. This directly contradicts the retrieval context, which mentions Einstein winning a Nobel Prize and has no connection to Machine Learning or Data Science.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'Qual a diferen√ßa entre MlOps e Data Scientist?',\n",
       "  'actual_output': 'MLOps (Machine Learning Operations) e Data Scientist s√£o duas fun√ß√µes/√°reas distintas no ecossistema de Machine Learning, embora complementares. Veja a diferen√ßa:\\n\\n### **MLOps (Machine Learning Operations):**\\n- **O que √©:** MLOps √© uma pr√°tica de **engenharia** voltada para a **gest√£o e opera√ß√£o de sistemas de Machine Learning** em produ√ß√£o. √â como um \"DevOps\" para ML, focando em:\\n  - **Automatiza√ß√£o** de processos como integra√ß√£o, teste, implanta√ß√£o e monitoramento de modelos.\\n  - **Manuten√ß√£o** cont√≠nua dos modelos, garantindo que eles funcionem bem ao longo do tempo.\\n  - **Infraestrutura** e **deployment** dos modelos em sistemas reais.\\n\\n- **Papel:** Garante que os modelos criados pelos Data Scientists sejam **operacionalizados, escal√°veis e monitorados** em ambiente de produ√ß√£o.\\n\\n### **Data Scientist:**\\n- **O que √©:** Um Data Scientist √© um **cientista de dados** que se concentra em **criar e validar modelos de Machine Learning**. Suas principais tarefas incluem:\\n  - **An√°lise de dados** e **sele√ß√£o de features**.\\n  - **Desenvolvimento** e **treinamento** de modelos preditivos.\\n  - **Evalu√ß√£o** do desempenho dos modelos.\\n\\n- **Papel:** Respons√°vel pela **cria√ß√£o do \"queijo\" (modelo)**, enquanto o MLOps cuida de como ele ser√° \"comido\" (implantado e mantido) em larga escala.\\n\\n### **Diferen√ßa Principal:**\\n- **Data Scientist** cria o modelo, enquanto **MLOps** garante que o modelo funcione bem no dia a dia, como em um sistema de produ√ß√£o. S√£o fun√ß√µes complementares, mas com focos diferentes: um no **desenvolvimento do modelo** e outro na sua **manuten√ß√£o e opera√ß√£o**.',\n",
       "  'expected_output': 'A diferen√ßa entre um Data Scientist e um ML Engineer √© que o primeiro se concentra em desenvolver modelos de aprendizado autom√°tico, enquanto o segundo se concentra na engenharia da constru√ß√£o e implanta√ß√£o desses modelos.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.',\n",
       "   \"ML Engineer vs Data Scientist: What' s the differ ence?\\nMLOps Engineer vs Data Scientist: What' s the differ ence?\\nMLOps Engineer vs ML Engineer : What' s the differ ence?\\nFollow me on Twitter: @huwdev ¬© MLOps 2024 - Built by Huw Fulcher11/11/25, 10:05 PM MLOps Now - ML Engineer vs Data Scientist\\nhttps://mlopsnow.com/blog/ml-engineer-vs-data-scientist/ 4/4\",\n",
       "   'ML platform . Similarly, Xin et al. analyze ML pipelines at\\nGoogle to understand typical model configurations and retraining\\npatterns. Polyzotis et al. survey challenges centric to data\\nmanagement for machine learning deployments. Paleyes et al. re-\\nview published reports of individual ML deployments and survey\\ncommon challenges . Our study instead focuses on issues across\\nthe production workflow (i.e., MLOps practices and challenges) as\\nopposed to individual pain-points, identified by interviewing those\\nwho are are most affected by it‚Äîthe ML engineers.\\nData Science and ML-Related Interview Studies. Kandel et\\nal. interview data analysts at enterprises, focusing on broader\\norganizational contexts like we do; however, MLOps workflows\\nand challenges extend beyond data analysis. Other studies build\\non Kandel et al.‚Äôs work, exploring aspects such as collaboration,\\ncode practices, and tools , all centered on gen-\\neral data analysis and data science, as opposed to transitioning',\n",
       "   \"Therefore, many businesses are investing in their data science teams and ML capabilities\\nto develop predictive models that can deliver business value to their users.\\nThis document is for data scientists and ML engineers who want to apply DevOps\\n\\xa0(https://cloud.google.com/devops/) principles to ML systems (MLOps). MLOps is an ML\\nengineering culture and practice that aims at unifying ML system development (Dev) and\\nML system operation (Ops). Practicing MLOps means that you advocate for automation\\nand monitoring at all steps of ML system construction, including integration, testing,\\nreleasing, deployment and infrastructure management.\\nData scientists can implement and train an ML model with predictive performance on an\\noffline holdout dataset, given relevant training data for their use case. However, the real\\nchallenge isn't building an ML model, the challenge is building an integrated ML system and\",\n",
       "   'subset of MLOps capability services.\\nML development\\nExperimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for \\ndata preparation and ML modeling. Experimentation starts when the ML use case is well defined, meaning that the \\nfollowing questions have been answered:\\n‚Ä¢ What is the task?\\n‚Ä¢ How can we measure business impact?\\n‚Ä¢ What is the evaluation metric?\\nFigure 5. The ML development process\\n17\\n‚Ä¢ What is the relevant data?\\n‚Ä¢ What are the training and serving requirements?\\nExperimentation aims to arrive at an effective prototype model for the ML use case at hand. In addition to experimen -\\ntation, data scientists need to formalize their ML training procedures. They do this by implementing an end-to-end \\npipeline, so that the procedures can be operationalized and run in production. Figure 5 shows the process of ML \\ndevelopment. \\nDuring experimentation, data scientists typically perform the following steps:'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7555555555555555,\n",
       "    'reason': \"The score is 0.76 because irrelevant nodes are correctly ranked lower than relevant nodes (nodes 2 and 4) as they don't provide direct answers to the question about the differences between MLOps and DevOps, while nodes 1 and 3 offer valuable insights into the topic.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"This document clearly explains the concept of MLOps and its relationship to DevOps, making it relevant to the question about the differences between the two.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information that directly answers the question about the key elements of an effective MLOPs strategy.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"This document provides a detailed explanation of the concepts to consider when setting up an MLOps environment, making it relevant to the topic.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text is not directly related to the question about the differences between MLOPs and DevOps.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"This document provides a clear definition of MLOps and its relationship to DevOps, making it relevant to the topic.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5555555555555556,\n",
       "    'reason': 'The score is 0.56 because the contextual recall score indicates that most sentences in the expected output can be attributed to nodes in the retrieval context, but some sentences remain unconnected, suggesting that there are still areas where the information does not align with the provided context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'MLOps establishes a defined and scalable development process, ensuring consistency, reproducibility and governance throughout the ML lifecycle.\\' This sentence can be attributed to the nodes of retrieval contexts.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific node in the retrieval context is directly related to this sentence. It\\'s a general statement about MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'MLOps and DevOps focus on different aspects of the development process.\\' This sentence can be attributed to the nodes of retrieval contexts, specifically the part that compares MLOPs and DevOps.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific node in the retrieval context is directly related to this sentence. It\\'s a general statement about similarities between MLOPs and DevOps.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'MLOps builds upon DevOps principles and applies them to the machine learning lifecycle.\\' This sentence can be attributed to the nodes of retrieval contexts, specifically the part that explains the relationship between MLOPs and DevOps.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific node in the retrieval context is directly related to this sentence. It\\'s a general statement about key elements of an effective MLOps strategy.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'This document covers concepts to consider when setting up an MLOps environment for your data science practices...\\' This sentence can be attributed to the nodes of retrieval contexts, specifically the part that discusses setting up an MLOPs environment.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific node in the retrieval context is directly related to this sentence. It\\'s a general statement about DevOps versus MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'MLOps, short for machine learning operations, is a set of practices designed to create an assembly line for building and running machine learning models.\\' This sentence can be attributed to the nodes of retrieval contexts, specifically the part that defines MLOPs.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.9354838709677419,\n",
       "    'reason': \"The score is 0.94 because the retrieval context provides relevant statements that directly address the difference between MLOps and DevOps, such as 'MLOps establishes a defined and scalable development process...' and 'DevOps focuses on streamlining the development, testing and deployment of traditional software applications.' These statements demonstrate a clear understanding of both concepts and their distinct differences.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"MLOps establishes a defined and scalable development process, ensuring consistency, reproducibility and governance throughout the ML lifecycle.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Manual deployment and monitoring are slow and require significant human effort, hindering scalability.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without proper centralized monitoring, individual models might experience performance issues that go unnoticed, impacting overall accuracy.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"DevOps focuses on streamlining the development, testing and deployment of traditional software applications.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It emphasizes collaboration between development and operations teams to automate processes and improve software delivery speed and quality.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps builds upon DevOps principles and applies them to the machine learning lifecycle.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It goes beyond deploying code, encompassing data management, model training, monitoring and continuous improvement.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"strategic in their decision-making.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Both MLOps and DevOps share a need for process automation, continuous integration, and continuous delivery .\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It also helps to have proper testing of the code base for both MLOPs and DevOps.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In addition, there should be adequate collaboration between software developers and those who manage the infrastructure, as well as other stakeholders.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Although MLOps is derived from DevOps, there are subtle dif ferences between the two.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In MLOps, data is a necessary input for developing the machine learning model. But in DevOps, data is an output of the program, not an input.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In MLOPs, the model must be validated continuously in production for performance deterioration caused by new data over time. The software system does not deteriorate in DevOps; it is merely monitored for health maintenance purposes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"MLOps requires skills, tools and practices to effectively manage the machine learning lifecycle.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps teams need a diverse skillset encompassing both technical and soft skills.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"They must understand the entire data science pipeline, from data preparation and model training to evaluation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Familiarity with software engineering practices like version control, CI/CD pipelines and containerization are also crucial.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In addition, knowledge of DevOps principles, infrastructure management and automation tools is essential for the efficient deployment and operation of ML models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"MLOps: Continuous delivery and automation pipelines in machine learning\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"DevOps versus MLOps\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Steps for developing ML models\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps maturity levels\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MlOps for generative AI\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"DevOps\\\\u00a0(https://cloud.google.com/devops/) is a popular practice in developing and operating large-scale software systems.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This practice provides benefits such as shortening the development cycles, increasing deployment velocity, and dependable releases.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"To achieve these benefits, you introduce two concepts in the software system development:\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"\\\\\"you introduce two concepts\\\\\" is not directly related to the difference between MLOps and DevOps.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"What is MLOps?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps, short for machine learning operations, is a set of practices designed to create an assembly line for building and running machine learning models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The term MLops is a combination of machine learning (ML) and DevOps.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Creating an MLOps process incorporates continuous integration and continuous delivery (CI/CD) methodology from DevOps to create an assembly line for each step in creating a machine learning product.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about the difference between MLOps and DevOps, making it highly relevant to the input.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"**MLOps** and **DevOps** differ in their focuses and applications within software development, specifically in the context of Machine Learning (ML).\",\\n    \"Both share common principles such as automation, continuous integration, and delivery.\",\\n    \"They require collaboration between teams (development, operations, infrastructure, etc.).\",\\n    \"They use practices like CI/CD (Continuous Integration/Continuous Delivery).\",\\n    \"**DevOps** focuses on traditional software development, optimizing development, deployment, and maintenance cycles.\",\\n    \"**MLOps** emerged from DevOps principles but specializes in managing the Machine Learning lifecycle, including data, model training, validation, and monitoring in production.\",\\n    \"In **DevOps**, data is an output of the system (e.g., logs, performance metrics).\",\\n    \"In **MLOps**, data is essential input for models, requiring specific management (cleaning, versioning, etc.).\",\\n    \"**DevOps** monitoring is focused on system health (e.g., uptime, performance).\",\\n    \"**MLOps** requires continuous model validation to detect degradation of performance due to changes in data or environment.\",\\n    \"MLOps is like DevOps but with a special focus on Machine Learning. It incorporates good practices from DevOps and adds extra layers for handling data, models, and continuous validation.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"While it mentions DevOps, the statement is primarily focused on explaining MLOps and its differences with DevOps.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement only highlights a difference between MLOps and DevOps, but does not provide specific information about the input (what is the difference between MLOps and DevOps?).\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement only explains what MLOps does, but does not provide information about how it relates to the input (what is the difference between MLOps and DevOps?).\"\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5833333333333334,\n",
       "    'reason': \"The score is 0.58 because the actual output contradicts the retrieval context in several ways: it implies that MLOps and DevOps have different focuses within software development, specifically mentioning Machine Learning (ML), whereas the retrieval context only discusses MLOps' focus on managing the ML lifecycle; it also suggests that data management is essential in MLOps, but the retrieval context only mentions data as a necessary input for developing machine learning models without providing specific details about its management.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"MLOps establishes a defined and scalable development process, ensuring consistency, reproducibility and governance throughout the ML lifecycle.\",\\n    \"Manual deployment and monitoring are slow and require significant human effort, hindering scalability.\",\\n    \"Without proper centralized monitoring, individual models might experience performance issues that go unnoticed, impacting overall accuracy.\",\\n    \"MLOps builds upon DevOps principles and applies them to the machine learning lifecycle.\",\\n    \"It emphasizes collaboration between development and operations teams to automate processes and improve software delivery speed and quality.\",\\n    \"MLOps goes beyond deploying code, encompassing data management, model training, monitoring and continuous improvement.\",\\n    \"Both MLOps and DevOps share a need for process automation, continuous integration, and continuous delivery .\",\\n    \"There should be adequate collaboration between software developers and those who manage the infrastructure, as well as other stakeholders.\",\\n    \"In MLOPs, data is a necessary input for developing the machine learning model. But in DevOps, data is an output of the program, not an input.\",\\n    \"The model must be validated continuously in production for performance deterioration caused by new data over time.\",\\n    \"MLOps requires skills, tools and practices to effectively manage the machine learning lifecycle.\",\\n    \"MLOps teams need a diverse skillset encompassing both technical and soft skills.\",\\n    \"They must understand the entire data science pipeline, from data preparation and model training to evaluation.\",\\n    \"Familiarity with software engineering practices like version control, CI/CD pipelines and containerization are also crucial.\",\\n    \"Knowledge of DevOps principles, infrastructure management and automation tools is essential for the efficient deployment and operation of ML models.\"\\n] \\n \\nClaims:\\n[\\n    \"MLOps and DevOps share common principles such as automation, continuous integration, and delivery.\",\\n    \"Both MLOps and DevOps aim to automate processes and improve the speed and quality of development.\",\\n    \"Both require collaboration between teams (development, operations, infrastructure, etc.).\",\\n    \"Both utilize practices like CI/CD (Continuous Integration/Continuous Delivery).\",\\n    \"MLOps focuses on the management of the Machine Learning lifecycle, including data, model training, validation, and monitoring in production.\",\\n    \"Differentiation lies in their focus and applications within software development, specifically in the context of Machine Learning (ML).\",\\n    \"DevOps focuses on traditional software development, optimizing development, deployment, and maintenance cycles.\",\\n    \"MLOps emerged from DevOps principles but specializes in managing the lifecycle of Machine Learning, including data, model training, validation, and monitoring in production.\",\\n    \"In MLOps, data is an essential input for models, requiring specific management (cleaning, versioning, etc.).\",\\n    \"DevOps treats data as outputs of the system (e.g., logs, performance metrics).\",\\n    \"MLOps requires continuous validation of models to detect degradation of performance due to changes in data or environment.\",\\n    \"MLOps incorporates good practices from DevOps and adds extra layers to handle data, models, and continuous validation.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim states that both MLOps and DevOps aim to automate processes and improve the speed and quality of development, but this is not explicitly stated in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim mentions that MLOps focuses on managing the Machine Learning lifecycle, including data, model training, validation, and monitoring in production. The retrieval context does not explicitly contradict this, but it also does not provide direct evidence to support it.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim states that differentiation lies in their focus and applications within software development, specifically in the context of Machine Learning (ML). However, the retrieval context only discusses MLOps\\' focus on managing the ML lifecycle, without mentioning DevOps\\' specific focus.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim states that DevOps focuses on traditional software development, optimizing development, deployment, and maintenance cycles. The retrieval context does not explicitly contradict this, but it also does not provide direct evidence to support it.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim states that MLOps emerged from DevOps principles but specializes in managing the lifecycle of Machine Learning, including data, model training, validation, and monitoring in production. However, the retrieval context only discusses MLOps\\' focus on managing the ML lifecycle without mentioning its emergence from DevOps.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim states that In MLOps, data is an essential input for models, requiring specific management (cleaning, versioning, etc.). However, the retrieval context only discusses data as a necessary input for developing machine learning models in MLOps, without mentioning its specific management.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim states that DevOps treats data as outputs of the system (e.g., logs, performance metrics). The retrieval context does not explicitly contradict this, but it also does not provide direct evidence to support it.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim states that MLOps requires continuous validation of models to detect degradation of performance due to changes in data or environment. The retrieval context mentions the importance of continuous validation in production for performance deterioration caused by new data over time, but does not explicitly support this.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim states that MLOps incorporates good practices from DevOps and adds extra layers to handle data, models, and continuous validation. The retrieval context discusses the importance of collaboration between development and operations teams, as well as the need for process automation, but does not explicitly support this claim.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'Qual a diferen√ßa entre MLOps e DevOps?',\n",
       "  'actual_output': 'A diferen√ßa entre **MLOps** e **DevOps** est√° em seus focos e aplica√ß√µes dentro do desenvolvimento de software e, especificamente, no contexto do Machine Learning (ML). Ambos compartilham princ√≠pios em comum, como automa√ß√£o, integra√ß√£o cont√≠nua e entrega cont√≠nua, mas se diferenciam em aspectos-chave:\\n\\n### Pontos de Semelhan√ßa:\\n- Ambos buscam **automatizar processos** e melhorar a velocidade e qualidade do desenvolvimento.\\n- Requerem **colabora√ß√£o** entre equipes (desenvolvimento, opera√ß√µes, infraestrutura, etc.).\\n- Utilizam pr√°ticas como **CI/CD (Continuous Integration/Continuous Delivery)**.\\n\\n---\\n\\n### Principais Diferen√ßas:\\n1. **Origem e Contexto**:\\n   - **DevOps** foca no desenvolvimento de **softwares tradicionais**, otimizando ciclos de desenvolvimento, implanta√ß√£o e manuten√ß√£o.\\n   - **MLOps** surgiu a partir dos princ√≠pios do DevOps, mas se especializa no gerenciamento do **ciclo de vida do Machine Learning**, incluindo dados, treinamento de modelos, valida√ß√£o e monitoramento em produ√ß√£o.\\n\\n2. **Tratamento de Dados**:\\n   - **DevOps**: Os dados s√£o **outputs** do sistema (ex: logs, m√©tricas de desempenho).\\n   - **MLOps**: Os dados s√£o **inputs essenciais** para o modelo, exigindo gerenciamento espec√≠fico (limpeza, versionamento, etc.).\\n\\n3. **Monitoramento**:\\n   - **DevOps**: O monitoramento √© voltado para a **sa√∫de do sistema** (ex: uptime, desempenho).\\n   - **MLOps**: Requer **valida√ß√£o cont√≠nua dos modelos** para detectar degrada√ß√£o de desempenho devido a mudan√ßas nos dados ou no ambiente.\\n\\n---\\n\\n### Resumo:\\nMLOps √© como o DevOps, mas com um olhar especial para o Machine Learning. Ele incorpora as boas pr√°ticas do DevOps e adiciona camadas extras para lidar com dados, modelos e valida√ß√£o cont√≠nua. üòä',\n",
       "  'expected_output': 'DevOps foca em desenvolvimento e opera√ß√£o de software tradicional, enquanto MLOps lida tamb√©m com dados, treinamento de modelos, versionamento de experimentos e monitoramento de m√©tricas de infer√™ncia e drift.',\n",
       "  'context': None,\n",
       "  'retrieval_context': [\"Scalability and governance\\n\\nMLOps establishes a defined and scalable development process, ensuring consistency, reproducibility and governance throughout the ML lifecycle. Manual deployment and monitoring are slow and require significant human effort, hindering scalability. Without proper centralized monitoring, individual models might experience performance issues that go unnoticed, impacting overall accuracy.\\n\\nWhat's the relationship to DevOps?\\n\\nMLOps and DevOps focus on different aspects of the development process. DevOps focuses on streamlining the development, testing and deployment of traditional software applications. It emphasizes collaboration between development and operations teams to automate processes and improve software delivery speed and quality.\\n\\nMLOps builds upon DevOps principles and applies them to the machine learning lifecycle. It goes beyond deploying code, encompassing data management, model training, monitoring and continuous improvement.\",\n",
       "   'strategic in their decision-making.\\nSimilarities between MLOPs and DevOps\\nBoth MLOps and DevOps share a need for process automation, continuous integration, and continuous delivery .\\nIt also helps to have proper testing of the code base for both MLOps and DevOps.\\nIn addition, there should be adequate collaboration between software developers and those who manage the infrastructure, as well as other stakeholders.\\nDissimilarities between MLOps and DevOps\\nAlthough MLOps is derived from DevOps, there are subtle dif ferences between the two.\\nIn MLOps, data is a necessary input for developing the machine learning model. But in DevOps, data is an output of the program, not an input.\\nIn MLOPs, the model must be validated continuously in production for performance deterioration caused by new data over time. The software system does not deteriorate\\nin DevOps; it is merely monitored for health maintenance purposes.',\n",
       "   'What are the key elements of an effective MLOps strategy?\\n\\nMLOps requires skills, tools and practices to effectively manage the machine learning lifecycle. MLOps teams need a diverse skillset encompassing both technical and soft skills. They must understand the entire data science pipeline, from data preparation and model training to evaluation. Familiarity with software engineering practices like version control, CI/CD pipelines and containerization are also crucial. In addition, knowledge of DevOps principles, infrastructure management and automation tools is essential for the efficient deployment and operation of ML models.',\n",
       "   'systems (MLOps). This document covers concepts to consider when setting up an MLOps\\nenvironment for your data science practices, such as CI, CD, and CT in ML.\\nThe following topics are discussed:11/13/25, 11:39 PM MLOps: Continuous delivery and automation pipelines in machine learning | Cloud Architecture Center | Google Cloud Do‚Ä¶\\nhttps://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning 2/18\\nDevOps versus MLOps\\nSteps for developing ML models\\nMLOps maturity levels\\nMlOps for generative AI\\nDevOps versus MLOps\\nDevOps\\xa0(https://cloud.google.com/devops/) is a popular practice in developing and operating\\nlarge-scale software systems. This practice provides benefits such as shortening the\\ndevelopment cycles, increasing deployment velocity, and dependable releases. To achieve\\nthese benefits, you introduce two concepts in the software system development:\\nContinuous integration (CI)\\xa0(https://en.wikipedia.org/wiki/Continuous_integration)',\n",
       "   'What is MLOps?\\n\\nMLOps, short for machine learning operations, is a set of practices designed to create an assembly line for building and running machine learning models. It helps companies automate tasks and deploy models quickly, ensuring everyone involved (data scientists, engineers, IT) can cooperate smoothly and monitor and improve models for better accuracy and performance.\\n\\nThe term MLops is a combination of machine learning (ML) and DevOps. The term was coined in 2015 in a paper called \"Hidden technical debt in machine learning systems,\" which outlined the challenges inherent in dealing with large volumes of data and how to use DevOps processes to instill better ML practices. Creating an MLOps process incorporates continuous integration and continuous delivery (CI/CD) methodology from DevOps to create an assembly line for each step in creating a machine learning product.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7095238095238094,\n",
       "    'reason': 'The score is 0.71 because irrelevant nodes, such as the fairy tale about Goldilocks (ranked 4), are correctly ranked lower than relevant nodes that provide insights into concept drift and its impact on machine learning models (ranks 1, 2, and 5).',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'concept drift\\' which is a type of data drift, and it\\'s mentioned as a challenge in the ML lifecycle.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text doesn\\'t mention anything about models getting retrained due to performance degradation or significant changes in data distributions.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'accuracy drift\\' and \\'bias\\', which are related to the topic of data drift and its impact on model performance.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The fairy tale about Goldilocks is not relevant to the topic of data drift in machine learning models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'natural data shift\\' and how it can cause issues with hand-curated features and data quality checks.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text doesn\\'t mention anything about models getting stale or needing to be retrained due to data drift.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'model performance degradation\\' and how it can be addressed by retraining the model on fresh data.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the contextual recall score indicates that half of the expected output can be attributed to nodes in the retrieval context, while the other half does not have a clear connection to any node.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'On availability of new training data...\\' - This sentence can be attributed to the 1st node in the retrieval context, which talks about the availability of new training data and its impact on model performance.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'On model performance degradation...\\' - This sentence can be attributed to the 2nd node in the retrieval context, which talks about the retraining of models when there is noticeable performance degradation.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'It\\'s hard to assess...\\' - This sentence can be attributed to the 3rd node in the retrieval context, which talks about significant changes in data distributions and the need for retraining models on fresh data.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'Monitoring and optimization...\\' - This sentence can be attributed to the 4th node in the retrieval context, which talks about monitoring model performance for accuracy drift, bias, and other potential issues.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'asked P17...\\' - This sentence can be attributed to the 5th node in the retrieval context, which talks about an example of a natural data drift problem and its impact on model performance.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node: \\'Operationalizing Machine Learning...\\' - This sentence can be attributed to the 6th node in the retrieval context, which talks about the retraining of models and its impact on model performance.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node: \\'However, a few engineers...\\' - This sentence can be attributed to the 7th node in the retrieval context, which talks about natural data shift and its impact on model performance.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6086956521739131,\n",
       "    'reason': \"The score is 0.61 because the input question about drift in machine learning models doesn't seem to be related to the statements in the retrieval context that discuss model retraining, monitoring, and performance degradation. The relevant statements focus on the importance of continuous monitoring and retraining to prevent accuracy drift and other issues, whereas the input question is more focused on understanding what drift means in a machine learning context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"On availability of new training data: New data isn\\'t systematically available for the ML system and instead is available on an ad hoc basis when new data is collected and made available in the source databases.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"On model performance degradation: The model is retrained when there is noticeable performance degradation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"On significant changes in the data distributions (concept drift).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It\\'s hard to assess the complete performance of the online model, but you notice significant changes on the data distributions of the features that are used to perform the prediction.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These changes suggest that your model has gone stale, and that needs to be retrained on fresh data.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Monitoring and optimization\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model monitoring forms the cornerstone of this phase, involving the ongoing scrutiny of the model\\'s performance in the production environment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This step helps identify emerging issues, such as accuracy drift, bias and concerns around fairness, which could compromise the model\\'s utility or ethical standing.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring is about overseeing the model\\'s current performance and anticipating potential problems before they escalate.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"5Goldilocks and the Three Bears is a popular Western fairy tale.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The model gets retrained every day, so we don\\\\u2019t have the scenario of like: Oh, our models got stale and we need to re-train it because it\\\\u2019s starting to make mistakes because data has drifted...\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"However, a few engineers mentioned that natural data shift could cause some hand-curated features and data quality checks to corrupt (P3, P6, P8).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"object recognition, probabilities or likelihoods as embeddings\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A general trend is to try to move more into the neural network, and to combine models wherever possible so there are fewer bigger models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Then you don\\\\u2019t have these intermediate dependencies that cause drift and performance regressions...you eliminate entire classes of bugs and and issues by consolidating all these different piecemeal stacks.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4.5.6 Organizationally Supporting ML Engineers Requires Delib-erate Practices.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Our interviewees reported various organizational processes for sustaining models as part of their ML infrastructure.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P6, P12, P14, P16, P18, and P19 described on-call processes for supervising production ML models.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For each model, at any point in time, some ML engineer would be on call, or primarily responsible for it.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Any bug or incident observed (e.g., user complaint, pipeline\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': False,\n",
       "    'score': 0.7857142857142857,\n",
       "    'reason': \"The score is 0.79 because, although there are some irrelevant statements made in the actual output that could have brought down the score further, the overall relevance of the output to the input question about 'drift' in machine learning is still relatively high.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Drift in machine learning is a change in the real world that affects data or the relationship between data and the model\\'s objective.\",\\n    \"Data Drift (Drift de Dados) is when characteristics of production data differ from those used for training.\",\\n    \"Imagine a model trained to detect credit card fraud using historical data. If, after some time, the pattern of customer purchases changes completely (e.g., many start making online purchases instead of physical ones), the data received by the model changes.\",\\n    \"The drift is like \\'Goldilocks and the Three Bears\\' - the data needs to be \\'just right\\'.\",\\n    \"Data Drift is when the data becomes \\'too big\\'.\",\\n    \"Concept Drift (Drift de Conceito) is when the relationship between data and the objective that the model should achieve changes.\",\\n    \"A model of image classification was trained to identify cats. It worked perfectly. But then, the definition of \\'cat\\' in culture or even biology changed significantly (a rare scenario, but imagine!), making it so the model, based on historical data, no longer correctly identifies cats in practice.\",\\n    \"It\\'s when the very rules or correlation that the model learned in its time change, and this makes the model \\'stale\\'.\",\\n    \"The model was created based on a specific set of data and patterns from the past.\",\\n    \"If these data or patterns change (drift), the model may become \\'outdated\\' or \\'worn out\\'.\",\\n    \"This can make the model start making errors more frequently, predict poor values, or even discriminate differently.\",\\n    \"Monitoring is crucial to continuously monitor the model\\'s performance and check if the received data is similar to the training data (to detect data drift) or if the performance is as expected (to try to detect concept drift).\",\\n    \"When drift is detected, the model may need to be retrained with new data or adapted specifically to deal with changes.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement is not directly relevant to drift in machine learning, but it could be supporting information.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The statement is unrelated to the concept of drift in machine learning.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement is not directly relevant to drift in machine learning, but it could be supporting information.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The statement is unrelated to the concept of drift in machine learning.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement is not directly relevant to drift in machine learning, but it could be supporting information.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The statement is unrelated to the concept of drift in machine learning.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement is not directly relevant to drift in machine learning, but it could be supporting information.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.3076923076923077,\n",
       "    'reason': 'The score is 0.31 because all contradictions indicate that the actual output does not directly contradict the retrieval context, and since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The ML system does not have systematically available new training data.\",\\n    \"New data is only available on an ad hoc basis when collected and made available in the source databases.\",\\n    \"The model gets retrained every day.\",\\n    \"There are no natural data drift problems experienced by the company.\",\\n    \"The model performance degrades noticeably before being retrained.\",\\n    \"Significant changes in data distributions can cause concept drift, which requires retraining the model.\",\\n    \"Model monitoring is critical for maintaining effectiveness and fairness over time.\",\\n    \"Continuous vigilance ensures optimal model performance and prevents unexpected outcomes.\",\\n    \"Monitoring model performance helps identify emerging issues such as accuracy drift, bias, and concerns around fairness.\",\\n    \"The company does not have to deal with scenarios where models get stale and need to be retrained due to data drifting.\",\\n    \"Some engineers mentioned that natural data shift could cause hand-curated features and data quality checks to corrupt.\",\\n    \"A general trend is to try to move more into neural networks and combine models wherever possible.\",\\n    \"Consolidating different models eliminates intermediate dependencies that can cause drift and performance regressions.\",\\n    \"On-call processes are used for supervising production ML models, with some engineer being primarily responsible for each model at any point in time.\"\\n] \\n \\nClaims:\\n[\\n    \"Einstein won the noble prize for his discovery of the photoelectric effect in 1968.\",\\n    \"The photoelectric effect is a phenomenon that laid the foundation for quantum mechanics.\",\\n    \"Drift in machine learning is a change in the real world that affects data or the relationship between data and the model\\'s objective, making the model worse over time.\",\\n    \"There are mainly two types of drift: Data Drift (Drift de Dados) and Concept Drift (Drift de Conceito).\",\\n    \"Data Drift is when the characteristics of the data received in practice change differently from those used to train it.\",\\n    \"The example of Data Drift is a model trained to detect credit card fraud using historical data, but then the pattern of customer purchases changes completely.\",\\n    \"Concept Drift is when the relationship between the data and the objective that the model should achieve changes.\",\\n    \"The example of Concept Drift is a model for classifying images that was trained to identify cats, but then the definition of \\'cat\\' in culture or biology changed significantly.\",\\n    \"It\\'s a problem because the model was created based on a specific set of data and patterns from the past.\",\\n    \"If those data or patterns change (drift), the model may become \\'outdated\\' or \\'worn out\\'.\",\\n    \"This can make the model start making errors more frequently, predict poor values, or even discriminate differently.\",\\n    \"Monitoring is crucial to continuously monitor the model\\'s performance and verify if the received data are similar to the training data (to detect Data Drift) or if the performance is as expected (to try to detect Concept Drift).\",\\n    \"When drift is detected, the model may need to be retrained with new data or adapted specifically to deal with changes.\",\\n    \"The drift is an important issue in maintaining machine learning models in production because the real world does not stop changing!\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claims do not directly contradict the retrieval context. However, since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claims do not directly contradict the retrieval context. However, since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claims do not directly contradict the retrieval context. However, since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claims do not directly contradict the retrieval context. However, since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claims do not directly contradict the retrieval context. However, since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claims do not directly contradict the retrieval context. However, since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claims do not directly contradict the retrieval context. However, since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claims do not directly contradict the retrieval context. However, since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claims do not directly contradict the retrieval context. However, since there is no mention of drift in machine learning being a problem due to lack of new training data, it can be inferred that the claim does not consider the given context.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© drift em modelos de machine learning?',\n",
       "  'actual_output': 'Okay, vamos entender o que √© \"drift\" em modelos de machine learning!\\n\\nEm resumo, **drift em machine learning √© uma mudan√ßa no mundo real que afeta os dados ou a rela√ß√£o entre os dados e o objetivo do modelo, fazendo com que o modelo, uma vez bom, comece a dar resultados cada vez piores com o tempo.**\\n\\nExistem principalmente dois tipos de drift:\\n\\n1.  **Data Drift (Drift de Dados):**\\n    *   **O que √©:** Quando as caracter√≠sticas dos dados que o modelo recebe na pr√°tica (dados de produ√ß√£o) mudam de forma diferente daquelas usadas para trein√°-lo.\\n    *   **Exemplo:** Imagine um modelo treinado para detectar fraudes de cart√£o de cr√©dito usando dados hist√≥ricos. Se, depois de algum tempo, o padr√£o de compra dos clientes mudar completamente (por exemplo, muitos passarem a fazer compras online em vez de lojas f√≠sicas), os dados que o modelo recebe mudam. Se o modelo foi treinado apenas com dados de compras f√≠sicas, ele pode come√ßar a mal detectar fraudes nesse novo padr√£o.\\n    *   **Analogia do contexto:** √â como o \"Goldilocks and the Three Bears\" - os dados precisam estar \"just right\". Se ficarem muito diferentes (\"muito grande\") ou praticamente iguais (\"muito pequeno\"), o modelo pode ter problemas. O drift de dados √© quando eles ficam \"muito grandes\".\\n\\n2.  **Concept Drift (Drift de Conceito):**\\n    *   **O que √©:** Quando a rela√ß√£o entre os dados e o objetivo que o modelo deve alcan√ßar muda. O mundo real muda de forma que a defini√ß√£o de \"fraude\" ou \"bom comprador\" muda, independente dos dados.\\n    *   **Exemplo:** Um modelo de classifica√ß√£o de imagens foi treinado para identificar gatos. Funcionava perfeitamente. Mas depois, a defini√ß√£o de \"gato\" na cultura ou at√© mesmo a pr√≥pria biologia dos gatos mudou de forma significativa (um cen√°rio raro, mas imagine!), fazendo com que o modelo, baseado nos dados hist√≥ricos, n√£o mais identifique corretamente os gatos na pr√°tica.\\n    *   **Analogia do contexto:** √â quando as pr√≥prias regras ou a correla√ß√£o que o modelo aprendeu na √©poca mudam, e isso faz com que o modelo \"estale\".\\n\\n**Por que √© um problema?**\\n\\n*   O modelo foi criado com base em um conjunto espec√≠fico de dados e padr√µes do passado.\\n*   Se esses dados ou padr√µes mudam (drift), o modelo pode se tornar \"desatualizado\" ou \"estragado\".\\n*   Isso pode fazer com que o modelo comece a fazer erros mais frequentemente, prever valores ruins, ou at√© mesmo discriminar de forma diferente.\\n\\n**Como lidar?**\\n\\n*   **Monitoramento:** √â crucial monitorar continuamente o desempenho do modelo e verificar se os dados recebidos s√£o similares aos dados de treino (para detectar data drift) ou se o desempenho est√° conforme o esperado (para tentar detectar concept drift).\\n*   **Retreinamento:** Quando se detecta drift, o modelo pode precisar ser reentrenado com os novos dados ou adaptado especificamente para lidar com as mudan√ßas.\\n\\nEnt√£o, o drift √© uma quest√£o importante na manuten√ß√£o de modelos de machine learning em produ√ß√£o, porque o mundo real n√£o para de mudar!',\n",
       "  'expected_output': 'Drift √© a mudan√ßa estat√≠stica no comportamento dos dados ou das rela√ß√µes entre vari√°veis ao longo do tempo, resultando em perda de performance do modelo.',\n",
       "  'context': None,\n",
       "  'retrieval_context': [\"On availability of new training data: New data isn't systematically available for the ML\\nsystem and instead is available on an ad hoc basis when new data is collected and\\nmade available in the source databases.11/13/25, 11:39 PM MLOps: Continuous delivery and automation pipelines in machine learning | Cloud Architecture Center | Google Cloud Do‚Ä¶\\nhttps://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning 12/18\\nOn model performance degradation: The model is retrained when there is noticeable\\nperformance degradation.\\nOn significant changes in the data distributions (concept drift\\n\\xa0(https://en.wikipedia.org/wiki/Concept_drift)). It's hard to assess the complete\\nperformance of the online model, but you notice significant changes on the data\\ndistributions of the features that are used to perform the prediction. These changes\\nsuggest that your model has gone stale, and that needs to be retrained on fresh data.\\nChallenges\",\n",
       "   \"Monitoring and optimization\\n\\nIn the lifecycle of a deployed machine learning model, continuous vigilance ensures effectiveness and fairness over time. Model monitoring forms the cornerstone of this phase, involving the ongoing scrutiny of the model's performance in the production environment. This step helps identify emerging issues, such as accuracy drift, bias and concerns around fairness, which could compromise the model's utility or ethical standing. Monitoring is about overseeing the model's current performance and anticipating potential problems before they escalate.\",\n",
       "   'asked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:\\n5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\ncharacter, looks for things that are not too big or not too small, things that are ‚Äújust\\nright.‚Äù\\nOperationalizing Machine Learning: An Interview Study\\nThe model gets retrained every day, so we don‚Äôt have the\\nscenario of like: Oh, our models got stale and we need to re-\\ntrain it because it‚Äôs starting to make mistakes because data\\nhas drifted...fortunately we‚Äôve never had to deal with [such\\na] scenario. Sometimes there are bad jobs, but\\nwe can always effectively roll back to a different .\\nHowever, a few engineers mentioned that natural data shift\\ncould cause some hand-curated features and data quality\\nchecks to corrupt (P3, P6, P8). P6 discussed a histogram used',\n",
       "   'object recognition, probabilities or likelihoods as embeddings). P1\\ndescribed a push at their company to rely more on neural networks:\\nA general trend is to try to move more into the neural\\nnetwork, and to combine models wherever possible so\\nthere are fewer bigger models. Then you don‚Äôt have\\nthese intermediate dependencies that cause drift and\\nperformance regressions...you eliminate entire classes of\\nbugs and and issues by consolidating all these different\\npiecemeal stacks.\\n4.5.6 Organizationally Supporting ML Engineers Requires Delib-\\nerate Practices. Our interviewees reported various organizational\\nprocesses for sustaining models as part of their ML infrastructure.\\nP6, P12, P14, P16, P18, and P19 described on-call processes for su-\\npervising production ML models. For each model, at any point in\\ntime, some ML engineer would be on call, or primarily responsible\\nfor it. Any bug or incident observed (e.g., user complaint, pipeline',\n",
       "   'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes. Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7555555555555555,\n",
       "    'reason': 'The score is 0.76 because irrelevant nodes, such as those discussing MLOps and data versioning, are correctly ranked lower than the relevant nodes that provide definitions and explanations about feature stores, like the first and third nodes in retrieval contexts.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'feature store\\' which is directly related to the expected output, describing what a feature store is.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text about MLOps and model validation is not relevant to the definition of a feature store.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains how a feature store provides high-throughput batch serving and low-latency real-time serving for feature values, which supports both training and serving workloads.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text about data versioning is not directly related to the definition of a feature store.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context highlights the importance of consistency and reusability of features across different models and projects, which is a key aspect of a feature store.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6,\n",
       "    'reason': 'The score is 0.60 because the contextual recall score indicates that the expected output is partially attributed to nodes in retrieval context, suggesting a moderate level of relevance between the two.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'high-throughput batch serving and low-latency real-time serving for the feature values, and\\\\nto support both training and serving workloads.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'repository also provides data consistency for training and inference. This helps data scientists and ML researchers \\\\nsave time on data preparation and feature engineering, which typically take up a significant amount of their time.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Key functionalities in the data and feature repository include the following:\\\\n15\\\\n\\\\u2022 Enable shareability, discoverability, reusability, and versioning of data assets.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'ML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'An optional additional component for level 1 ML pipeline automation is a feature store.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'A feature store needs to provide an API for both\\\\nhigh-throughput batch serving and low-latency real-time serving for the feature values, and\\\\nto support both training and serving workloads.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'For experimentation, data scientists can get an offline extract from the feature\\\\nstore to run their experiments.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'For continuous training, the automated ML training pipeline can fetch a batch of\\\\nthe up-to-date feature values of the dataset that are used for the training task.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'For online prediction, the prediction service can fetch in a batch of\\\\nthe feature values related to the requested entity, such as customer demographic features,\\\\nproduct features, and current session aggregation features.\\'\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8125,\n",
       "    'reason': \"The score is 0.81 because the retrieval context provides detailed information about the purpose and functionality of a feature store, which is highly relevant to understanding what a feature store is. For example, statements like 'A feature store needs to provide an API for both high-throughput batch serving and low-latency real-time serving for the feature values...' and 'Feature stores promote consistency and reusability of features across different models and projects.' demonstrate the context's focus on the concept of a feature store, making it highly relevant to the input question.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"high-throughput batch serving and low-latency real-time serving for the feature values, and\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"to support both training and serving workloads.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Discover and reuse available feature sets for their entities, instead of re-creating the same or similar ones.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Avoid having similar features that have different definitions by maintaining features and their related metadata.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Serve up-to-date feature values from the feature store.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Avoid training-serving skew by using the feature store as the data source for experimentation, continuous training, and online serving.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For experimentation, data scientists can get an offline extract from the feature store to run their experiments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For continuous training, the automated ML training pipeline can fetch a batch of the up-to-date feature values of the dataset that are used for the training task.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"repository also provides data consistency for training and inference.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Enable shareability, discoverability, reusability, and versioning of data assets.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Allow real-time ingestion and low-latency serving for event streaming and online prediction workloads.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Allow high-throughput batch ingestion and serving for extract, transform, load (ETL) processes and model training, and for scoring workloads.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Enable feature versioning for point-in-time queries.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Support various data modalities, including tabular data, images, and text.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML data assets can be managed at the entity features level or at the full dataset level. For example, a feature repository\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'For example, a feature repository\\' when it has nothing to do with what is feature store.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"compatibility and consistency with the prediction service API.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In addition to offline model validation, a newly deployed model undergoes online model validation\\\\u2014in a canary deployment or an A/B testing setup\\\\u2014before it serves prediction for the online traffic.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Feature store\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A feature store is a centralized repository where you standardize the definition, storage, and access of features for training and serving.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A feature store needs to provide an API for both high-throughput batch serving and low-latency real-time serving for the feature values, and to support both training and serving workloads.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"store to run their experiments.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For continuous training, the automated ML training pipeline can fetch a batch of the up-to-date feature values of the dataset that are used for the training task.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For online prediction, the prediction service can fetch in a batch of the feature values related to the requested entity, such as customer demographic features, product features, and current session aggregation features.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For online prediction and feature retrieval, the prediction service identifies the relevant features for an entity. For example, if the entity is a customer, relevant features might include age, purchase history, and browsing behavior.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The service batches these feature values together and retrieves all the needed features for the entity at once, rather than individually.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This retrieval method helps with efficiency, especially when you need to manage multiple entities.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It involves tracking and managing different versions of the data, allowing for traceability of results and the ability to revert to previous states if necessary.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The concept of a feature store is then introduced as a centralized repository for storing and managing features used in model training.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Feature stores promote consistency and reusability of features across different models and projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By having a dedicated system for feature management, teams can ensure they use the most relevant and up-to-date features.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the answer directly addresses the question about what a feature store is, making it highly relevant and accurate.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"A feature store is a centralized repository for standardizing the definition, storage, and access to machine learning model features.\",\\n    \"It acts as an intermediary between models and data, allowing for easy finding and reusing of available feature sets for different entities.\",\\n    \"It helps avoid duplication of features with different definitions.\",\\n    \"It serves updated and consistent features.\",\\n    \"It eliminates the \\'training-serving skew\\' by ensuring the same features are used in both training and prediction processes.\",\\n    \"The feature store offers important functionalities such as data ingestion and serving with high capacity (batch) and low latency (real-time).\",\\n    \"It provides versioning of features, allowing queries at the point where the data was captured.\",\\n    \"It supports different types of data (tabular, images, text).\",\\n    \"The feature store helps the data science team save time by avoiding repetitive tasks of data preparation and feature engineering, and promotes reusing and consistency of features across different projects.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.9090909090909091,\n",
       "    'reason': 'The score is 0.91 because the actual output only partially aligns with the retrieval context, as the claim mentions avoiding duplication of features with different definitions, which is not explicitly mentioned in the retrieval context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The feature store provides an API for both high-throughput batch serving and low-latency real-time serving for the feature values.\",\\n    \"The feature store supports both training and serving workloads.\",\\n    \"A feature store is a centralized repository where you standardize the definition, storage, and access of features for training and serving.\",\\n    \"Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis.\",\\n    \"Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\",\\n    \"A feature store promotes consistency and reusability of features across different models and projects.\"\\n] \\n \\nClaims:\\n[\\n    \"Um feature store √© um reposit√≥rio centralizado criado para padronizar a defini√ß√£o, armazenamento e acesso a features utilizadas no treinamento e na infer√™ncia de modelos de machine learning.\",\\n    \"Ele atua como um intermedi√°rio entre os modelos e os dados, permitindo que sejam encontradas e reutilizadas facilmente as feature sets dispon√≠veis para diferentes entidades (ex: clientes, produtos).\",\\n    \"Se evite a duplica√ß√£o de features com defini√ß√µes diferentes.\",\\n    \"Sejam servidas features atualizadas e consistentes.\",\\n    \"Se elimine a \\'training-serving skew\\' (diferen√ßas entre os dados usados para treinamento e para a predi√ß√£o em tempo real), garantindo que as mesmas features sejam usadas em ambos os processos.\",\\n    \"Ingest√£o e servi√ß√£o de dados com alta capacidade (batch) e baixa lat√™ncia (real-time).\",\\n    \"Vers√£o de features, permitindo consultas no ponto em que o dado foi capturado.\",\\n    \"Suporte a diferentes tipos de dados (tabular, imagens, texto).\",\\n    \"O feature store ajuda a equipe de data science a economizar tempo, evitando a repeti√ß√£o de tarefas de prepara√ß√£o de dados e engenharia de features, e promove a reutiliza√ß√£o e consist√™ncia das features em projetos diferentes.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim suggests avoiding duplication of features with different definitions, but the retrieval context does not explicitly mention this as a concern.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim mentions eliminating \\'training-serving skew\\', which is not directly addressed in the retrieval context. However, it does mention supporting both training and serving workloads, which could be related.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim mentions versioning features, but the retrieval context only mentions data versioning as a means to maintain integrity and reproducibility. It does not explicitly mention feature versioning.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim mentions supporting different types of data, but the retrieval context only mentions tabular data. It does not explicitly mention support for images or text.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© feature store?',\n",
       "  'actual_output': 'Um **feature store** √© um reposit√≥rio centralizado criado para padronizar a defini√ß√£o, armazenamento e acesso a **features** (atributos ou caracter√≠sticas) utilizadas no treinamento e na infer√™ncia de modelos de machine learning.\\n\\nEle atua como um intermedi√°rio entre os modelos e os dados, permitindo que:\\n\\n*   **Sejam encontradas e reutilizadas** facilmente as *feature sets* dispon√≠veis para diferentes entidades (ex: clientes, produtos).\\n*   **Se evite** a duplica√ß√£o de features com defini√ß√µes diferentes.\\n*   **Sejam servidas** features atualizadas e consistentes.\\n*   **Se elimine a \"training-serving skew\"** (diferen√ßas entre os dados usados para treinamento e para a predi√ß√£o em tempo real), garantindo que as mesmas features sejam usadas em ambos os processos.\\n\\nAl√©m disso, o feature store oferece funcionalidades importantes como:\\n\\n*   **Ingest√£o e servi√ß√£o** de dados com alta capacidade (batch) e baixa lat√™ncia (real-time).\\n*   **Vers√£o de features**, permitindo consultas no ponto em que o dado foi capturado.\\n*   Suporte a diferentes tipos de dados (tabular, imagens, texto).\\n\\nEm resumo, o feature store ajuda a equipe de data science a economizar tempo, evitando a repeti√ß√£o de tarefas de prepara√ß√£o de dados e engenharia de features, e promove a reutiliza√ß√£o e consist√™ncia das features em projetos diferentes.',\n",
       "  'expected_output': 'Uma feature store √© um sistema que centraliza cria√ß√£o, versionamento, armazenamento e disponibiliza√ß√£o de features para treinamento e infer√™ncia.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['high-throughput batch serving and low-latency real-time serving for the feature values, and\\nto support both training and serving workloads.\\nThe feature store helps data scientists do the following:\\nDiscover and reuse available feature sets for their entities, instead of re-creating the\\nsame or similar ones.\\nAvoid having similar features that have different definitions by maintaining features\\nand their related metadata.\\nServe up-to-date feature values from the feature store.\\nAvoid training-serving skew by using the feature store as the data source for\\nexperimentation, continuous training, and online serving. This approach makes sure\\nthat the features used for training are the same ones used during serving:\\nFor experimentation, data scientists can get an offline extract from the feature\\nstore to run their experiments.\\nFor continuous training, the automated ML training pipeline can fetch a batch of\\nthe up-to-date feature values of the dataset that are used for the training task.',\n",
       "   'repository also provides data consistency for training and inference. This helps data scientists and ML researchers \\nsave time on data preparation and feature engineering, which typically take up a significant amount of their time. Key \\nfunctionalities in the data and feature repository include the following:\\n15\\n‚Ä¢ Enable shareability, discoverability, reusability, and versioning of data assets.\\n‚Ä¢ Allow real-time ingestion and low-latency serving for event streaming and online prediction workloads. \\n‚Ä¢ Allow high-throughput batch ingestion and serving for extract, transform, load (ETL) processes and model \\ntraining, and for scoring workloads.\\n‚Ä¢ Enable feature versioning for point-in-time queries.\\n‚Ä¢ Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -',\n",
       "   'compatibility and consistency with the prediction service API.11/13/25, 11:39 PM MLOps: Continuous delivery and automation pipelines in machine learning | Cloud Architecture Center | Google Cloud Do‚Ä¶\\nhttps://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning 10/18\\nIn addition to offline model validation, a newly deployed model undergoes online model\\nvalidation‚Äîin a canary deployment or an A/B testing setup‚Äîbefore it serves prediction for\\nthe online traffic.\\nFeature store\\nAn optional additional component for level 1 ML pipeline automation is a feature store. A\\nfeature store is a centralized repository where you standardize the definition, storage, and\\naccess of features for training and serving. A feature store needs to provide an API for both\\nhigh-throughput batch serving and low-latency real-time serving for the feature values, and\\nto support both training and serving workloads.',\n",
       "   'store to run their experiments.\\nFor continuous training, the automated ML training pipeline can fetch a batch of\\nthe up-to-date feature values of the dataset that are used for the training task.\\nFor online prediction, the prediction service can fetch in a batch of the feature\\nvalues related to the requested entity, such as customer demographic features,\\nproduct features, and current session aggregation features.\\nFor online prediction and feature retrieval, the prediction service identifies the\\nrelevant features for an entity. For example, if the entity is a customer, relevant\\nfeatures might include age, purchase history, and browsing behavior. The service\\nbatches these feature values together and retrieves all the needed features for\\nthe entity at once, rather than individually. This retrieval method helps with\\nefficiency, especially when you need to manage multiple entities.',\n",
       "   'Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis. It involves tracking and managing different versions of the data, allowing for traceability of results and the ability to revert to previous states if necessary. Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\\n\\nThe concept of a feature store is then introduced as a centralized repository for storing and managing features used in model training. Feature stores promote consistency and reusability of features across different models and projects. By having a dedicated system for feature management, teams can ensure they use the most relevant and up-to-date features.\\n\\nModel development'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8541666666666666,\n",
       "    'reason': \"The score is 0.85 because irrelevant nodes, such as those discussing manual deployment or verifying predictive performance targets, are correctly ranked lower than relevant nodes that discuss model development, evaluation, and deployment. The first 'no' verdict at rank 3 is a clear indication of this, as it's not directly related to serving a model in production.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'model development\\' which is relevant to the topic of serving a model in production.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses \\'model evaluation\\' and \\'model deployment\\', which are all part of the process of making a model available for use.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text mentions \\'Verifying that models meet the predictive performance targets before they are deployed.\\' but this is not directly related to serving a model in production.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context talks about \\'Automated deployment to a test environment\\' and \\'Semi-automated deployment to a pre-production environment\\', which are all part of the process of making a model available for use.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text mentions \\'Manual deployment to a production environment after several successful runs of the pipeline on the pre-production environment.\\' but this is not directly related to serving a model in production.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses \\'Setting up a CI/CD system lets you automatically test and deploy new pipeline implementations\\' which is relevant to the topic of serving a model in production.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the contextual recall struggles to attribute the expected output sentences to relevant nodes in the retrieval context, with most sentences lacking clear connections to specific nodes.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes from the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'https://mlopsnow.com/blog/what-is-mlops/\\'... This sentence is related to understanding ML Ops and its development lifecycle, which is mentioned in the 1st node of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes from the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects...\\'... This sentence is related to understanding ML Ops and its development lifecycle, which is mentioned in the 2nd node of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'https://mlopsnow.com/blog/what-is-mlops/\\'... This sentence is related to understanding ML Ops and its development lifecycle, which is mentioned in the 1st node of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes from the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects...\\'... This sentence is related to understanding ML Ops and its development lifecycle, which is mentioned in the 2nd node of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes from the retrieval context can be attributed to this sentence.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7222222222222222,\n",
       "    'reason': \"The score is 0.72 because the retrieval context provides relevant information about the data science process, including model development, evaluation, and deployment, which are all related to serving a model in production. For example, statements like 'Model deployment: Implementing the ML model into a product, service, or system.' and 'To summarize, implementing ML in a production environment doesn't only mean deploying your model as an API for prediction. Rather, it means deploying an ML pipeline that can automate the retraining and deployment of new models.' provide context about what it means to serve a model in production.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A typical data science project consists of several stages:\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data acquisition: Obtaining raw data from various sources, such as databases, sensors, or external APIs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data preprocessing: Cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Featur e engineering: Selecting the most relevant data attributes, or \\\\u201cfeatures,\\\\u201d and converting them into a suitable format for ML algorithms.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model training: Applying ML algorithms to the preprocessed data to create a predictive model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model evaluation: Assessing the performance of the model and making adjustments to improve its accuracy.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model deployment: Implementing the ML model into a product, service, or system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring and maintenance: Continuously monitoring the performance of the ML model and updating it as needed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Hyperparameters, including trials of automated hyperparameter tuning and model selection.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Information about training, validation, and testing data splits that were used.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model evaluation metrics and the validation procedure that was used.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"If there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about the possibility of not needing to retrain the model, which is not related to serving a model in production.\"\\n            },\\n            {\\n                \"statement\": \"The model is then ready to be reviewed, approved, and deployed to the target serving environment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In addition, all the relevant metadata and artifacts that were produced during model development are tracked in the metadata tracking repository.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about tracking metadata and artifacts, which is not directly related to serving a model in production.\"\\n            },\\n            {\\n                \"statement\": \"However, in most cases, ML models need to be retrained on a regular basis when new data is available or when the code changes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In this case, the output of the ML development process is not the model to be deployed in production. Instead, the output is the implementation of the continuous\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about the output of the ML development process being the implementation of the continuous, which is not directly related to serving a model in production.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Model development is a core phase in the data science process\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"An essential aspect of model development is maintaining and tracking experiments\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This process helps optimize model performance and ensures that the development process is transparent and reproducible.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Evaluation is critical to ensure that the models perform well in real-world scenarios.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model deployment\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement \\'Model deployment\\' does not provide any relevant information about what it means to serve a model in production.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Verifying that models meet the predictive performance targets before they are deployed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Automated deployment to a test environment, for example, a deployment that is triggered by pushing code to the development branch.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about automated deployment, but it has nothing to do with what \\'servir um modelo em produ\\\\u00e7\\\\u00e3o\\' means.\"\\n            },\\n            {\\n                \"statement\": \"Semi-automated deployment to a pre-production environment, for example, a deployment that is triggered by merging code to the main branch after reviewers approve the changes.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about semi-automated deployment, but it has nothing to do with what \\'servir um modelo em produ\\\\u00e7\\\\u00e3o\\' means.\"\\n            },\\n            {\\n                \"statement\": \"Manual deployment to a production environment after several successful runs of the pipeline on the pre-production environment.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about manual deployment, but it has nothing to do with what \\'servir um modelo em produ\\\\u00e7\\\\u00e3o\\' means.\"\\n            },\\n            {\\n                \"statement\": \"To summarize, implementing ML in a production environment doesn\\'t only mean deploying your model as an API for prediction. Rather, it means deploying an ML pipeline that can automate the retraining and deployment of new models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Setting up a CI/CD system lets you automatically test and deploy new pipeline implementations.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about setting up a CI/CD system, but it has nothing to do with what \\'servir um modelo em produ\\\\u00e7\\\\u00e3o\\' means.\"\\n            },\\n            {\\n                \"statement\": \"This system lets you cope with rapid changes in your data and business environment.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about coping with rapid changes, but it has nothing to do with what \\'servir um modelo em produ\\\\u00e7\\\\u00e3o\\' means.\"\\n            },\\n            {\\n                \"statement\": \"You don\\'t have to immediately retrain your model when the data distribution changes.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about not having to immediately retrain a model, but it has nothing to do with what \\'servir um modelo em produ\\\\u00e7\\\\u00e3o\\' means.\"\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about serving a model in production, making it highly relevant and leaving no room for improvement.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Serving a production model means putting it into practice!\",\\n    \"Imagine developing an AI model that makes good predictions in its test environment.\",\\n    \"When you \\'serve\\' the model in production, it starts making those predictions within the real system where people use the product or service.\",\\n    \"In the MLOps context, this means implementing the model so it can receive data from the real world, process it and provide responses or actions in the main system where work is done.\",\\n    \"This can be done through an API (a kind of door for the model to receive and send information) or by integrating it directly into the system.\",\\n    \"It\\'s like serving a ready plate to customers at the restaurant (production) after being tested in the kitchen (development)!\",\\n    \"It\\'s important to ensure the model works well and is continuously monitored after being served in production.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement does not directly address the input, but it provides context about AI model development and testing.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The analogy is not directly relevant to serving a production model, but it helps illustrate the concept of moving from development to production.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The development lifecycle of data science projects typically consists of 7 stages: Data acquisition, Data preprocessing, Featur e engineering, Model training, Model evaluation, Model deployment, and Monit oring and maint enance.\",\\n    \"A typical data science project involves obtaining raw data from various sources, such as databases, sensors, or external APIs.\",\\n    \"Data preprocessing is a stage in the development lifecycle of data science projects that involves cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n    \"Featur e engineering is a stage in the development lifecycle of data science projects that involves selecting the most relevant data attributes, or ‚Äúfeatures,‚Äù and converting them into a suitable format for ML algorithms.\",\\n    \"Model training is a stage in the development lifecycle of data science projects that involves applying ML algorithms to the preprocessed data to create a predictive model.\",\\n    \"Model evaluation is a stage in the development lifecycle of data science projects that involves assessing the performance of the model and making adjustments to improve its accuracy.\",\\n    \"Model deployment is a stage in the development lifecycle of data science projects that involves implementing the ML model into a product, service, or system.\",\\n    \"Monit oring and maint enance is a stage in the development lifecycle of data science projects that involves continuously monitoring the performance of the ML model and updating it as needed.\",\\n    \"Hyperparameters, including trials of automated hyperparameter tuning and model selection, are important aspects of the ML development process.\",\\n    \"Information about training, validation, and testing data splits that were used is important metadata in the ML development process.\",\\n    \"Model evaluation metrics and the validation procedure that was used are important aspects of the ML development process.\",\\n    \"The output of the ML development process can be either a model to be deployed in production or the implementation of the continuous model development process.\",\\n    \"Model development is a core phase in the data science process, focusing on constructing and refining machine learning models.\",\\n    \"Maintaining and tracking experiments is an essential aspect of model development.\",\\n    \"Detailed records of different model iterations, hyperparameter configurations used, and outcomes of various experiments are critical for comparing different models and configurations.\",\\n    \"The ML development process involves maintaining and tracking experiments to optimize model performance and ensure transparency and reproducibility.\",\\n    \"Evaluation is critical in the ML development process to assess the performance of the models on unseen data.\",\\n    \"Metrics such as accuracy, precision, recall, and fairness measures gauge how well the model meets the project objectives.\",\\n    \"These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment.\",\\n    \"The final model should be effective and fair.\",\\n    \"Model deployment involves verifying that models meet predictive performance targets before they are deployed.\",\\n    \"Automated deployment to a test environment, semi-automated deployment to a pre-production environment, or manual deployment to a production environment are possible ways to deploy ML models.\",\\n    \"Implementing ML in a production environment means deploying an ML pipeline that can automate the retraining and deployment of new models.\",\\n    \"A CI/CD system lets you automatically test and deploy new pipeline implementations, coping with rapid changes in your data and business environment.\"\\n] \\n \\nClaims:\\n[\\n    \"Serving a model in production means putting it into practice!\",\\n    \"A model developed for making good predictions in its test environment is implemented to make those predictions within the real system where people use the product or service.\",\\n    \"In the context of MLOps, serving a model means implementing it so that it can receive data from the real world, process it, and provide responses or actions in the main system where work is done.\",\\n    \"Serving a model can be done through an API or by integrating it directly into the system.\",\\n    \"Implementing a model to receive data from the real world, process it, and provide responses or actions in the main system where work is done is like serving a ready-to-use dish for customers to use at the restaurant (production) after being tested in the kitchen (development).\",\\n    \"It\\'s important to ensure that the model works well and be monitored continuously after being served in production.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The claim is a correct description of the model serving process, which involves implementing the model in a production environment to receive data from the real world and provide responses or actions.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que significa servir um modelo em produ√ß√£o?',\n",
       "  'actual_output': 'Ent√£o, \"servir um modelo em produ√ß√£o\" significa coloc√°-lo em pr√°tica de verdade! üöÄ\\n\\nImagine que voc√™ desenvolveu um modelo de intelig√™ncia artificial que faz previs√µes muito boas em seu ambiente de teste. Quando voc√™ o \"serve\" em produ√ß√£o, ele passa a fazer essas previs√µes dentro do sistema real onde as pessoas usam o produto ou servi√ßo.\\n\\nNo contexto do MLOps, isso significa implementar o modelo de forma que ele possa receber dados do mundo real, process√°-los e fornecer respostas ou a√ß√µes no sistema principal onde o trabalho √© feito. Isso pode ser feito atrav√©s de uma API (uma esp√©cie de porta por onde o modelo recebe e envia informa√ß√µes) ou integrando-o diretamente ao sistema.\\n\\n√â como se voc√™ estivesse servindo um prato pronto para os clientes usarem no restaurante (a produ√ß√£o) depois de ter sido testado na cozinha (desenvolvimento)! üçΩÔ∏è\\n\\n√â importante garantir que o modelo funcione bem e seja monitorado continuamente ap√≥s ser servido em produ√ß√£o.',\n",
       "  'expected_output': 'Servir um modelo significa disponibiliz√°-lo por meio de um endpoint, job ou pipeline para receber dados e retornar previs√µes de forma escal√°vel e confi√°vel.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.',\n",
       "   '‚Ä¢ Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\n‚Ä¢ Information about training, validation, and testing data splits that were used. \\n‚Ä¢ Model evaluation metrics and the validation procedure that was used.\\nIf there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\\ntion is submitted to the model registry. The model is then ready to be reviewed, approved, and deployed to the target \\n18\\nserving environment. In addition, all the relevant metadata and artifacts \\nthat were produced during model development are tracked in the metadata \\ntracking repository.\\nHowever, in most cases, ML models need to be retrained on a regular basis \\nwhen new data is available or when the code changes. In this case, the \\noutput of the ML development process is not the model to be deployed in \\nproduction. Instead, the output is the implementation of the continuous',\n",
       "   'Model development\\n\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks. The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\n\\nAn essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments. Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.',\n",
       "   'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios. Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment. Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\n\\nModel deployment',\n",
       "   \"Verifying that models meet the predictive performance targets before they are\\ndeployed.\\nAutomated deployment to a test environment, for example, a deployment that is\\ntriggered by pushing code to the development branch.\\nSemi-automated deployment to a pre-production environment, for example, a\\ndeployment that is triggered by merging code to the main branch after reviewers\\napprove the changes.\\nManual deployment to a production environment after several successful runs of the\\npipeline on the pre-production environment.\\nTo summarize, implementing ML in a production environment doesn't only mean deploying\\nyour model as an API for prediction. Rather, it means deploying an ML pipeline that can\\nautomate the retraining and deployment of new models. Setting up a CI/CD system lets you\\nautomatically test and deploy new pipeline implementations. This system lets you cope\\nwith rapid changes in your data and business environment. You don't have to immediately\"],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6565175565175564,\n",
       "    'reason': \"The score is 0.66 because the relevant nodes (nodes 1, 3, 5, and 7) are ranked higher than irrelevant nodes (nodes 2, 4, 6, and 8-10), with a clear distinction between the two groups. The reasons for the 'yes' verdicts highlight direct connections to the expected output's mentions of 'versionar modelos', 'rastrear artefatos', 'garantir rollback seguro', 'producir resultados', and 'identificar os melhores modelos'. In contrast, the 'no' verdicts are justified by the lack of information about specific topics, such as reproducing experiment results, ensuring rollback security, or testing model predictions.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'versionar modelos\\', which directly relates to the expected output\\'s mention of \\'versionar modelos permite rastrear artefatos\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the importance of versioning models in terms of reproducing experiment results or ensuring rollback security.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of tracking and managing different versions of data, which aligns with the expected output\\'s mention of \\'rastrear artefatos\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the cost of analyzing improvements to a model in the future.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'mitigation strategies\\' and \\'augmentmato learn\\', which are relevant to the expected output\\'s mention of \\'garantir rollback seguro\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about undeclared consumers or silent usage of model outputs.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of monitoring for model drift and ensuring the accuracy and reliability of models, which aligns with the expected output\\'s mention of \\'producir resultados\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about testing or validating model predictions.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'A/B testing\\' and \\'introduzir novos modelos\\', which are relevant to the expected output\\'s mention of \\'identificar os melhores modelos\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about data versioning or feature stores.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of tracking and managing different versions of data, which aligns with the expected output\\'s mention of \\'rastrear artefatos\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about maintaining and tracking experiments or optimizing model performance.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5217391304347826,\n",
       "    'reason': 'The score is 0.52 because the contextual recall score indicates that most of the sentences in the expected output are well-matched to nodes in the retrieval context, with some minor discrepancies.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Versionar modelos permite rastrear artefatos, reproduzir experimentos, auditar previs\\\\u00f5es e garantir rollback seguro.\\' matches the phrase \\'Version control is a significant aspect of ML Ops\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'more expensive to analyze improvements to that model in the f uture.\\' matches the phrase \\'The cost increases when correction models are cascaded...\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Undeclared Consumers. Oftentimes, a prediction from a machine learning model mais made widely accessible...\\' matches the phrase \\'Without access controls, some of these consu mers may be undeclared, silently using the output of a given model as an input to another system.\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Monit oring identifies model drif t over time. Without model monitoring, production systems are flying blind.\\' matches the phrase \\'By monitoring for model drift the data science team is able to proactively work rather than reactively.\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Testing ensur es the accuracy and r eliability o f models. Validating both the model\\\\u2019s predictions and the data sets used is a fundamental step in greenlighting models for production.\\' matches the phrase \\'Validating both the model\\\\u2019s predictions and the data sets used is a fundamental step in greenlighting models for production.\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Use A/B t esting t o identif y best models. A/B testing is sometimes overlooked in Machine Learning but is a great way to introduce new models.\\' matches the phrase \\'A/B testing is sometimes overlooked in Machine Learning but is a great way to introduce new models.\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'4. Version Contr ol\\' matches the phrase \\'Version control is a significant aspect of ML Ops.\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis. It involves tracking and managing different versions of the data...\\' matches the phrase \\'Version control is a significant aspect of ML Ops.\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'The concept of a feature store is then introduced as a centralized repository for storing and managing features used in model training.\\' matches the phrase \\'By having a dedicated system for feature management, teams can ensure they use the most relevant and up-to-date features.\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Model development is a core phase in the data science process, focusing on constructing and refining machine learning models.\\' matches the phrase \\'Model development is a core phase in the data science process...\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'An essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations...\\' matches the phrase \\'Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches.\\' in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Collaboration and governance\\\\nCreating a streamlined and efficient workflow needs the adoption of several practices and tools, among which version control stands as a cornerstone.\\' matches the phrase \\'Using systems like Git, teams can meticulously track and manage changes in code, data and models.\\' in the retrieval context.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.9090909090909091,\n",
       "    'reason': \"The score is 0.91 because the retrieval context contains relevant statements about model development, monitoring, and versioning, which are all related to the importance of versioning models. For example, 'Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis.' and 'Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.' These statements demonstrate the relevance of the retrieval context to the input question.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"more expensive to analyze improvements to that model in the future.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The cost increases when correction models are cascaded, with a model for problem A\\\\u2032\\\\u2032learned on top of m\\\\u2032 a, and so on, for several slightly different test distributions.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Once in place, a correction cascade can create an improvement deadlock, as improving the accuracy of any individual component actually leads to system-level detriments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Mitigation strategies are to augment learn the corrections directly within the same model by adding features to distinguish among the cases, or to accept the cost of creating a separate model for A\\\\u2032.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Undeclared Consumers. Oftentimes, a prediction from a machine learning model mais made widely accessible, either at runtime or by writing to \\\\ufb01les or logs that may later be consumed by other systems.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without access controls, some of these consu mers may be undeclared , silently using the output of a given model as an input to another system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In mo re classical software engineering,\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'In mo re classical software engineering,\\' when it has nothing to do with versioning models.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous Integration.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monit oring identifies model drif t over time.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without model monitoring, production systems are flying blind.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By monitoring for model drift the data science team is able to proactively work rather than reactively.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing ensur es the accuracy and r eliability o f models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Validating both the model\\\\u2019s predictions and the data sets used is a fundamental step in greenlighting models for production.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Use A/B t esting t o identif y best models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A/B testing is sometimes overlooked in Machine Learning but is a great way to introduce new models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Rather than swapping models out straight away you can introduce the new model alongside the old. This weighted approach allows you to see the efficacy of the new model in production before committing to it.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Version Contr ol\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Version Control\\' when it has nothing to do with the importance of versioning models.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It involves tracking and managing different versions of the data, allowing for traceability of results and the ability to revert to previous states if necessary.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The concept of a feature store is then introduced as a centralized repository for storing and managing features used in model training.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Feature stores promote consistency and reusability of features across different models and projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By having a dedicated system for feature management, teams can ensure they use the most relevant and up-to-date features.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Model development\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model development is a core phase in the data science process, focusing on constructing and refining machine learning models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"An essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This process helps optimize model performance and ensures that the development process is transparent and reproducible.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Collaboration and governance\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Using systems like Git, teams can meticulously track and manage changes in code, data and models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Fostering a collaborative environment makes it easier for team members to work together on projects and ensures that any modifications can be documented and reversed when needed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The ability to roll back to previous versions is invaluable, especially when new changes introduce errors or reduce the effectiveness of the models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about the importance of versioning models, making all statements highly relevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Versioning models is important because it guarantees rastreabilidade.\",\\n    \"It facilitates reproducibility by allowing us to go back exactly to the initial point (data, code, configurations) that generated a specific version.\",\\n    \"Versioning prevents regression in performance by keeping a detailed record of all iterations and comparing different versions easily.\",\\n    \"It promotes consistency by ensuring that, over time, different parts of the project (models, data, code) can be referenced consistently and reliably.\",\\n    \"Versioning supports better engineering practices alongside data version control and the use of systems like Git, promoting a more organized and collaborative workflow in ML Ops.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"Evidence suggests that model improvements are more expensive to analyze in the future.\",\\n    \"The cost of analyzing model improvements increases when correction models are cascaded.\",\\n    \"A correction cascade can create an improvement deadlock, as improving the accuracy of any individual component actually leads to system-level detriments.\",\\n    \"Mitigation strategies for improvement deadlocks include augmenting to learn corrections directly within the same model or creating a separate model for A‚Ä≤.\",\\n    \"Some predictions from machine learning models may be made widely accessible without access controls, allowing undeclared consumers to use the output as an input to another system.\",\\n    \"Model monitoring is necessary to identify model drift over time and ensure proactive work rather than reactive.\",\\n    \"Testing ensures the accuracy and reliability of models by validating both the model\\'s predictions and the data sets used.\",\\n    \"A/B testing can be used to identify the best models by introducing new models alongside old ones and weighing their efficacy in production.\",\\n    \"Version control is a significant aspect of ML Ops, allowing teams to track changes in code, data, and models.\",\\n    \"Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis by tracking and managing different versions of the data.\",\\n    \"A feature store can be used as a centralized repository for storing and managing features used in model training, promoting consistency and reusability across different models and projects.\",\\n    \"Model development is a core phase in the data science process, focusing on constructing and refining machine learning models.\",\\n    \"Maintaining and tracking experiments is an essential aspect of model development, involving keeping detailed records of different model iterations, hyperparameter configurations used, and outcomes of various experiments.\",\\n    \"Fostering a collaborative environment through version control systems like Git can facilitate teamwork and ensure that modifications can be documented and reversed when needed.\"\\n] \\n \\nClaims:\\n[\\n    \"O versionamento de modelos √© importante porque garante rastreabilidade.\",\\n    \"O versionamento de modelos √© importante porque facilita a reprodu√ß√£o.\",\\n    \"O versionamento de modelos √© importante porque evita regress√£o no desempenho.\",\\n    \"O versionamento de modelos √© importante porque promove consist√™ncia.\",\\n    \"O versionamento de modelos √© importante porque suporta melhores pr√°ticas de engenharia.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'Por que versionar modelos √© importante?',\n",
       "  'actual_output': 'O versionamento de modelos √© importante porque:\\n\\n1.  **Garante Rastreabilidade:** Permite saber exatamente quais dados e quais configura√ß√µes foram usados para treinar uma vers√£o espec√≠fica do modelo. Isso √© crucial para entender por que um modelo obteve determinados resultados.\\n\\n2.  **Facilita a Reprodutibilidade:** Se um modelo come√ßa a ter problemas ou se quisermos replicar um resultado espec√≠fico, o versionamento permite voltar exatamente ao ponto inicial (dados, c√≥digo, configura√ß√µes) que gerou aquela vers√£o.\\n\\n3.  **Evita Regress√£o no Desempenho:** Ao manter um registro detalhado de todas as itera√ß√µes, √© poss√≠vel comparar facilmente diferentes vers√µes do modelo e identificar quando (e por qu√™) o desempenho melhorou ou piorou.\\n\\n4.  **Promove Consist√™ncia:** Garante que, ao longo do tempo, diferentes partes do projeto (modelos, dados, c√≥digo) possam ser referenciadas de forma consistente e confi√°vel.\\n\\n5.  **Suporta Melhores Pr√°ticas de Engenharia:** Juntamente com o controle de vers√£o de dados e o uso de sistemas como Git, o versionamento de modelos √© uma parte fundamental das melhores pr√°ticas de ML Ops (Machine Learning Operations), promovendo um fluxo de trabalho mais organizado e colaborativo.\\n\\nEm resumo, o versionamento ajuda a manter o controle do desenvolvimento do modelo, entender seu hist√≥rico de sucesso ou insucesso e garantir que mudan√ßas possam ser feitas de forma confi√°vel e audit√°vel.',\n",
       "  'expected_output': 'Versionar modelos permite rastrear artefatos, reproduzir experimentos, auditar previs√µes e garantir rollback seguro.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['more expensive to analyze improvements to that model in the f uture. The cost increases when\\ncorrection models are cascaded, with a model for problem A‚Ä≤‚Ä≤learned on top of m‚Ä≤\\na, and so on,\\nfor several slightly different test distributions. Once in place, a correction cascade can create an\\nimprovement deadlock, as improving the accuracy of any indi vidual component actually leads to\\nsystem-level detriments. Mitigation strategies are to aug mentmato learn the corrections directly\\nwithin the same model by adding features to distinguish amon g the cases, or to accept the cost of\\ncreating a separate model for A‚Ä≤.\\nUndeclared Consumers. Oftentimes, a prediction from a machine learning model mais made\\nwidely accessible, either at runtime or by writing to Ô¨Åles or logs that may later be consumed by\\nother systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,',\n",
       "   'Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track',\n",
       "   'Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis. It involves tracking and managing different versions of the data, allowing for traceability of results and the ability to revert to previous states if necessary. Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\\n\\nThe concept of a feature store is then introduced as a centralized repository for storing and managing features used in model training. Feature stores promote consistency and reusability of features across different models and projects. By having a dedicated system for feature management, teams can ensure they use the most relevant and up-to-date features.\\n\\nModel development',\n",
       "   'Model development\\n\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks. The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\n\\nAn essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments. Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.',\n",
       "   'Collaboration and governance\\n\\nCreating a streamlined and efficient workflow needs the adoption of several practices and tools, among which version control stands as a cornerstone. Using systems like Git, teams can meticulously track and manage changes in code, data and models. Fostering a collaborative environment makes it easier for team members to work together on projects and ensures that any modifications can be documented and reversed when needed. The ability to roll back to previous versions is invaluable, especially when new changes introduce errors or reduce the effectiveness of the models.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8541666666666666,\n",
       "    'reason': \"The score is 0.85 because although there are some irrelevant nodes (nodes 3 and 6) that should be ranked lower than the relevant ones, the retrieval contexts effectively distinguish between them by providing clear reasons for their relevance or irrelevance to the input question 'O que √© um pipeline de ML?'\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions the development lifecycle of data science projects, which includes stages like data acquisition, preprocessing, feature engineering, model training, evaluation, deployment, and monitoring. This directly relates to the expected output\\'s description of a pipeline as an automated flow that encompasses these stages.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of optimizing performance in ML Ops, which aligns with the expected output\\'s mention of a pipeline as a continuous training procedure that produces a model as output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not provide any information about Einstein or his Nobel Prize, making it irrelevant to the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains the development lifecycle of data science projects and mentions the importance of optimizing performance in ML Ops, which is directly related to the expected output\\'s description of a pipeline as an automated flow that encompasses various stages.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not provide any information about the expected output\\'s mention of \\'fluxo automatizado\\' or \\'MLOps process\\', making it irrelevant to the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of optimizing performance in ML Ops and mentions the need for real-time monitoring and alerting systems, which aligns with the expected output\\'s description of a pipeline as an automated flow that produces a model as output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not provide any information about the expected output\\'s mention of \\'Einstein won the Nobel Prize in 1968 for his discovery of the photoelectric effect\\', making it irrelevant to the expected output.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.9,\n",
       "    'reason': 'The score is 0.90 because the contextual recall score indicates a strong match between the expected output and the nodes in the retrieval context, with most sentences aligning well with specific nodes, demonstrating a high degree of relevance.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 1st node in the retrieval context: \\'flow:\\\\n1. The core activity during this ML development phase is experimentation...\\' which mentions the concept of experimentation and data scientists, aligning with the given sentence.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence does not contain any specific nodes or parts from the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 2nd node in the retrieval context: \\'aging these pipelines, detecting errors and recovering fro m failures are all dif\\\\ufb01cult and costly...\\' which discusses the challenges of pipeline maintenance, aligning with the given sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 3rd node in the retrieval context: \\'Pipeline jungles can only be avoided by thinking holistical ly about data collection and feature ex-\\\\ntraction...\\' which talks about pipeline maintenance and optimization, aligning with the given sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 4th node in the retrieval context: \\'Glue code and pipeline jungles are symptomatic of integrati on issues that may have a root cause in\\\\noverly separated \\\\u201cresearch\\\\u201d and \\\\u201cengineering\\\\u201d roles...\\' which discusses integration issues, aligning with the given sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 5th node in the retrieval context: \\'To understand ML Ops, it\\\\u2019s essential to be familiar with the development\\\\nlifecycle of data science projects...\\' which discusses the concept of ML Ops and its relation to data science projects, aligning with the given sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 6th node in the retrieval context: \\'A typical data science project consists of\\\\nseveral stages:\\\\n1. Data acquisition...\\' which discusses the development lifecycle of data science projects, aligning with the given sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 7th node in the retrieval context: \\'Optimising performance of data pipelines and models is a crucial aspect\\\\nof ML Ops...\\' which discusses the importance of optimizing data pipeline and model performance, aligning with the given sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 8th node in the retrieval context: \\'MLOps Ar chitectur e and Design\\\\nThe ML Ops architecture comprises several components...\\' which discusses the concept of ML Ops architecture, aligning with the given sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 9th node in the retrieval context: \\'Takeaway. The MLOps anti-patterns described in this section re-\\\\nveal that ML engineering, as a field, is changing faster than educa-\\\\ntional resources can keep up...\\' which discusses the concept of ML Ops and its relation to educational resources, aligning with the given sentence.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.9166666666666666,\n",
       "    'reason': \"The score is 0.92 because the retrieval context contains relevant statements about machine learning development phases, experimentation, and pipeline management, which are closely related to the input question about what a pipeline of ML is. For example, the statement 'If the ML system requires continuous training (repeated retraining of the model), the training procedure is operationalized as a training pipeline.' directly addresses the concept of a pipeline in ML.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"The core activity during this ML development phase is experimentation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"As data scientists and ML research -ers prototype model architectures and training routines, they create labeled datasets, and they use features and other reusable ML artifacts that are governed through the data and model management process.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The primary output of this process is a formalized training procedure, which includes data preprocessing, model architecture, and model training settings.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"If the ML system requires continuous training (repeated retraining of the model), the training procedure is operationalized as a training pipeline.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This requires a CI/CD routine to build, test, and deploy the pipeline to the target execution environment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The continuous training pipeline is executed repeatedly based on retraining triggers, and it produces a model as output.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The model is retrained as new data becomes available, or if model performance decay is detected.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"aging these pipelines, detecting errors and recovering from failures are all difficult and costly.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing such pipelines often requires expensive end-to-end integration tests.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Pipeline jungles can only be avoided by thinking holistically about data collection and feature extraction.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground up is indeed a major investment of engineering effort, but one that can dramatically reduce ongoing costs and speed further innovation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Glue code and pipeline jungles are symptomatic of integration issues that may have a root cause in overly separated \\\\u201cresearch\\\\u201d and \\\\u201cengineering\\\\u201d roles.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"When ML packages are developed in an ivory-tower setting, the result may appear like black boxes to the teams that employ them in practice.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A hybrid research approach where engineers and researchers are embedded together on the same teams\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'A hybrid research approach...\\' when it has nothing to do with what is a pipeline of ML.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A typical data science project consists of several stages:\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data acquisition: Obtaining raw data from various sources, such as databases, sensors, or external APIs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data preprocessing: Cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Featur e engineering: Selecting the most relevant data attributes, or \\\\u201cfeatures,\\\\u201d and converting them into a suitable format for ML algorithms.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model training: Applying ML algorithms to the preprocessed data to create a predictive model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model evaluation: Assessing the performance of the model and making adjustments to improve its accuracy.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model deployment: Implementing the ML model into a product, service, or system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring and maintenance: Continuously monitoring the performance of the ML model and updating it as needed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Optimising Data Pipeline and Model Performance\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Implement robust data preprocessing techniques to clean and transform input data efficiently.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Use automated feature engineering to select relevant features, reducing the risk of overfitting and enhancing overall model performance.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Implement real-time monitoring and alerting systems for pipelines and models, facilitating prompt identification and resolution of issues.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps Architecture and Tools\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps Architecture and Design\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The ML Ops architecture comprises several components, including data collection , data pre p, model training, validation, and deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A well-designed architecture ensures smooth collaboration between different\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'smooth collaboration\\' when it has nothing to do with the definition of MLOps.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Takeaway. The MLOps anti-patterns described in this section re-veal that ML engineering, as a field, is changing faster than educational resources can keep up.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"We see this as opportunities for new resources, such as classroom material (e.g., textbooks, courses) to prescribe the right engineering practices and rigor for the highly experimental discipline that is production ML, and automated documentation assistance for ML pipelines in organizations.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps tool builders may be interested in an organization of the dozens of tools, libraries, and services MLEs use to run ML and data processing pipelines.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Although multiple MLEs reported having to \\\\u201cglue\\\\u201d open-source solutions together and having to build \\\\u201chomegrown\\\\u201d infrastructure as part of their work (P1, P2, P5, P6, P10, P12),\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"an analysis of the various deployments reveals that tools Shreya Shankar\\\\u2217, Rolando Garcia\\\\u2217, Joseph M. Hellerstein, Aditya G. Parameswaran Run Layer\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement appears to be a reference list or author credits, which is not relevant to the input question about what a pipeline of ML is.\"\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the answer directly addresses the question about what a machine learning (ML) pipeline is, making it highly relevant and accurate.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"A pipeline of ML is an automated workflow that connects all necessary steps to build, train, and deploy a machine learning model.\",\\n    \"It integrates processes such as data acquisition, preprocessing, feature engineering, training the model, evaluation, and deployment, ensuring the model is delivered efficiently and repeatedly.\",\\n    \"The main stages of a pipeline of ML are: Data Acquisition, Data Preprocessing, Feature Engineering, Model Training, Model Evaluation, Model Deployment, and Monitoring and Maintenance.\",\\n    \"In some cases, the pipeline can be configured for continuous training, where the model is retrained repeatedly when new data or changes in performance are detected.\",\\n    \"The objective of a pipeline of ML is to automate and connect these stages, reducing the need for manual coding (\\'glue code\\') and avoiding the formation of \\'jungles of pipelines\\' (multiplicity of disorganized scripts).\",\\n    \"This facilitates collaboration between researchers and engineers and accelerates the development of ML systems in production.\",\\n    \"A pipeline of ML can function as a production line, where each stage is executed sequentially to transform data into a functional model.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The core activity during ML development phase is experimentation.\",\\n    \"As data scientists and ML researchers prototype model architectures and training routines, they create labeled datasets, and they use features and other reusable ML artifacts that are governed through the data and model management process.\",\\n    \"The primary output of this process is a formalized training procedure, which includes data preprocessing, model architecture, and model training settings.\",\\n    \"If the ML system requires continuous training (repeated retraining of the model), the training procedure is operationalized as a training pipeline.\",\\n    \"A CI/CD routine is required to build, test, and deploy the pipeline to the target execution environment.\",\\n    \"The continuous training pipeline is executed repeatedly based on retraining triggers, and it produces a model as output.\",\\n    \"The model is retrained as new data becomes available, or if model performance decay is detected.\",\\n    \"Testing such pipelines often requires expensive end-to-end integration tests.\",\\n    \"Aging these pipelines can only be avoided by thinking holistically about data collection and feature extraction.\",\\n    \"Pipelines jungles can be avoided by redesigning from the ground up, which can dramatically reduce ongoing costs and speed further innovation.\",\\n    \"Glue code and pipeline jungles are symptomatic of integration issues that may have a root cause in overly separated \\'research\\' and \\'engineering\\' roles.\",\\n    \"A hybrid research approach where engineers and researchers are embedded together on the same teams can help avoid these issues.\",\\n    \"The development lifecycle of data science projects consists of several stages: data acquisition, data preprocessing, feature engineering, model training, model evaluation, model deployment, and monitoring and maintenance.\",\\n    \"Optimizing performance of data pipelines and models is a crucial aspect of ML Ops.\",\\n    \"Organisations can implement robust data preprocessing techniques to clean and transform input data efficiently.\",\\n    \"Automated feature engineering can be used to select relevant features, reducing the risk of overfitting and enhancing overall model performance.\",\\n    \"Real-time monitoring and alerting systems for pipelines and models can facilitate prompt identification and resolution of issues.\",\\n    \"The ML Ops architecture comprises several components, including data collection, data preprocessing, model training, validation, and deployment.\",\\n    \"A well-designed architecture ensures smooth collaboration between different teams.\",\\n    \"The MLOps anti-patterns described in this section reveal that ML engineering, as a field, is changing faster than educational resources can keep up.\",\\n    \"MLEs use dozens of tools, libraries, and services to run ML and data processing pipelines.\"\\n] \\n \\nClaims:\\n[\\n    \"A **pipeline de ML** is a automated workflow that connects all necessary steps to build, train and deploy a machine learning model.\",\\n    \"It integrates processes such as data acquisition, preprocessing, feature engineering, training the model, evaluation and deployment, ensuring the model is delivered efficiently and repeatedly.\",\\n    \"The main stages of a pipeline de ML are: Data Acquisition, Data Preprocessing, Feature Engineering, Model Training, Model Evaluation, Model Deployment, Monitoring and Maintenance.\",\\n    \"A pipeline de ML can be configured for continuous training, where the model is retrained repeatedly when new data or changes in performance are detected.\",\\n    \"The objective of a pipeline de ML is to automate and connect these stages, reducing the need for manual coding (\\'glue code\\') and avoiding the formation of \\'jungles of pipelines\\' (multiplicity of disorganized scripts).\",\\n    \"A pipeline de ML can function as a production line, where each stage is executed sequentially to transform data into a functional model.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© um pipeline de ML?',\n",
       "  'actual_output': 'Um **pipeline de ML** √© um fluxo de trabalho automatizado que conecta todas as etapas necess√°rias para construir, treinar e implantar um modelo de machine learning. Ele integra processos como aquisi√ß√£o de dados, pr√©-processamento, engenharia de caracter√≠sticas, treinamento do modelo, avalia√ß√£o e implanta√ß√£o, garantindo que o modelo seja entregue de forma eficiente e repet√≠vel.\\n\\n### Principais etapas de um pipeline de ML:\\n1. **Data Acquisition**: Obten√ß√£o de dados brutos de diversas fontes.\\n2. **Data Preprocessing**: Limpeza, transforma√ß√£o e prepara√ß√£o dos dados.\\n3. **Feature Engineering**: Sele√ß√£o e formata√ß√£o das caracter√≠sticas mais relevantes.\\n4. **Model Training**: Aplica√ß√£o de algoritmos de ML aos dados preparados.\\n5. **Model Evaluation**: Avalia√ß√£o da performance do modelo.\\n6. **Model Deployment**: Implanta√ß√£o do modelo em produ√ß√£o.\\n7. **Monitoring and Maintenance**: Monitoramento cont√≠nuo e atualiza√ß√µes peri√≥dicas.\\n\\n### Pipeline de Treinamento Cont√≠nuo\\nEm alguns casos, o pipeline pode ser configurado para **treinamento cont√≠nuo**, onde o modelo √© retrainido repetidamente quando novos dados ou mudan√ßas no desempenho forem detectados. Isso garante que o modelo permane√ßa preciso e relevante ao longo do tempo.\\n\\n### Objetivo\\nO pipeline de ML automatiza e conecta essas etapas, reduzindo a necessidade de codifica√ß√£o manual (\"glue code\") e evitando a forma√ß√£o de \"jungles de pipelines\" (multiplicidade de scripts desorganizados). Isso facilita a colabora√ß√£o entre pesquisadores e engenheiros e acelera o desenvolvimento de sistemas de ML em produ√ß√£o.\\n\\nExemplo pr√°tico: Um pipeline de ML pode funcionar como uma linha de produ√ß√£o, onde cada etapa √© executada sequencialmente para transformar dados em um modelo funcional. üîÑ',\n",
       "  'expected_output': '√â um fluxo automatizado que engloba etapas como ingest√£o, processamento, feature engineering, treinamento, avalia√ß√£o e deploy.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['flow:\\n1. The core activity during this ML development phase is experimentation. As data scientists and ML research -\\ners prototype model architectures and training routines, they create labeled datasets, and they use features \\nand other reusable ML artifacts that are governed through the data and model management process. The \\nFigure 3. The MLOps process\\n9\\nprimary output of this process is a formalized training procedure, which includes data preprocessing, model \\narchitecture, and model training settings. \\n2. If the ML system requires continuous training (repeated retraining of the model), the training procedure is \\noperationalized as a training pipeline. This requires a CI/CD routine to build, test, and deploy the pipeline to \\nthe target execution environment.\\n3. The continuous training pipeline is executed repeatedly based on retraining triggers, and it produces a model \\nas output. The model is retrained as new data becomes available, or if model performance decay is detected.',\n",
       "   'aging these pipelines, detecting errors and recovering fro m failures are all difÔ¨Åcult and costly .\\nTesting such pipelines often requires expensive end-to-en d integration tests. All of this adds to\\ntechnical debt of a system and makes further innovation more costly.\\nPipeline jungles can only be avoided by thinking holistical ly about data collection and feature ex-\\ntraction. The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground\\nup is indeed a major investment of engineering effort, but on e that can dramatically reduce ongoing\\ncosts and speed further innovation.\\nGlue code and pipeline jungles are symptomatic of integrati on issues that may have a root cause in\\noverly separated ‚Äúresearch‚Äù and ‚Äúengineering‚Äù roles. When M L packages are developed in an ivory-\\ntower setting, the result may appear like black boxes to the t eams that employ them in practice. A\\nhybrid research approach where engineers and researchers a re embedded together on the same teams',\n",
       "   'https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.',\n",
       "   'Optimising Data Pipeline and Model P erformance\\nOptimising performance of data pipelines and models is a crucial aspect\\nof ML Ops. T o address performance-related challenges, organisations can:\\nImplement robust data preprocessing techniques to clean and\\ntransform input data efficiently.\\nUse automated feature engineering to select relevant features,\\nreducing the risk of overfitting and enhancing overall model\\nperformance.\\nImplement real-time monitoring and alerting systems for pipelines\\nand models, facilitating prompt identification and resolution of issues.\\nMLOps Ar chitectur e and T ools\\nMLOps Ar chitectur e and Design\\nThe ML Ops architecture comprises several components, including data\\ncollection , data pr ep, model training, validation, and deployment. A well-11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations\\nhttps://mlopsnow.com/blog/what-is-mlops/ 7/11\\ndesigned architecture ensures smooth collaboration between different',\n",
       "   'Takeaway. The MLOps anti-patterns described in this section re-\\nveal that ML engineering, as a field, is changing faster than educa-\\ntional resources can keep up. We see this as opportunities for new\\nresources, such as classroom material (e.g., textbooks, courses) to\\nprescribe the right engineering practices and rigor for the highly\\nexperimental discipline that is production ML, and automated doc-\\numentation assistance for ML pipelines in organizations.\\n5.3 Characterizing the ‚ÄúMLOps Stack‚Äù for Tool\\nBuilders\\nMLOps tool builders may be interested in an organization of the\\ndozens of tools, libraries, and services MLEs use to run ML and\\ndata processing pipelines. Although multiple MLEs reported hav-\\ning to ‚Äúglue‚Äù open-source solutions together and having to build\\n‚Äúhomegrown‚Äù infrastructure as part of their work (P1, P2, P5, P6,\\nP10, P12), an analysis of the various deployments reveals that tools\\nShreya Shankar‚àó, Rolando Garcia‚àó, Joseph M. Hellerstein, Aditya G. Parameswaran\\nRun Layer'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': \"The score is 0.50 because irrelevant nodes (nodes 1 and 3) are ranked lower than relevant nodes (nodes 2 and 4), indicating that contextual precision is moderate, as some 'no' verdicts are correctly placed below the 'yes' verdicts.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not mention reproducibility in machine learning.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions the importance of measuring business metrics, which is related to reproducibility in ML.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not mention anything about reproducing results using the same code, data, and parameters.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions the importance of formalizing ML training procedures and implementing an end-to-end pipeline, which is related to reproducibility in ML.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not mention anything about reproducing results using the same code, data, and parameters.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5454545454545454,\n",
       "    'reason': 'The score is 0.55 because the contextual recall successfully captures some of the key concepts related to ML Ops, such as experimentation and artifact tracking, but still lacks a comprehensive understanding of the topic, failing to fully attribute sentences like the one about reproducing results using the same code, data, and parameters.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Building an ML-enabled system is a multifaceted undertaking that combines data engineering, ML engineering, and application engineering tasks...\\' (1st sentence)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'\\\\u2022 Support various data modalities, including tabular data, images, and text.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'ML metadata and artifact tracking\\\\nVarious types of ML artifacts are produced in different processes of the MLOps lifecycle...\\' (1st sentence)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'subset of MLOps capability services.\\\\nML development\\\\nExperimentation is the core activity in ML development...\\' (1st sentence)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node: \\'rather than ML-specific metrics alone like MAP (P5, P7, P15, P16,\\\\nP11, P17, P18, P19). The need to evaluate product-critical metrics...\\' (1st sentence)\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5121951219512195,\n",
       "    'reason': \"The score is 0.51 because the retrieval context does not mention ML reproducibility, which is the topic of the input question 'O que √© reprodutibilidade em ML?' The relevant statements in the retrieval context are about data science projects, model training, and deployment, but do not relate to reproducibility.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A typical data science project consists of several stages: 1. Data acquisition: Obtaining raw data from various sources, such as databases, sensors, or external APIs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"2. Data preprocessing: Cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"3. Feature engineering: Selecting the most relevant data attributes, or \\\\u201cfeatures,\\\\u201d and converting them into a suitable format for ML algorithms.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Model training: Applying ML algorithms to the preprocessed data to create a predictive model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"5. Model evaluation: Assessing the performance of the model and making adjustments to improve its accuracy.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"6. Model deployment: Implementing the ML model into a product, service, or system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"7. Monitoring and maintenance: Continuously monitoring the performance of the ML model and updating it as needed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Building an ML-enabled system\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data engineering involves ingesting, integrating, curating, and refining data to facilitate a broad spectrum of operational tasks, data analytics tasks, and ML tasks.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"If an organization does not have robust data engineering processes and technologies, it might not be set up for success with downstream business intelligence, advanced analytics, or ML projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML models are built and deployed in production using curated data that is usually created by the data engineering team.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The models do not operate in silos; they are components of, and support, a large range of application systems, such as business intelligence systems, line of business applications, process control systems, and embedded systems\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Support various data modalities, including tabular data, images, and text.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML data assets can be managed at the entity features level or at the full dataset level.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For example, a feature repository might contain an entity called customer, which includes features like age group, postal code, and gender.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"On the other hand, a dataset repository might include a customer churn dataset, which includes features from the customer and product entities, as well as purchase- and web-activity event logs.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML metadata and artifact tracking\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Various types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive statistics and data schemas, trained models, and evaluation results.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML metadata is the information about these artifacts, including their location, types, properties, and associations to experiments and runs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"subset of MLOps capability services.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML development\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Experimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for data preparation and ML modeling.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Experimentation starts when the ML use case is well defined, meaning that the following questions have been answered:\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The context does not mention Einstein\\'s achievements.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 What is the task?\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 How can we measure business impact?\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 What is the evaluation metric?\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 What is the relevant data?\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 What are the training and serving requirements?\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Figure 5. The ML development process\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"17\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 What is the task?\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"During experimentation, data scientists typically perform the following steps:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"rather than ML-specific metrics alone like MAP (P5, P7, P15, P16, P11, P17, P18, P19).\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The need to evaluate product-critical metrics stemmed from close collaboration with other stakeholders, such as product managers and business operators.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P11 felt that a key reason many ML projects fail is that they don\\\\u2019t measure metrics that will yield the organization value:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Tying to the business\\\\u2019s KPIs (key performance indicators) is really important.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"But it\\\\u2019s a process\\\\u2014you need to figure out what are, and frankly I think that\\\\u2019s how people should be doing AI.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It like: hey, let\\\\u2019s do these experiments and get cool numbers and show off these nice precision-recall curves to our bosses and call it a day.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It should be like: hey, let\\\\u2019s actually show the same business metrics that everyone else is held accountable to to our bosses at the end of the day.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Since product-specific metrics are, by definition, different for different ML models, it was important for engineers to treat choices-\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': False,\n",
       "    'score': 0.5,\n",
       "    'reason': \"The score is 0.50 because the model's response partially addressed the question, but included an irrelevant statement about not finding specific information on reproducibility in ML.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"I didn\\'t find specific information about \\'reproducibility in ML\\' in the given context.\",\\n    \"I can help with other questions related to MLOps or ML development, such as the stages of the life cycle, development processes, product metrics, or the importance of data curation.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"I didn\\'t find specific information about \\'reproducibility in ML\\' in the given context.\"\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6,\n",
       "    'reason': 'The score is 0.60 because the actual output does not align with the information presented in the retrieval context, as it appears to be unrelated to the development lifecycle of data science projects or ML development processes.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The development lifecycle of data science projects typically consists of 7 stages: Data acquisition, Data preprocessing, Featur e engineering, Model training, Model evaluation, Model deployment, and Monit oring and maintenance.\",\\n    \"Data engineering involves ingesting, integrating, curating, and refining data to facilitate a broad spectrum of operational tasks, data analytics tasks, and ML tasks.\",\\n    \"ML models are built and deployed in production using curated data that is usually created by the data engineering team.\",\\n    \"ML data assets can be managed at the entity features level or at the full dataset level.\",\\n    \"Various types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive statistics and data schemas, trained models, and evaluation results.\",\\n    \"ML metadata is the information about these artifacts, including their location, types, properties, and associations to experiments and runs.\",\\n    \"The core activity in ML development is experimentation, where data scientists can rapidly try several ideas for data preparation and ML modeling.\",\\n    \"Experimentation aims to arrive at an effective prototype model for the ML use case at hand.\",\\n    \"In addition to experimentation, data scientists need to formalize their ML training procedures by implementing an end-to-end pipeline.\",\\n    \"The process of ML development involves steps such as defining the task, measuring business impact, selecting relevant data, and determining training and serving requirements.\"\\n] \\n \\nClaims:\\n[\\n    \"No entanto, posso te ajudar com outras d√∫vidas relacionadas a MLOps ou o desenvolvimento de ML,\",\\n    \"como os est√°gios do ciclo de vida,\",\\n    \"processos de desenvolvimento,\",\\n    \"m√©tricas de produto,\",\\n    \"a import√¢ncia da curadoria de dados\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claim is not related to the development lifecycle of data science projects, which consists of 7 stages: Data acquisition, Data preprocessing, Feature engineering, Model training, Model evaluation, Model deployment, and Monitoring and maintenance.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claim is not related to the development lifecycle of data science projects or ML development processes.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© reprodutibilidade em ML?',\n",
       "  'actual_output': 'Infelizmente, n√£o encontrei informa√ß√µes espec√≠ficas sobre \"reprodutibilidade em ML\" no contexto fornecido.\\n\\nNo entanto, posso te ajudar com outras d√∫vidas relacionadas a MLOps ou o desenvolvimento de ML, como os est√°gios do ciclo de vida, processos de desenvolvimento, m√©tricas de produto ou a import√¢ncia da curadoria de dados. Se precisar de mais alguma informa√ß√£o sobre algum desses t√≥picos, estou √† disposi√ß√£o!',\n",
       "  'expected_output': 'Capacidade de reproduzir os mesmos resultados usando o mesmo c√≥digo, dados e par√¢metros.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.',\n",
       "   'Building an ML-enabled system\\nBuilding an ML-enabled system is a multifaceted undertaking that combines data engineering, ML engineering, and \\napplication engineering tasks, as shown in figure 1.\\nData engineering involves ingesting, integrating, curating, and refining data to facilitate a broad spectrum of opera -\\ntional tasks, data analytics tasks, and ML tasks. Data engineering can be crucial to the success of the analytics and \\nML initiatives. If an organization does not have robust data engineering processes and technologies, it might not be \\nset up for success with downstream business intelligence, advanced analytics, or ML projects.\\nML models are built and deployed in production using curated data that is usually created by the data engineering \\nteam. The models do not operate in silos; they are components of, and support, a large range of application systems, \\nsuch as business intelligence systems, line of business applications, process control systems, and embedded sys -',\n",
       "   '‚Ä¢ Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -\\ntory might contain an entity called customer, which includes features like age group, postal code, and gender. On the \\nother hand, a dataset repository might include a customer churn dataset, which includes features from the customer \\nand product entities, as well as purchase- and web-activity event logs.\\nML metadata and artifact tracking\\nVarious types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive \\nstatistics and data schemas, trained models, and evaluation results. ML metadata is the information about these \\nartifacts, including their location, types, properties, and associations to experiments and runs. The ML metadata and',\n",
       "   'subset of MLOps capability services.\\nML development\\nExperimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for \\ndata preparation and ML modeling. Experimentation starts when the ML use case is well defined, meaning that the \\nfollowing questions have been answered:\\n‚Ä¢ What is the task?\\n‚Ä¢ How can we measure business impact?\\n‚Ä¢ What is the evaluation metric?\\nFigure 5. The ML development process\\n17\\n‚Ä¢ What is the relevant data?\\n‚Ä¢ What are the training and serving requirements?\\nExperimentation aims to arrive at an effective prototype model for the ML use case at hand. In addition to experimen -\\ntation, data scientists need to formalize their ML training procedures. They do this by implementing an end-to-end \\npipeline, so that the procedures can be operationalized and run in production. Figure 5 shows the process of ML \\ndevelopment. \\nDuring experimentation, data scientists typically perform the following steps:',\n",
       "   'rather than ML-specific metrics alone like MAP (P5, P7, P15, P16,\\nP11, P17, P18, P19). The need to evaluate product-critical metrics\\nstemmed from close collaboration with other stakeholders, such\\nas product managers and business operators. P11 felt that a key\\nreason many ML projects fail is that they don‚Äôt measure metrics\\nthat will yield the organization value:\\nTying to the business‚Äôs KPIs (key\\nperformance indicators) is really important. But it‚Äôs a\\nprocess‚Äîyou need to figure out what are, and\\nfrankly I think that‚Äôs how people should be doing AI. It\\n like: hey, let‚Äôs do these experiments and\\nget cool numbers and show off these nice precision-recall\\ncurves to our bosses and call it a day. It should be like:\\nhey, let‚Äôs actually show the same business metrics that\\neveryone else is held accountable to to our bosses at the\\nend of the day.\\nSince product-specific metrics are, by definition, different for\\ndifferent ML models, it was important for engineers to treat choos-'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6787301587301586,\n",
       "    'reason': 'The score is 0.68 because irrelevant nodes, such as those discussing effort recognition and role distinctions in AI projects, are ranked lower than relevant nodes that directly address CI/CD concepts, like automation of tests and validation, packaging, and deployment of models.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions CI/CD in the context of machine learning, which is relevant to the input question.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not explicitly mention the automation of tests, validation, packaging, and deployment of models, which is a key aspect of CI/CD in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the typical steps for training and evaluating an ML model to serve as a prediction service, which is relevant to the input question.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not directly address the topic of CI/CD in ML or its application to machine learning models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions the importance of recognizing and rewarding effort in successful ML teams, which is relevant to the input question.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not explicitly discuss the automation of CI/CD processes or its application to machine learning models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the need to evaluate product-critical metrics and tie them to business KPIs, which is relevant to the input question.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not directly address the topic of CI/CD in ML or its application to machine learning models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions the importance of understanding and appreciating the distinctions between different roles in AI and ML projects, which is relevant to the input question.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not explicitly discuss the automation of CI/CD processes or its application to machine learning models.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5111111111111111,\n",
       "    'reason': 'The score is 0.51 because the contextual recall score indicates that there are some relevant sentences in the expected output that can be attributed to nodes in the retrieval context, but not all of them, suggesting a moderate level of alignment between the two.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node, \\'testing, integration testing, and continuous delivery of the software module or the package.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node, \\'However, in ML, there are a few notable differences:\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node, \\'CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node, \\'Data science steps for ML\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node, \\'Overview of MLOps lifecycle and core capabilities\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node, \\'and automate themes from Google\\\\u2019s AI Adoption Framework.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node, \\'The decision about whether (or to which degree) to adopt each of these processes and capabilities in your organization depends on your business context.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"8th node, \\'For example, you must determine the business value that the framework creates when compared to the cost of purchasing or building capabilities (for example, the cost in engineering hours).\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"9th node, \\'Moreover, 72% of a cohort of organizations that began AI pilots before 2019 have not been able to deploy even a single application in production.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"10th node, \\'Algorithmia\\\\u2019s survey of the state of enterprise machine\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"11th node, \\'achieved by a shift in team culture.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"12th node, \\'Recognizing, prioritizing, and rewarding this effort is important for the long term health of successful ML teams.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"13th node, \\'Acknowledgments This paper owes much to the important lessons learned day to day in a culture that values both innovative ML research and strong engineering practice.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"14th node, \\'Ma ny colleagues have helped shape our thoughts here, and the bene\\\\ufb01t of accumulated folk wisdom can not be overstated.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"15th node, \\'We would like to speci\\\\ufb01cally recognize the following: Roberto Bayardo, Luis Cobo, Sharat Chikkerur, Jeff Dean, Philip Henderson, Arnar Mar Hrafnkelsson, Ankur Jain, Joe Kovac, Jeremy Kubica, H. Brendan McMahan, Satyaki Mahalanabis, Lan Nie, Michael Pohl, Abdul Salem, Sajid Siddiqi, Ricky Shan, Alan Skelly, Cory Williams, and Andrew Young.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"16th node, \\'A short version of this paper was presented at the SE4ML works hop in 2014 in Montreal, Canada.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"17th node, \\'8\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"18th node, \\'rather than ML-specific metrics alone like MAP (P5, P7, P15, P16, P11, P17, P18, P19).\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"19th node, \\'The need to evaluate product-critical metrics stemmed from close collaboration with other stakeholders, such as product managers and business operators.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"20th node, \\'P11 felt that a key reason many ML projects fail is that they don\\\\u2019t measure metrics that will yield the organization value:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"21st node, \\'Tying to the business\\\\u2019s KPIs (key performance indicators) is really important. But it\\\\u2019s a process\\\\u2014you need to figure out what are, and frankly I think that\\\\u2019s how people should be doing AI.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"22nd node, \\'It should be like: hey, let\\\\u2019s actually show the same business metrics that everyone else is held accountable to to our bosses at the end of the day.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"23rd node, \\'Since product-specific metrics are, by definition, different for different ML models, it was important for engineers to treat choices-\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.3,\n",
       "    'reason': \"The score is 0.30 because the retrieval context contains irrelevant information about Google's AI Adoption Framework, digital transformation, pilots, and proofs of concept, which are not directly related to CI/CD applied to ML. The relevant statements in the context only briefly touch on the topic, but do not provide substantial information.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"testing, integration testing, and continuous delivery of the software module or the package.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"CD is no longer about a single software package or a service, but a system (an ML training pipeline) that should automatically deploy another service (model prediction service).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"CT is a new property, unique to ML systems, that\\'s concerned with automatically retraining and serving the models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The following section discusses the typical steps for training and evaluating an ML model to serve as a prediction service.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data science steps for ML\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Overview of MLOps lifecycle and core capabilities\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"and automate themes from Google\\\\u2019s AI Adoption Framework.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Google\\\\u2019s AI Adoption Framework\\' when it has nothing to do with CI/CD applied to ML.\"\\n            },\\n            {\\n                \"statement\": \"Despite the growing recognition of AI/ML as a crucial pillar of digital transformation, successful deployments and effective operations are a bottleneck for getting value from AI.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'digital transformation\\' when it has nothing to do with CI/CD applied to ML.\"\\n            },\\n            {\\n                \"statement\": \"Only one in two organizations has moved beyond pilots and proofs of concept.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'pilots and proofs of concept\\' when it has nothing to do with CI/CD applied to ML.\"\\n            },\\n            {\\n                \"statement\": \"Moreover, 72% of a cohort of organizations that began AI pilots before 2019 have not been able to deploy even a single application in production.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'AI pilots\\' when it has nothing to do with CI/CD applied to ML.\"\\n            },\\n            {\\n                \"statement\": \"Algorithmia\\\\u2019s survey of the state of enterprise machine\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Recognizing, prioritizing, and rewarding effort is important for the long term health of successful ML teams.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This paper owes much to the important lessons learned day to day in a culture that values both innovative ML research and strong engineering practice.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is not directly related to CI/CD applied to ML.\"\\n            },\\n            {\\n                \"statement\": \"Many colleagues have helped shape our thoughts here, and the benefit of accumulated folk wisdom cannot be overstated.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is not directly related to CI/CD applied to ML.\"\\n            },\\n            {\\n                \"statement\": \"We would like to specifically recognize the following: Roberto Bayardo, Luis Cobo, Sharat Chikkerur, Jeff Dean, Philip Henderson, Arnar Mar Hrafnkelsson, Ankur Jain, Joe Kovac, Jeremy Kubica, H. Brendan McMahan, Satyaki Mahalanabis, Lan Nie, Michael Pohl, Abdul Salem, Sajid Siddiqi, Ricky Shan, Alan Skelly, Cory Williams, and Andrew Young.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is not directly related to CI/CD applied to ML.\"\\n            },\\n            {\\n                \"statement\": \"A short version of this paper was presented at the SE4ML works hop in 2014 in Montreal, Canada.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is not directly related to CI/CD applied to ML.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"rather than ML-specific metrics alone like MAP (P5, P7, P15, P16, P11, P17, P18, P19).\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The need to evaluate product-critical metrics stemmed from close collaboration with other stakeholders, such as product managers and business operators.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P11 felt that a key reason many ML projects fail is that they don\\\\u2019t measure metrics that will yield the organization value:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Tying to the business\\\\u2019s KPIs (key performance indicators) is really important.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"But it\\\\u2019s a process\\\\u2014you need to figure out what are, and frankly I think that\\\\u2019s how people should be doing AI.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It like: hey, let\\\\u2019s do these experiments and get cool numbers and show off these nice precision-recall curves to our bosses and call it a day.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It should be like: hey, let\\\\u2019s actually show the same business metrics that everyone else is held accountable to to our bosses at the end of the day.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Since product-specific metrics are, by definition, different for different ML models, it was important for engineers to treat choices-\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Each role contributes significantly to the success of AI and ML projects but has unique skill sets and areas of focus.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"If you\\\\u2019re looking to become an ML Engineer check out our article about the 5 skills you need to be successful.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is not directly related to CI/CD applied to ML, but rather provides information on becoming an ML Engineer.\"\\n            },\\n            {\\n                \"statement\": \"Want to become an ML Ops master? Sign up to the ML Ops Now newsletter to get weekly ML Ops insights.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is not directly related to CI/CD applied to ML, but rather promotes a newsletter for ML Ops.\"\\n            },\\n            {\\n                \"statement\": \"Unlock your future in ML Ops with Navigating ML Ops: A Beginner\\'s Blueprint.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is not directly related to CI/CD applied to ML, but rather promotes an article on ML Ops.\"\\n            },\\n            {\\n                \"statement\": \"Other articles you might be interested in:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about CI/CD applied to Machine Learning, making all statements highly relevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"CI/CD is adapted for Machine Learning (ML) to handle its particularities, such as data and models.\",\\n    \"The main differences include validation of data and testing of models in CI.\",\\n    \"In CD, the automation focuses on implantation of training pipelines.\",\\n    \"CT (Continuous Training) is a unique property of ML that ensures models are retrained and served automatically as needed.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The statement highlights the specific challenges and requirements of Machine Learning, making it relevant to addressing the input.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"Although this statement mentions automation, it focuses on training pipelines rather than directly answering the question about CI/CD in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8,\n",
       "    'reason': \"The score is 0.80 because the actual output mentions 'implanta√ß√£o de pipelines de treinamento', which is not directly mentioned in the retrieval context, but it's a common practice in ML.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The process of delivering an ML model to production involves several steps, including defining the business use case and establishing success criteria.\",\\n    \"These steps can be completed manually or automatically by a pipeline.\",\\n    \"In ML, CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.\",\\n    \"CD in ML is not just about deploying a single software package or service, but rather an entire system (an ML training pipeline) that should automatically deploy another service (model prediction service).\",\\n    \"There is a new property unique to ML systems called CT, which is concerned with automatically retraining and serving the models.\",\\n    \"The process of delivering an ML model to production can be completed manually or automatically by a pipeline.\",\\n    \"Successful deployments and effective operations are a bottleneck for getting value from AI.\",\\n    \"Only one in two organizations has moved beyond pilots and proofs of concept.\",\\n    \"72% of a cohort of organizations that began AI pilots before 2019 have not been able to deploy even a single application in production.\",\\n    \"A shift in team culture is necessary to achieve successful ML deployments.\",\\n    \"Recognizing, prioritizing, and rewarding the effort required for successful ML teams is important for their long-term health.\",\\n    \"The importance of accumulated folk wisdom cannot be overstated.\",\\n    \"This paper owes much to the important lessons learned day-to-day in a culture that values both innovative ML research and strong engineering practice.\"\\n] \\n \\nClaims:\\n[\\n    \"No contexto do Machine Learning (ML), o CI/CD √© adaptado para lidrar com as particularidades da √°rea, como dados e modelos.\",\\n    \"Al√©m de testar e validar c√≥digo e componentes, o CI inclui: Valida√ß√£o de dados: Verifica√ß√£o de qualidade, esquemas e integridade dos dados.\",\\n    \"Testes de modelos: Garantir que os modelos atinjam os requisitos de desempenho e generaliza√ß√£o.\",\\n    \"Diferente do CD tradicional (que foca na entrega de um pacote/software), no ML a automa√ß√£o √© voltada para: Implanta√ß√£o de pipelines de treinamento: O sistema automatiza o reentrenamento e a servifica√ß√£o dos modelos.\",\\n    \"√â uma propriedade √∫nica do ML, que garante que os modelos sejam reentrenados e servidos automaticamente, conforme necess√°rio.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim mentions \\'implanta\\\\u00e7\\\\u00e3o de pipelines de treinamento\\' which is not directly mentioned in the context, but it\\'s a common practice in ML. However, the context does mention that CD in ML involves deploying an entire system (an ML training pipeline) rather than just a single software package.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© CI/CD aplicado a ML?',\n",
       "  'actual_output': 'No contexto do Machine Learning (ML), o CI/CD (Continuous Integration/Continuous Delivery) √© adaptado para lidrar com as particularidades da √°rea, como dados e modelos. Veja as principais diferen√ßas:\\n\\n### **CI no ML**  \\nAl√©m de testar e validar c√≥digo e componentes, o CI inclui:  \\n- **Valida√ß√£o de dados**: Verifica√ß√£o de qualidade, esquemas e integridade dos dados.  \\n- **Testes de modelos**: Garantir que os modelos atinjam os requisitos de desempenho e generaliza√ß√£o.  \\n\\n### **CD no ML**  \\nDiferente do CD tradicional (que foca na entrega de um pacote/software), no ML a automa√ß√£o √© voltada para:  \\n- **Implanta√ß√£o de pipelines de treinamento**: O sistema automatiza o reentrenamento e a servifica√ß√£o dos modelos.  \\n\\n### **CT (Continuous Training)**  \\n√â uma propriedade √∫nica do ML, que garante que os modelos sejam reentrenados e servidos automaticamente, conforme necess√°rio.  \\n\\nEssas adapta√ß√µes s√£o essenciais para garantir a opera√ß√£o eficiente e eficaz de sistemas de ML em produ√ß√£o.',\n",
       "  'expected_output': 'CI/CD em ML automatiza testes, valida√ß√£o, empacotamento e implanta√ß√£o de modelos, garantindo ciclos mais r√°pidos e confi√°veis.',\n",
       "  'context': None,\n",
       "  'retrieval_context': [\"testing, integration testing, and continuous delivery of the software module or the package.\\nHowever, in ML, there are a few notable differences:\\nCI is no longer only about testing and validating code and components, but also\\ntesting and validating data, data schemas, and models.\\nCD is no longer about a single software package or a service, but a system (an ML\\ntraining pipeline) that should automatically deploy another service (model prediction\\nservice).\\nCT is a new property, unique to ML systems, that's concerned with automatically\\nretraining and serving the models.\\nThe following section discusses the typical steps for training and evaluating an ML model\\nto serve as a prediction service.\\nData science steps for ML\\nIn any ML project, after you define the business use case and establish the success criteria,\\nthe process of delivering an ML model to production involves the following steps. These\\nsteps can be completed manually or can be completed by an automatic pipeline.\",\n",
       "   'and automate themes from Google‚Äôs AI Adoption Framework. The decision about whether (or to which degree) to \\nadopt each of these processes and capabilities in your organization depends on your business context. For exam -\\nple, you must determine the business value that the framework creates when compared to the cost of purchasing or \\nbuilding capabilities (for example, the cost in engineering hours).\\nOverview of MLOps lifecycle \\nand core capabilities\\nDespite the growing recognition of AI/ML as a crucial pillar of digital transformation, successful deployments and \\neffective operations are a bottleneck for getting value from AI. Only one in two organizations has moved beyond \\npilots and proofs of concept. Moreover, 72% of a cohort of organizations that began AI pilots before 2019 have not \\nbeen able to deploy even a single application in production.1 Algorithmia‚Äôs survey of the state of enterprise machine',\n",
       "   'achieved by a shift in team culture. Recognizing, prioritiz ing, and rewarding this effort is important\\nfor the long term health of successful ML teams.\\nAcknowledgments\\nThis paper owes much to the important lessons learned day to d ay in a culture that values both\\ninnovative ML research and strong engineering practice. Ma ny colleagues have helped shape our\\nthoughts here, and the beneÔ¨Åt of accumulated folk wisdom can not be overstated. We would like\\nto speciÔ¨Åcally recognize the following: Roberto Bayardo, L uis Cobo, Sharat Chikkerur, Jeff Dean,\\nPhilip Henderson, Arnar Mar Hrafnkelsson, Ankur Jain, Joe K ovac, Jeremy Kubica, H. Brendan\\nMcMahan, Satyaki Mahalanabis, Lan Nie, Michael Pohl, Abdul Salem, Sajid Siddiqi, Ricky Shan,\\nAlan Skelly, Cory Williams, and Andrew Young.\\nA short version of this paper was presented at the SE4ML works hop in 2014 in Montreal, Canada.\\n8',\n",
       "   'rather than ML-specific metrics alone like MAP (P5, P7, P15, P16,\\nP11, P17, P18, P19). The need to evaluate product-critical metrics\\nstemmed from close collaboration with other stakeholders, such\\nas product managers and business operators. P11 felt that a key\\nreason many ML projects fail is that they don‚Äôt measure metrics\\nthat will yield the organization value:\\nTying to the business‚Äôs KPIs (key\\nperformance indicators) is really important. But it‚Äôs a\\nprocess‚Äîyou need to figure out what are, and\\nfrankly I think that‚Äôs how people should be doing AI. It\\n like: hey, let‚Äôs do these experiments and\\nget cool numbers and show off these nice precision-recall\\ncurves to our bosses and call it a day. It should be like:\\nhey, let‚Äôs actually show the same business metrics that\\neveryone else is held accountable to to our bosses at the\\nend of the day.\\nSince product-specific metrics are, by definition, different for\\ndifferent ML models, it was important for engineers to treat choos-',\n",
       "   \"team. Each role contributes significantly to the success of AI and ML\\nprojects but has unique skill sets and areas of focus. By understanding and\\nappreciating these distinctions, organizations can more effectively allocate\\nresources, encourage collaboration, and drive innovation in their machine\\nlearning initiatives.\\nIf you‚Äôre looking to become an ML Engineer check out our article about\\nthe 5 skills y ou need t o be successful.\\nWant t o become an ML Ops mast er? Sign up t o the ML Ops Now\\nnewslett er to get w eekly ML Ops insights.\\nUnlock your future in ML Ops with Navigating ML Ops: A\\nBeginner' s Bluepr int.\\nOther ar ticles y ou might be int erested in:\\nYour Ultimat e Machine Learning Engineer R oadmap\\n3 ways t o learn ML Ops quickly\\nML Engineer vs Data Scientist: What' s the differ ence?\\nMLOps Engineer vs Data Scientist: What' s the differ ence?\\nMLOps Engineer vs ML Engineer : What' s the differ ence?\"],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': \"The score is 0.50 because the relevant nodes (ranked 2nd and 4th) are correctly ranked higher than irrelevant nodes (ranked 1st and 3rd), but not all 'no' verdicts are consistently ranked lower, as some are still relatively close to the top-ranked 'yes' verdict.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context does not provide any information related to monitoring a model in production.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions \\'model drift over time\\' and \\'monitoring for model drift\\', which is relevant to the topic of monitoring a model in production.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context talks about testing, validation, and A/B testing, but it does not specifically mention monitoring a model in production.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text discusses \\'model monitoring\\' as a capability that lets you track the efficiency and effectiveness of deployed models in production.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context talks about online experimentation, model registry, and metadata tracking, but it does not specifically mention monitoring a model in production.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5357142857142857,\n",
       "    'reason': 'The score is 0.54 because the contextual recall score indicates that there are some mismatches between the expected output and the nodes in the retrieval context, but overall, the model is still able to capture most of the relevant information.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Continuous Integration.\\\\nMonit oring identifies model drif t over time.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Without model monitoring,\\\\nproduction systems are flying blind.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'By monitoring for model drift the data\\\\nscience team is able to proactively work rather than reactively.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'Testing ensur es the accuracy and r eliability o f models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'Validating both\\\\nthe model\\\\u2019s predictions and the data sets used is a fundamental step in\\\\ngreenlighting models for production.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node: \\'Use A/B t esting t o identif y best models. A/B testing is sometimes\\\\noverlooked in Machine Learning but is a great way to introduce new\\\\nmodels.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node: \\'Rather than swapping models out straight away you can introduce\\\\nthe new model alongside the old. This weighted approach allows you to\\\\nsee the efficacy of the new model in production before committing to it.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"8th node: \\'4. Version Contr ol\\\\nVersion control is a significant aspect of ML Ops. It allows teams to track\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"9th node: \\'dation system has on click-throughs and on conversation rates.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"10th node: \\'The results of online experimentation should be \\\\nintegrated with the model registry capability to facilitate the decision about releasing the model to production.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"11th node: \\'Online \\\\nexperimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models \\\\nand to promote well-performing ones.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"12th node: \\'Key functionalities in online experimentation include the following:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"13th node: \\'\\\\u2022 Support canary and shadow deployments.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"14th node: \\'\\\\u2022 Support traffic splitting and A/B tests.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"15th node: \\'\\\\u2022 Support multi-armed bandit (MAB) tests.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"16th node: \\'Model monitoring\\\\nThe model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production \\\\nto ensure predictive quality and business continuity.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"17th node: \\'This capability informs you if your models are stale and need to \\\\nbe investigated and updated.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"18th node: \\'Key functionalities in model monitoring include the following:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"19th node: \\'\\\\u2022 Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"20th node: \\'\\\\u2022 Information about training, validation, and testing data splits that were used.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"21st node: \\'\\\\u2022 Model evaluation metrics and the validation procedure that was used.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"22nd node: \\'If there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\\\\ntion is submitted to the model registry.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"23rd node: \\'The model is then ready to be reviewed, approved, and deployed to the target \\\\n18\\\\nserving environment.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"24th node: \\'In addition, all the relevant metadata and artifacts \\\\nthat were produced during model development are tracked in the metadata \\\\ntracking repository.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"25th node: \\'However, in most cases, ML models need to be retrained on a regular basis \\\\nwhen new data is available or when the code changes.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"26th node: \\'In this case, the \\\\noutput of the ML development process is not the model to be deployed in \\\\nproduction.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"27th node: \\'Instead, the output is the implementation of the continuous\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"28th node: \\'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"29th node: \\'Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"30th node: \\'By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.\\'\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.875,\n",
       "    'reason': \"The score is 0.88 because despite the retrieval context containing information unrelated to monitoring a model in production, it still provides relevant statements such as 'Monit oring identifies model drift over time.' and 'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.', which are directly related to the input question.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous Integration.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monit oring identifies model drift over time.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without model monitoring, production systems are flying blind.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By monitoring for model drift the data science team is able to proactively work rather than reactively.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing ensures the accuracy and reliability of models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Validating both the model\\'s predictions and the data sets used is a fundamental step in greenlighting models for production.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Use A/B testing to identify best models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A/B testing is sometimes overlooked in Machine Learning but is a great way to introduce new models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Rather than swapping models out straight away you can introduce the new model alongside the old. This weighted approach allows you to see the efficacy of the new model in production before committing to it.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Version Control\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"The results of online experimentation should be integrated with the model registry capability to facilitate the decision about releasing the model to production.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Online experimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models and to promote well-performing ones.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Support canary and shadow deployments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Support traffic splitting and A/B tests.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Support multi-armed bandit (MAB) tests.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model monitoring\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The context does not provide any specific information about model monitoring, and the input question is unrelated to this topic.\"\\n            },\\n            {\\n                \"statement\": \"This capability informs you if your models are stale and need to be investigated and updated.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Hyperparameters, including trials of automated hyperparameter tuning and model selection.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Information about training, validation, and testing data splits that were used.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model evaluation metrics and the validation procedure that was used.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"If there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'experimentation\\' when it has nothing to do with monitoring a model in production.\"\\n            },\\n            {\\n                \"statement\": \"The model is then ready to be reviewed, approved, and deployed to the target serving environment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In addition, all the relevant metadata and artifacts that were produced during model development are tracked in the metadata tracking repository.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"However, in most cases, ML models need to be retrained on a regular basis when new data is available or when the code changes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In this case, the output of the ML development process is not the model to be deployed in production. Instead, the output is the implementation of the continuous\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'continuous\\' when it has nothing to do with monitoring a model in production.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Monitoring and optimization\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model monitoring forms the cornerstone of this phase, involving the ongoing scrutiny of the model\\'s performance in the production environment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This step helps identify emerging issues, such as accuracy drift, bias and concerns around fairness, which could compromise the model\\'s utility or ethical standing.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring is about overseeing the model\\'s current performance and anticipating potential problems before they escalate.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about monitoring a model in production, making it highly relevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Monitorar um modelo em produ√ß√£o √© essencial por v√°rias raz√µes.\",\\n    \"O monitoramento detecta mudan√ßas no desempenho ou comportamento do modelo ao longo do tempo (drift).\",\\n    \"Sem monitoramento, os sistemas operam \\'flying blind\\' (cegos), sem saber se o modelo ainda est√° funcionando corretamente.\",\\n    \"Ele garante que o modelo continue a alcan√ßar a precis√£o e confiabilidade necess√°rias no ambiente de produ√ß√£o.\",\\n    \"Isso √© crucial para manter a qualidade das previs√µes e a lideran√ßa do sistema.\",\\n    \"Ao monitorar, a equipe de data science pode identificar problemas antes que eles causem falhas.\",\\n    \"Isso permite um trabalho proativo, corrigindo ou ajustando o modelo antes que os usu√°rios ou o sistema sejam afetados negativamente, em vez de aguardar problemas ocorrerem e ent√£o reagir de forma reativa.\",\\n    \"O monitoramento inclui a valida√ß√£o tanto das previs√µes do modelo quanto dos dados de entrada utilizados.\",\\n    \"Isso garante que tanto o modelo quanto os dados continuem relevantes e adequados para as tarefas em produ√ß√£o.\",\\n    \"Ao identificar problemas como desempenho declinante ou mudan√ßas necess√°rias no modelo, o monitoramento permite que voc√™ tome a√ß√µes corretivas ou de reentrenamento antes que os problemas se tornem cr√≠ticos ou causem consequ√™ncias indesejadas.\",\\n    \"Em resumo, o monitoramento transforma a data science de uma atividade de desenvolvimento em uma pr√°tica cont√≠nua de manuten√ß√£o e otimiza√ß√£o de modelos em produ√ß√£o, garantindo sua confiabilidade e efic√°cia no longo prazo.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"Einstein won the noble prize for his discovery of the photoelectric effect in 1968.\",\\n    \"The photoelectric effect is a phenomenon that laid the foundation for quantum mechanics.\"\\n] \\n \\nClaims:\\n[\\n    \"Monitorar um modelo em produ√ß√£o √© essencial por v√°rias raz√µes.\",\\n    \"O monitoramento detecta mudan√ßas no desempenho ou comportamento do modelo ao longo do tempo (drift).\",\\n    \"Sem monitoramento, os sistemas operam \\'flying blind\\' (cegos), sem saber se o modelo ainda est√° funcionando corretamente.\",\\n    \"Ele garante que o modelo continue a alcan√ßar a precis√£o e confiabilidade necess√°rias no ambiente de produ√ß√£o.\",\\n    \"Isso √© crucial para manter a qualidade das previs√µes e a lideran√ßa do sistema.\",\\n    \"Ao monitorar, a equipe de data science pode identificar problemas antes que eles causem falhas.\",\\n    \"Isso permite um trabalho proativo, corrigindo ou ajustando o modelo antes que os usu√°rios ou o sistema sejam afetados negativamente, em vez de aguardar problemas ocorrerem e ent√£o reagir de forma reativa.\",\\n    \"O monitoramento inclui a valida√ß√£o tanto das previs√µes do modelo quanto dos dados de entrada utilizados.\",\\n    \"Isso garante que tanto o modelo quanto os dados continuem relevantes e adequados para as tarefas em produ√ß√£o.\",\\n    \"Ao identificar problemas como desempenho declinante ou mudan√ßas necess√°rias no modelo, o monitoramento permite que voc√™ tome a√ß√µes corretivas ou de reentrenamento antes que os problemas se tornem cr√≠ticos ou causem consequ√™ncias indesejadas.\",\\n    \"O monitoramento transforma a data science de uma atividade de desenvolvimento em uma pr√°tica cont√≠nua de manuten√ß√£o e otimiza√ß√£o de modelos em produ√ß√£o, garantindo sua confiabilidade e efic√°cia no longo prazo.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'Por que monitorar um modelo em produ√ß√£o?',\n",
       "  'actual_output': 'Monitorar um modelo em produ√ß√£o √© essencial por v√°rias raz√µes:\\n\\n1.  **Identificar Drift do Modelo:** O monitoramento detecta mudan√ßas no desempenho ou comportamento do modelo ao longo do tempo (drift). Sem monitoramento, os sistemas operam \"flying blind\" (cegos), sem saber se o modelo ainda est√° funcionando corretamente.\\n\\n2.  **Garantir Performance e Lideran√ßa:** Ele garante que o modelo continue a alcan√ßar a precis√£o e confiabilidade necess√°rias no ambiente de produ√ß√£o. Isso √© crucial para manter a qualidade das previs√µes e a lideran√ßa do sistema.\\n\\n3.  **Trabalhar de Forma Proativa:** Ao monitorar, a equipe de data science pode identificar problemas antes que eles causem falhas. Isso permite um trabalho proativo, corrigindo ou ajustando o modelo antes que os usu√°rios ou o sistema sejam afetados negativamente, em vez de aguardar problemas ocorrerem e ent√£o reagir de forma reativa.\\n\\n4.  **Validar Previs√µes e Dados:** O monitoramento inclui a valida√ß√£o tanto das previs√µes do modelo quanto dos dados de entrada utilizados. Isso garante que tanto o modelo quanto os dados continuem relevantes e adequados para as tarefas em produ√ß√£o.\\n\\n5.  **Prevenir Problemas e Ajustes:** Ao identificar problemas como desempenho declinante ou mudan√ßas necess√°rias no modelo, o monitoramento permite que voc√™ tome a√ß√µes corretivas ou de reentrenamento antes que os problemas se tornem cr√≠ticos ou causem consequ√™ncias indesejadas.\\n\\nEm resumo, o monitoramento transforma a data science de uma atividade de desenvolvimento em uma pr√°tica cont√≠nua de manuten√ß√£o e otimiza√ß√£o de modelos em produ√ß√£o, garantindo sua confiabilidade e efic√°cia no longo prazo.',\n",
       "  'expected_output': 'Para detectar quedas de performance, drifts, falhas de pipeline, mudan√ßas de distribui√ß√£o e problemas de lat√™ncia ou disponibilidade.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track',\n",
       "   'dation system has on click-throughs and on conversation rates. The results of online experimentation should be \\nintegrated with the model registry capability to facilitate the decision about releasing the model to production. Online \\nexperimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models \\nand to promote well-performing ones. Key functionalities in online experimentation include the following:\\n‚Ä¢ Support canary and shadow deployments.\\n‚Ä¢ Support traffic splitting and A/B tests.\\n‚Ä¢ Support multi-armed bandit (MAB) tests.\\nModel monitoring\\nThe model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production \\nto ensure predictive quality and business continuity. This capability informs you if your models are stale and need to \\nbe investigated and updated. Key functionalities in model monitoring include the following:',\n",
       "   '‚Ä¢ Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\n‚Ä¢ Information about training, validation, and testing data splits that were used. \\n‚Ä¢ Model evaluation metrics and the validation procedure that was used.\\nIf there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\\ntion is submitted to the model registry. The model is then ready to be reviewed, approved, and deployed to the target \\n18\\nserving environment. In addition, all the relevant metadata and artifacts \\nthat were produced during model development are tracked in the metadata \\ntracking repository.\\nHowever, in most cases, ML models need to be retrained on a regular basis \\nwhen new data is available or when the code changes. In this case, the \\noutput of the ML development process is not the model to be deployed in \\nproduction. Instead, the output is the implementation of the continuous',\n",
       "   'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes. Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.',\n",
       "   \"Monitoring and optimization\\n\\nIn the lifecycle of a deployed machine learning model, continuous vigilance ensures effectiveness and fairness over time. Model monitoring forms the cornerstone of this phase, involving the ongoing scrutiny of the model's performance in the production environment. This step helps identify emerging issues, such as accuracy drift, bias and concerns around fairness, which could compromise the model's utility or ethical standing. Monitoring is about overseeing the model's current performance and anticipating potential problems before they escalate.\"],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7555555555555555,\n",
       "    'reason': \"The score is 0.76 because irrelevant nodes (nodes 2 and 4) are correctly ranked lower than relevant nodes (nodes 1, 3), as they don't provide information about what a model registry is, only describing its capabilities.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'model registry\\' which is the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about what a model registry is, it only describes its capabilities.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that a model registry is used to store and track models, which aligns with the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about what a model registry is used for, it only describes its capabilities.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that a model registry is used to store and track models, which aligns with the expected output.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6875,\n",
       "    'reason': 'The score is 0.69 because the contextual recall score indicates that most of the expected output sentences are supported by relevant information in the retrieval context, with some minor discrepancies.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'processing, model training, model evaluation, model serving, online experimentation, model monitoring, ML pipeline, and model registry.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Experimentation ...\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'\\\\u2022 Provide notebook environments that are integrated with version control tools like Git.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'\\\\u2022 Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'If there is no need to retrain the model on a regular basis, then the produced model at the end of the experimentation is submitted to the model registry.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'following:\\\\n\\\\u2022 Register, organize, track, and version your trained and deployed ML models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'The dataset and feature repository capability lets you unify the definition and the storage of the ML data assets.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'dation system has on click-throughs and on conversation rates.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'The results of online experimentation should be integrated with the model registry capability to facilitate the decision about releasing the model to production.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'\\\\u2022 Trigger pipelines on demand, on a schedule, or in response to specified events.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'The model registry capability lets you govern the lifecycle of the ML models in a central repository.\\'\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6486486486486487,\n",
       "    'reason': 'The score is 0.65 because the retrieval context provides statements about various aspects of machine learning, such as training, evaluation, deployment, and monitoring, but none of these statements directly relate to what a model registry is or its purpose.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"processing, model training, model evaluation, model serving, online experimentation, model monitoring, ML pipeline, and model registry.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"and model registry.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Finally, two cross-cutting capabilities that enable integration and interaction are an ML metadata and artifact repository and an ML dataset and feature repository.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The experimentation capability lets your data scientists and ML researchers collaboratively perform exploratory data analysis, create prototype model architectures, and implement training routines.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"An ML environment should also let them write modular, reusable, and testable source code that is version controlled.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Provide notebook environments that are integrated with version control tools like Git.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Hyperparameters, including trials of automated hyperparameter tuning and model selection.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Information about training, validation, and testing data splits that were used.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model evaluation metrics and the validation procedure that was used.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"If there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about submitting the model to the registry without mentioning what it\\'s related to. The context doesn\\'t provide any information about model registries.\"\\n            },\\n            {\\n                \"statement\": \"The model is then ready to be reviewed, approved, and deployed to the target serving environment.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about deploying a model without mentioning what kind of model it is or how it\\'s related to the context.\"\\n            },\\n            {\\n                \"statement\": \"In addition, all the relevant metadata and artifacts that were produced during model development are tracked in the metadata tracking repository.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about tracking metadata without mentioning what kind of metadata or how it\\'s related to the context.\"\\n            },\\n            {\\n                \"statement\": \"However, in most cases, ML models need to be retrained on a regular basis when new data is available or when the code changes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In this case, the output of the ML development process is not the model to be deployed in production. Instead, the output is the implementation of the continuous\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about the output of an ML development process without mentioning what it\\'s related to or how it\\'s relevant to the context.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Register, organize, track, and version your trained and deployed ML models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Store model metadata and runtime dependencies for deployability.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Maintain model documentation and reporting\\\\u2014for example, using model cards .\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Integrate with the model evaluation and deployment capability and track online and offline evaluation metrics for the models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Govern the model launching process: review, approve, release, and roll back. These decisions are based on a number of offline performance and fairness metrics and on online experimentation results.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The dataset and feature repository capability lets you unify the definition and the storage of the ML data assets.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Having a central repository of fresh, high-quality data assets enables shareability, discoverability, and reusability.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The repository also provides data consistency for training and inference. This helps data scientists and ML researchers\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"dation system has on click-throughs and on conversation rates.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The results of online experimentation should be integrated with the model registry capability to facilitate the decision about releasing the model to production.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Online experimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models and to promote well-performing ones.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Key functionalities in online experimentation include the following: \\\\u2022 Support canary and shadow deployments. \\\\u2022 Support traffic splitting and A/B tests. \\\\u2022 Support multi-armed bandit (MAB) tests.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model monitoring\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production to ensure predictive quality and business continuity. This capability informs you if your models are stale and need to be investigated and updated.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Key functionalities in model monitoring include the following:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Trigger pipelines on demand, on a schedule, or in response to specified events.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Enable local interactive execution for debugging during ML development.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Integrate with the ML metadata tracking capability to capture pipeline execution parameters and to produce artifacts.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Provide a set of built-in components for common ML tasks and also allow custom components.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Run on different environments, including local machines and scalable cloud platforms.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Optionally, provide GUI-based tools for designing and building pipelines.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Register, organize, track, and version your trained and deployed ML models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Store model metadata and runtime dependencies for deployability.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the answer perfectly addresses the question about what a model registry is, with no irrelevant information present.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"A model registry is a centralized technical capability that allows managing the lifecycle of Machine Learning (ML) models in a single repository.\",\\n    \"It includes registration, organization, tracking, and versioning of trained and deployed models.\",\\n    \"Storage of metadata and execution dependencies is also included to ensure reusability and portability of models.\",\\n    \"Maintenance of documentation and reports (such as model cards) is another key feature.\",\\n    \"Integration with evaluation and deployment processes allows offline and online metric tracking.\",\\n    \"Governance of the model release process: review, approval, release, and rollback based on performance metrics and online experimentation is also included.\",\\n    \"This capability is essential to ensure quality and discovery of models in production.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"EML provides experimentation capabilities that allow data scientists and ML researchers to collaboratively perform exploratory data analysis, create prototype model architectures, and implement training routines.\",\\n    \"The experimentation capability includes providing notebook environments integrated with version control tools like Git, hyperparameters, information about training, validation, and testing data splits, and model evaluation metrics.\",\\n    \"Models produced during experimentation can be submitted to the model registry for review, approval, and deployment.\",\\n    \"The output of the ML development process is not always the model to be deployed in production, but rather the implementation of continuous retraining when new data is available or code changes.\",\\n    \"EML provides a dataset and feature repository capability that unifies the definition and storage of ML data assets, enabling shareability, discoverability, and reusability.\",\\n    \"The dataset and feature repository provides data consistency for training and inference, helping data scientists and ML researchers to track the efficiency and effectiveness of deployed models in production.\",\\n    \"EML provides online experimentation capabilities that support canary and shadow deployments, traffic splitting and A/B tests, and multi-armed bandit (MAB) tests.\",\\n    \"Online experimentation enhances the reliability of ML releases by helping decide which models to discard or promote.\",\\n    \"The model monitoring capability tracks the efficiency and effectiveness of deployed models in production to ensure predictive quality and business continuity.\",\\n    \"EML provides a model registry capability that governs the lifecycle of ML models in a central repository, ensuring the quality of production models and enabling model discovery.\",\\n    \"Key functionalities in the model registry include registering, organizing, tracking, and versioning trained and deployed ML models, storing model metadata and runtime dependencies for deployability.\"\\n] \\n \\nClaims:\\n[\\n    \"Um model registry √© uma capacidade t√©cnica centralizada que permite gerenciar o ciclo de vida dos modelos de Machine Learning (ML) em um √∫nico reposit√≥rio.\",\\n    \"Sua principal funcionalidade inclui registro, organiza√ß√£o, rastreamento e versionamento dos modelos treinados e implantados.\",\\n    \"Sua principal funcionalidade inclui armazenamento de metadados e depend√™ncias de execu√ß√£o para garantir a reutiliza√ß√£o e a portabilidade dos modelos.\",\\n    \"Sua principal funcionalidade inclui manuten√ß√£o de documenta√ß√£o e relat√≥rios (como cards de modelos).\",\\n    \"Sua principal funcionalidade inclui integra√ß√£o com processos de avalia√ß√£o e implanta√ß√£o, permitindo o rastreamento de m√©tricas offline e online.\",\\n    \"Sua principal funcionalidade inclui governan√ßa do processo de lan√ßamento de modelos: revis√£o, aprova√ß√£o, libera√ß√£o e recesso (rollback) com base em m√©tricas de desempenho e experimenta√ß√£o online.\",\\n    \"Essa capacidade √© essencial para garantir a qualidade e o descobrimento dos modelos em produ√ß√£o.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim does not explicitly state that the model registry maintains documentation and reports, but it is implied by the mention of \\'cards de modelos\\'.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© um model registry?',\n",
       "  'actual_output': 'Um **model registry** √© uma capacidade t√©cnica centralizada que permite gerenciar o ciclo de vida dos modelos de Machine Learning (ML) em um √∫nico reposit√≥rio. Suas principais funcionalidades incluem:\\n\\n1. **Registro, organiza√ß√£o, rastreamento e versionamento** dos modelos treinados e implantados.  \\n2. **Armazenamento de metadados e depend√™ncias de execu√ß√£o** para garantir a reutiliza√ß√£o e a portabilidade dos modelos.  \\n3. **Manuten√ß√£o de documenta√ß√£o e relat√≥rios** (como cards de modelos).  \\n4. **Integra√ß√£o com processos de avalia√ß√£o e implanta√ß√£o**, permitindo o rastreamento de m√©tricas offline e online.  \\n5. **Governan√ßa do processo de lan√ßamento de modelos**: revis√£o, aprova√ß√£o, libera√ß√£o e recesso (rollback) com base em m√©tricas de desempenho e experimenta√ß√£o online.  \\n\\nEssa capacidade √© essencial para garantir a qualidade e o descobrimento dos modelos em produ√ß√£o.',\n",
       "  'expected_output': 'Reposit√≥rio central para armazenar vers√µes de modelos, m√©tricas e hist√≥rico.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['processing, model training, model evaluation, model serving, online experimentation, model monitoring, ML pipeline, \\nand model registry. Finally, two cross-cutting capabilities that enable integration and interaction are an ML metadata \\nand artifact repository and an ML dataset and feature repository.\\nFigure 4. Core MLOps technical capabilities\\n11\\nThe following sections outline the characteristics of each of the MLOps capabilities.\\nExperimentation \\nThe experimentation capability lets your data scientists and ML researchers collaboratively perform exploratory data \\nanalysis, create prototype model architectures, and implement training routines. An ML environment should also let \\nthem write modular, reusable, and testable source code that is version controlled. Key functionalities in experimenta -\\ntion include the following:\\n‚Ä¢ Provide notebook environments that are integrated with version control tools like Git.',\n",
       "   '‚Ä¢ Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\n‚Ä¢ Information about training, validation, and testing data splits that were used. \\n‚Ä¢ Model evaluation metrics and the validation procedure that was used.\\nIf there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\\ntion is submitted to the model registry. The model is then ready to be reviewed, approved, and deployed to the target \\n18\\nserving environment. In addition, all the relevant metadata and artifacts \\nthat were produced during model development are tracked in the metadata \\ntracking repository.\\nHowever, in most cases, ML models need to be retrained on a regular basis \\nwhen new data is available or when the code changes. In this case, the \\noutput of the ML development process is not the model to be deployed in \\nproduction. Instead, the output is the implementation of the continuous',\n",
       "   'following:\\n‚Ä¢ Register, organize, track, and version your trained and deployed ML models.\\n‚Ä¢ Store model metadata and runtime dependencies for deployability.\\n‚Ä¢ Maintain model documentation and reporting‚Äîfor example, using model cards .\\n‚Ä¢ Integrate with the model evaluation and deployment capability and track online and offline evaluation metrics \\nfor the models.\\n‚Ä¢ Govern the model launching process: review, approve, release, and roll back. These decisions are based on a \\nnumber of offline performance and fairness metrics and on online experimentation results.\\nDataset and feature repository\\nThe dataset and feature repository capability lets you unify the definition and the storage of the ML data assets. \\nHaving a central repository of fresh, high-quality data assets enables shareability, discoverability, and reusability. The \\nrepository also provides data consistency for training and inference. This helps data scientists and ML researchers',\n",
       "   'dation system has on click-throughs and on conversation rates. The results of online experimentation should be \\nintegrated with the model registry capability to facilitate the decision about releasing the model to production. Online \\nexperimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models \\nand to promote well-performing ones. Key functionalities in online experimentation include the following:\\n‚Ä¢ Support canary and shadow deployments.\\n‚Ä¢ Support traffic splitting and A/B tests.\\n‚Ä¢ Support multi-armed bandit (MAB) tests.\\nModel monitoring\\nThe model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production \\nto ensure predictive quality and business continuity. This capability informs you if your models are stale and need to \\nbe investigated and updated. Key functionalities in model monitoring include the following:',\n",
       "   '‚Ä¢ Trigger pipelines on demand, on a schedule, or in response to specified events.\\n‚Ä¢ Enable local interactive execution for debugging during ML development.\\n‚Ä¢ Integrate with the ML metadata tracking capability to capture pipeline execution parameters and to produce \\nartifacts.\\n‚Ä¢ Provide a set of built-in components for common ML tasks and also allow custom components.\\n‚Ä¢ Run on different environments, including local machines and scalable cloud platforms.\\n‚Ä¢ Optionally, provide GUI-based tools for designing and building pipelines.\\nModel registry\\nThe model registry capability lets you govern the lifecycle of the ML models in a central repository. This ensures the \\nquality of the production models and enables model discovery. Key functionalities in the model registry include the \\nfollowing:\\n‚Ä¢ Register, organize, track, and version your trained and deployed ML models.\\n‚Ä¢ Store model metadata and runtime dependencies for deployability.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6565175565175564,\n",
       "    'reason': \"The score is 0.66 because the relevant nodes (nodes 1, 3, 5, and 7) are ranked higher than irrelevant nodes (nodes 2, 4, 6, and 8-10), with a good balance between 'yes' verdicts and 'no' verdicts. The irrelevant nodes mostly provide information about ML Ops phases or techniques that don't directly relate to data validation.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions data validation, which is directly related to the expected output\\'s mention of verifying integrity, schema, ranges, and consistency of data.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The phrase \\'this phase, data engineers work together with data scientists\\' does not provide any information about data validation.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses model training, which is mentioned in the expected output as part of the ML Ops process.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The phrase \\'needs to support data scientists\\' does not provide any information about data validation or ML Ops.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions automation, which is a key aspect of ML Ops and related to the expected output\\'s mention of automated data collection, cleaning, and preparation.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The phrase \\'Use collaboration tools to help communication\\' does not provide any information about data validation or ML Ops.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of feedback sessions with data scientists, which is related to the expected output\\'s mention of ensuring data validation and managing new data.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The phrase \\'Several techniques can be applied during the model training phase\\' does not provide any information about data validation or ML Ops.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions experiment tracking, which is a tool used in ML Ops to manage and monitor experiments.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The phrase \\'Crankshaw et al. studied the problem of model deployment\\' does not provide any information about data validation or ML Ops.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of monitoring and response in ML Ops, which is related to the expected output\\'s mention of validating changes in production systems.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The phrase \\'Sculley et al. were early proponents that production ML systems raise special challenges\\' does not provide any information about data validation or ML Ops.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5384615384615384,\n",
       "    'reason': 'The score is 0.54 because the contextual recall score indicates that most of the expected output can be attributed to the nodes in the retrieval context, with some minor inconsistencies.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 1st node in the retrieval context, which mentions \\'data engineers work together with data scientists\\'...\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 2nd node in the retrieval context, which talks about \\'model creation\\' and \\'data pipelines\\'...\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 3rd node in the retrieval context, which discusses \\'model training\\' and \\'validation dataset\\'...\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 4th node in the retrieval context, which talks about \\'data collection\\' and \\'preparation\\'...\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 5th node in the retrieval context, which discusses \\'experiment tracking\\' and \\'model deployment\\'...\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 6th node in the retrieval context, which talks about \\'CI (Continuous Integration)\\' and \\'ML\\'...\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 7th node in the retrieval context, which discusses \\'MLOps Challenges\\' and \\'production ML systems\\'...\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7435897435897436,\n",
       "    'reason': \"The score is 0.74 because the input question about data validation in MLOps doesn't seem to be directly related to the statements in the retrieval context, which primarily discuss model training, evaluation, deployment, and maintenance. The relevant statements focus on iterative processes, hyperparameter optimisation, cross-validation, and regularisation, whereas data validation is not explicitly mentioned.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"this phase, data engineers work together with data scientists to prepare and preprocess the data, performing featur e engineering to ensure the data has the right format and structure.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"During model creation, various data pipelines are developed, enabling the smooth flow of information between the different stages of the machine learning process.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Tools such as data engineering platforms can be used to design, test and maintain these pipelines.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Once the model has been created, it is trained using a suitable dataset.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model training is an iterative process that involves feeding data into the model for it to learn and make predictions.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The model is continually adjusted, and its performance is evaluated against a validation dataset to fine-tune its accuracy and effectiveness.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Several techniques can be applied during the model training phase, including hyperparameter optimisation, cross-validation, and regularisation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Utilising the right combination of these methods helps\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"needs to support data scientists.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without their feedback, the system won\\\\u2019t meet user needs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Regular feedback sessions with data scientists can stimulate open communication and improve outcomes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Use collaboration tools to help communication.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Collaboration tools assist in enhancing communication and project management, mitigating technical debt, and facilitating continuous delivery.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Automation is a cornerstone of ML Ops, improving efficiency and accuracy.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Here are some best practices for it:11/11/25, 10:04 PM MLOps Now - MLOps Best Practices and Challenges\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Automate data collection, cleaning and preparation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"One significant aspect of automation in ML Ops is the handling of data. Automating collection, cleaning, and preparation improves efficiency drastically when improving models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It\\\\u2019s also an important practice for ensuring data validation and managing new data.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"data collection and processing, experimentation, evaluation and deployment, and monitoring and response\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Several research papers and companies have proposed tools to accomplish various tasks in the workflow, such as data pre-processing [22, 58,60] and experiment tracking.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Crankshaw et al. studied the problem of model deployment and low-latency prediction serving.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"With regards to validating changes in production systems, some researchers have studied CI (Continuous Integration) for ML and proposed preliminary solutions\\\\u2014for example, ease.ml/ci streamlines data management and proposes unit tests for overfitting\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Garg et al. survey different MLOps tools, and some papers introduce tools to perform validation and monitoring in production ML pipelines.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Sculley et al. were early proponents that production ML systems raise special challenges and can be hard to maintain over time, based on their experience at Google\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"different failure modes in the offline validation phase\\\\u2014e.g., perfor-mance drops in subpopulations users might care deeply about\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P11 did, P8 offered a reactive strategy of spawning a new dataset for each observed live failure:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Every gets into the same queue, and 3 of us sit down once a week and go through the queue...then our collect more data.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This new dataset was then used in the offline validation phase in future iterations of the production ML lifecycle.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"While processes to dynamically update the validation datasets ranged from human-in-the-loop to frequent synthetic data construction (P6),\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"we found that higher-stakes applications of ML (e.g., autonomous vehicles), created separate teams to manage the dynamic evaluation process.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P1 said: We had to move away from only aggregate metrics like MAP towards the ability to curate scenarios of interest, and then validate model performance on them specifically. So, as an example, you can\\\\u2019t hit pedestrians, right.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A typical data science project consists of several stages: 1. Data acquisition: Obtaining raw data from various sources, such as databases, sensors, or external APIs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"2. Data preprocessing: Cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"3. Feature engineering: Selecting the most relevant data attributes, or \\\\u201cfeatures,\\\\u201d and converting them into a suitable format for ML algorithms.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Model training: Applying ML algorithms to the preprocessed data to create a predictive model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"5. Model evaluation: Assessing the performance of the model and making adjustments to improve its accuracy.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"6. Model deployment: Implementing the ML model into a product, service, or system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"7. Monitoring and maintenance: Continuously monitoring the performance of the ML model and updating it as needed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about data validation in MLOps, providing a relevant and accurate response.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Data validation in MLOps is the process of ensuring that data used by machine learning models is precise, consistent, and suitable for the project\\'s purpose.\",\\n    \"This process is essential to avoid errors and ensure that models work correctly in production.\",\\n    \"Validation of data in production is important during the ML lifecycle, especially when there are changes in the production environment.\",\\n    \"Tools like CI/CD adapted for ML can be used to automate validation tests, such as checking overfitting or performance issues in specific subpopulations.\",\\n    \"One of the challenges is identifying failures in user subgroups that may impact model performance.\",\\n    \"Dynamic validation tools and processes are needed to monitor these scenarios.\",\\n    \"Tools like ease.ml/ci allow for unit testing to validate data and ensure the model maintains its accuracy over time.\",\\n    \"In summary, data validation in MLOps is an essential practice to ensure that data used by ML models is reliable and that the system continues to work correctly after implementations or changes in the production environment.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8571428571428571,\n",
       "    'reason': 'The score is 0.86 because the actual output slightly deviates from the retrieval context by mentioning identifying failures in subgroups of users, which was not explicitly stated but can be inferred.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The data science project development lifecycle consists of 7 stages: Data acquisition, Data preprocessing, Featur e engineering, Model training, Model evaluation, Model deployment, and Monitoring and maintenance.\",\\n    \"A typical data science project involves several stages including obtaining raw data from various sources, cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n    \"Featur e engineering is a stage in the data science project development lifecycle that involves selecting the most relevant data attributes or \\'features\\' and converting them into a suitable format for ML algorithms.\",\\n    \"The model training phase in the data science project development lifecycle involves applying ML algorithms to preprocessed data to create a predictive model.\",\\n    \"The model evaluation phase in the data science project development lifecycle involves assessing the performance of the model and making adjustments to improve its accuracy.\",\\n    \"The model deployment phase in the data science project development lifecycle involves implementing the ML model into a product, service, or system.\",\\n    \"Monitoring and maintenance is an ongoing process in the data science project development lifecycle that involves continuously monitoring the performance of the ML model and updating it as needed.\"\\n] \\n \\nClaims:\\n[\\n    \"EData validation em MLOps √© o processo de garantir que os dados utilizados pelos modelos de machine learning sejam precisos, consistentes e adequados para o prop√≥sito do projeto.\",\\n    \"Esse processo √© essencial para evitar erros e garantir que os modelos funcionem corretamente em produ√ß√£o.\",\\n    \"Durante o ciclo de vida do ML, √© importante validar os dados constantemente, especialmente quando h√° mudan√ßas no ambiente de produ√ß√£o.\",\\n    \"Ferramentas como CI/CD adaptadas para ML podem ser usadas para automatizar testes de valida√ß√£o, como verificar overfitting ou problemas de desempenho em subpopula√ß√µes espec√≠ficas.\",\\n    \"Um dos desafios √© identificar falhas em subgrupos de usu√°rios que podem impactar o desempenho do modelo.\",\\n    \"Ferramentas e processos de valida√ß√£o din√¢mica s√£o necess√°rios para monitorar esses cen√°rios.\",\\n    \"Ferramentas como ease.ml/ci permitem realizar testes unit√°rios para validar dados e garantir que o modelo mantenha sua precis√£o ao longo do tempo.\",\\n    \"A data validation em MLOps √© uma pr√°tica essencial para garantir que os dados utilizados pelos modelos ML sejam confi√°veis e que o sistema continue funcionando corretamente ap√≥s implementa√ß√µes ou mudan√ßas no ambiente de produ√ß√£o.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim mentions identifying failures in subgroups of users, which is not explicitly mentioned in the retrieval context. However, it can be inferred that monitoring and maintenance involve identifying potential issues.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© data validation em MLOps?',\n",
       "  'actual_output': '**Data Validation em MLOps**\\n\\nData validation em MLOps √© o processo de garantir que os dados utilizados pelos modelos de machine learning sejam precisos, consistentes e adequados para o prop√≥sito do projeto. Esse processo √© essencial para evitar erros e garantir que os modelos funcionem corretamente em produ√ß√£o.\\n\\n### Principais pontos sobre data validation em MLOps:\\n\\n1. **Valida√ß√£o de Dados em Produ√ß√£o**:  \\n   Durante o ciclo de vida do ML, √© importante validar os dados constantemente, especialmente quando h√° mudan√ßas no ambiente de produ√ß√£o. Ferramentas como CI/CD adaptadas para ML podem ser usadas para automatizar testes de valida√ß√£o, como verificar overfitting ou problemas de desempenho em subpopula√ß√µes espec√≠ficas.\\n\\n2. **Desafios**:  \\n   Um dos desafios √© identificar falhas em subgrupos de usu√°rios que podem impactar o desempenho do modelo. Ferramentas e processos de valida√ß√£o din√¢mica s√£o necess√°rios para monitorar esses cen√°rios.\\n\\n3. **Ferramentas e Pr√°ticas**:  \\n   Ferramentas como ease.ml/ci permitem realizar testes unit√°rios para validar dados e garantir que o modelo mantenha sua precis√£o ao longo do tempo.\\n\\nEm resumo, a data validation em MLOps √© uma pr√°tica essencial para garantir que os dados utilizados pelos modelos ML sejam confi√°veis e que o sistema continue funcionando corretamente ap√≥s implementa√ß√µes ou mudan√ßas no ambiente de produ√ß√£o.',\n",
       "  'expected_output': '√â o processo automatizado de verificar integridade, schema, ranges e consist√™ncia de dados antes de alimentar o pipeline de ML.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps',\n",
       "   'needs to support data scientists. Without their feedback, the system won‚Äôt\\nmeet user needs. R egular feedback sessions with data scientists can\\nstimulate open communication and improve outcomes.\\xa0\\nUse collaboration t ools t o help communication. Collaboration tools assist\\nin enhancing communication and project management, mitigating\\ntechnical debt, and facilitating continuous delivery.\\n2. Aut omating Pr ocesses\\nAutomation is a cornerstone of ML Ops, improving efficiency and accuracy.\\nHere are some best practices for it:11/11/25, 10:04 PM MLOps Now - MLOps Best Practices and Challenges\\nhttps://mlopsnow.com/blog/mlops-best-practices-and-challenges/ 2/7\\nAutomat e data collection, cleaning and pr eparation. One significant\\naspect of automation in ML Ops is the handling of data. Automating\\ncollection, cleaning, and preparation improves efficiency drastically when\\nimproving models. It‚Äôs also an important practice for ensuring data\\nvalidation and managing new data.',\n",
       "   'data collection and processing, experimentation, evaluation and de-\\nployment, and monitoring and response, as shown in Figure 1. Sev-\\neral research papers and companies have proposed tools to accom-\\nplish various tasks in the workflow, such as data pre-processing [ 22,\\n58,60] and experiment tracking . Crankshaw et al. stud-\\nied the problem of model deployment and low-latency prediction\\nserving . With regards to validating changes in production sys-\\ntems, some researchers have studied CI (Continuous Integration) for\\nML and proposed preliminary solutions‚Äîfor example, ease.ml/ci\\nstreamlines data management and proposes unit tests for overfit-\\nting , Garg et al. survey different MLOps tools , and some\\npapers introduce tools to perform validation and monitoring in\\nproduction ML pipelines .\\nMLOps Challenges. Sculley et al. were early proponents that pro-\\nduction ML systems raise special challenges and can be hard tomaintain over time, based on their experience at Google . Since',\n",
       "   'different failure modes in the offline validation phase‚Äîe.g., perfor-\\nmance drops in subpopulations users might care deeply about‚ÄîlikeP11 did, P8 offered a reactive strategy of spawning a new dataset\\nfor each observed live failure: ‚ÄúEvery gets into\\nthe same queue, and 3 of us sit down once a week and go through\\nthe queue...then our collect more data.‚Äù This\\nnew dataset was then used in the offline validation phase in future\\niterations of the production ML lifecycle.\\nWhile processes to dynamically update the validation datasets\\nranged from human-in-the-loop to frequent synthetic data con-\\nstruction (P6), we found that higher-stakes applications of ML (e.g.,\\nautonomous vehicles), created separate teams to manage the dy-\\nnamic evaluation process. P1 said:\\nWe had to move away from only aggregate metrics like\\nMAP towards the ability to curate scenarios of interest,\\nand then validate model performance on them specifi-\\ncally. So, as an example, you can‚Äôt hit pedestrians, right.',\n",
       "   'https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because irrelevant nodes, such as those discussing model explainability and logging of prediction serving requests (ranked 3), or model monitoring and abstractions for machine learning systems (ranked 5), are correctly ranked lower than the relevant nodes that discuss batch inference and online inference (ranks 1 and 2).',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This document does not contain any information about batch inference or online inference.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions \\'batch of the feature values\\' and \\'online prediction\\', which are relevant to the topic of batch inference and online inference.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This document is about enabling composite prediction routines, model explainability, and logging of prediction serving requests, but it does not relate to the difference between batch inference and online inference.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text discusses online experimentation, which involves understanding how newly trained models perform in production settings compared to current models, and this is relevant to the topic of online inference.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This document talks about model monitoring, direct feedback loops, hidden feedback loops, and abstractions for machine learning systems, but it does not relate to the difference between batch inference and online inference.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5454545454545454,\n",
       "    'reason': 'The score is 0.55 because the contextual recall score indicates a moderate level of accuracy in attributing sentences from the expected output to corresponding nodes in the retrieval context, with some sentences matching well and others not fitting as closely.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 1st node in the retrieval context, which mentions \\'batch inference process\\' and \\'online inference\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 2nd node in the retrieval context, which mentions \\'online prediction\\' and \\'feature values\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 3rd node in the retrieval context, which mentions \\'online experimentation\\' and \\'model registry capability\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 4th node in the retrieval context, which mentions \\'model monitoring\\' and \\'predictive quality\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 5th node in the retrieval context, which mentions \\'direct feedback loops\\' and \\'hidden feedback loops\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 6th node in the retrieval context, which mentions \\'abstractions\\' and \\'machine learning\\'.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.2857142857142857,\n",
       "    'reason': 'The score is 0.29 because the retrieval context contains information about machine learning abstractions, model behavior, and feedback loops that have no relation to the difference between batch inference and online inference.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"For continuous training, the automated ML training pipeline can fetch a batch of the up-to-date feature values of the dataset that are used for the training task.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For online prediction, the prediction service can fetch in a batch of the feature values related to the requested entity, such as customer demographic features, product features, and current session aggregation features.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For online prediction and feature retrieval, the prediction service identifies the relevant features for an entity. For example, if the entity is a customer, relevant features might include age, purchase history, and browsing behavior.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The service batches these feature values together and retrieves all the needed features for the entity at once, rather than individually.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Enable composite prediction routines, where multiple models are invoked hierarchically or simultaneously before the results are aggregated, in addition to any required pre- or post-processing routines.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Allow efficient use of ML inference accelerators with autoscaling to match spiky workloads and to balance cost with latency.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Support model explainability using techniques like feature attributions for a given model prediction.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Support logging of prediction serving requests and responses for analysis.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Online experimentation\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"The results of online experimentation should be integrated with the model registry capability to facilitate the decision about releasing the model to production.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Online experimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models and to promote well-performing ones.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Key functionalities in online experimentation include the following: \\\\u2022 Support canary and shadow deployments. \\\\u2022 Support traffic splitting and A/B tests. \\\\u2022 Support multi-armed bandit (MAB) tests.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The provided context does not relate to \\'Diferen\\\\u00e7a entre batch inference e online inference?\\'\"\\n            },\\n            {\\n                \"statement\": \"Model monitoring The model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production to ensure predictive quality and business continuity.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The provided context does not relate to \\'Diferen\\\\u00e7a entre batch inference e online inference?\\'\"\\n            },\\n            {\\n                \"statement\": \"This capability informs you if your models are stale and need to be investigated and updated. Key functionalities in model monitoring include the following:\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The provided context does not relate to \\'Diferen\\\\u00e7a entre batch inference e online inference?\\'\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"behavior of a given model before it is released.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These feedback loops can take different forms, but they are all more difficult to detect and address if they occur gradually over time, as may be the case when models are updated infrequently.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about model behavior and feedback loops, which has nothing to do with the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"Direct Feedback Loops. A model may directly influence the selection of its own future training data.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about direct feedback loops, which has nothing to do with the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"It is common practice to use standard supervised algorithms, although the theoretically correct solution would be to use bandit algorithms.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about model training data selection, which has nothing to do with the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"The problem here is that bandit algorithms (such as contextual bandits) do not necessarily scale well to the size of action spaces typically required for real-world problems.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about model training data selection, which has nothing to do with the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"It is possible to mitigate these effects by using some amount of randomization, or by isolating certain parts of data from being influenced by a given model.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about mitigating the effects of feedback loops, which has nothing to do with the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"Hidden Feedback Loops. Direct feedback loops are costly to analyze, but at least they pose a\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"What is the right interface to describe a stream of data, or a model, or a prediction?\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information about machine learning abstractions and interfaces when it has nothing to do with the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"Zheng recently made a compelling comparison of the state ML abstractions to the state of database technology, making the point that nothing in the machine learning literature comes close to the success of the relational database as a basic abstraction.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is about machine learning abstractions and their relation to database technology, which is not relevant to the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"For distributed learning in particular, there remains a lack of widely accepted abstractions.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is about the lack of abstractions for distributed learning, which is not related to the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"It could be argued that the widespread use of Map-Reduce in machine learning was driven by the void of strong distributed learning abstractions.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is about the use of Map-Reduce in machine learning and its relation to distributed learning abstractions, which is not relevant to the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"Indeed, one of the few areas of broad agreement in recent years appears to be that Map-Reduce is a poor abstraction for iterative ML algorithms.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is about the suitability of Map-Reduce as an abstraction for iterative ML algorithms, which is not related to the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"The parameter-server abstraction seems much more robust, but there are multiple competing specifications of this basic idea.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is about the parameter-server abstraction and its specifications, which is not relevant to the difference between batch inference and online inference.\"\\n            },\\n            {\\n                \"statement\": \"The lack of standard abstractions makes it all too easy to blur the lines between components.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is about the lack of standard abstractions and its effect on machine learning, which is not related to the difference between batch inference and online inference.\"\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about the difference between batch inference and online inference, making it highly relevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"**Batch inference** and **online inference** differ mainly in the way predictions are made and data is processed.\",\\n    \"Batch Inference (Infer√™ncia em Lote) consists of processing large groups of data at once.\",\\n    \"Batch Inference is ideal for updating models or making mass predictions where real-time is not necessary.\",\\n    \"Example: Updating a model with historical data or making predictions for millions of records simultaneously.\",\\n    \"**Online inference** involves obtaining data continuously and processing it in real-time.\",\\n    \"Online Inference is used when an immediate result is needed, such as in recommendation systems or fraud detection.\",\\n    \"Example: A recommendation system that suggests products in real-time based on user behavior.\",\\n    \"In summary, **Batch**: Processing in batch, ideal for updates and mass predictions.\",\\n    \"**Online**: Processing in real-time, ideal for applications that require an instant response.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The automated ML training pipeline can fetch a batch of feature values for continuous training.\",\\n    \"The prediction service can fetch in batches of feature values related to an entity, such as customer demographic features, product features, and current session aggregation features.\",\\n    \"For online prediction and feature retrieval, the prediction service identifies relevant features for an entity.\",\\n    \"Composite prediction routines allow multiple models to be invoked hierarchically or simultaneously before results are aggregated.\",\\n    \"Efficient use of ML inference accelerators with autoscaling can match spiky workloads and balance cost with latency.\",\\n    \"The model explainability feature uses techniques like feature attributions for a given model prediction.\",\\n    \"Logging of prediction serving requests and responses is supported for analysis.\",\\n    \"Online experimentation allows understanding how newly trained models perform in production settings compared to current models before releasing the new model to production.\",\\n    \"Canary and shadow deployments, traffic splitting, A/B tests, and multi-armed bandit (MAB) tests are supported in online experimentation.\",\\n    \"The model monitoring capability tracks the efficiency and effectiveness of deployed models in production to ensure predictive quality and business continuity.\",\\n    \"There is a lack of widely accepted abstractions for distributed learning in machine learning.\"\\n] \\n \\nClaims:\\n[\\n    \"A diferen√ßa entre batch inference e online inference est√° principalmente no modo como as previs√µes s√£o realizadas e os dados s√£o processados.\",\\n    \"Batch Inference (Infer√™ncia em Lote) consiste em processar grupos grandes de dados de uma vez (em lote).\",\\n    \"Batch Inference (Infer√™ncia em Lote) √© ideal para atualiza√ß√µes de modelos ou previs√µes em massa, onde n√£o √© necess√°rio tempo real.\",\\n    \"Exemplo: Atualizar um modelo com dados hist√≥ricos ou fazer previs√µes para milh√µes de registros de forma simult√¢nea.\",\\n    \"Online Inference (Infer√™ncia Online) envolve a obten√ß√£o de dados de forma cont√≠nua e process√°-los em tempo real.\",\\n    \"Online Inference (Infer√™ncia Online) √© usada quando √© necess√°rio um resultado imediato, como em sistemas de recomenda√ß√£o ou detec√ß√£o de fraudes.\",\\n    \"Exemplo: Um sistema de recomenda√ß√£o que sugere produtos em tempo real com base no comportamento do usu√°rio.\",\\n    \"Em resumo: Batch: Processamento em lote, ideal para atualiza√ß√µes e previs√µes em massa. Online: Processamento em tempo real, ideal para aplica√ß√µes que exigem resposta instant√¢nea.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claims do not directly contradict the retrieval context, but they are specific to machine learning and inference techniques. The retrieval context only provides general information about ML training pipelines and prediction services.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'Diferen√ßa entre batch inference e online inference?',\n",
       "  'actual_output': 'A diferen√ßa entre **batch inference** e **online inference** est√° principalmente no **modo como as previs√µes s√£o realizadas e os dados s√£o processados**:\\n\\n1. **Batch Inference (Infer√™ncia em Lote)**:\\n   - Consiste em processar grupos grandes de dados de uma vez (em lote).\\n   - √â ideal para atualiza√ß√µes de modelos ou previs√µes em massa, onde n√£o √© necess√°rio tempo real.\\n   - Exemplo: Atualizar um modelo com dados hist√≥ricos ou fazer previs√µes para milh√µes de registros de forma simult√¢nea.\\n\\n2. **Online Inference (Infer√™ncia Online)**:\\n   - Envolve a obten√ß√£o de dados de forma cont√≠nua e process√°-los em tempo real.\\n   - √â usada quando √© necess√°rio um resultado imediato, como em sistemas de recomenda√ß√£o ou detec√ß√£o de fraudes.\\n   - Exemplo: Um sistema de recomenda√ß√£o que sugere produtos em tempo real com base no comportamento do usu√°rio.\\n\\nEm resumo:\\n- **Batch**: Processamento em lote, ideal para atualiza√ß√µes e previs√µes em massa.\\n- **Online**: Processamento em tempo real, ideal para aplica√ß√µes que exigem resposta instant√¢nea.',\n",
       "  'expected_output': 'Batch inference processa grandes volumes de dados periodicamente, enquanto online inference responde em tempo real para requisi√ß√µes individuais.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['store to run their experiments.\\nFor continuous training, the automated ML training pipeline can fetch a batch of\\nthe up-to-date feature values of the dataset that are used for the training task.\\nFor online prediction, the prediction service can fetch in a batch of the feature\\nvalues related to the requested entity, such as customer demographic features,\\nproduct features, and current session aggregation features.\\nFor online prediction and feature retrieval, the prediction service identifies the\\nrelevant features for an entity. For example, if the entity is a customer, relevant\\nfeatures might include age, purchase history, and browsing behavior. The service\\nbatches these feature values together and retrieves all the needed features for\\nthe entity at once, rather than individually. This retrieval method helps with\\nefficiency, especially when you need to manage multiple entities.',\n",
       "   '‚Ä¢ Enable composite prediction routines, where multiple models are invoked hierarchically or simultaneously \\nbefore the results are aggregated, in addition to any required pre- or post-processing routines.\\n‚Ä¢ Allow efficient use of ML inference accelerators with autoscaling to match spiky workloads and to balance \\n13\\ncost with latency.\\n‚Ä¢ Support model explainability using techniques like feature attributions for a given model prediction.\\n‚Ä¢ Support logging of prediction serving requests and responses for analysis. \\nOnline experimentation\\nThe online experimentation capability lets you understand how newly trained models perform in production settings \\ncompared to the current models (if any) before you release the new model to production. For example, using a small \\nsubset of the serving population, you use online experimentation to understand the impact that a new recommen -\\ndation system has on click-throughs and on conversation rates. The results of online experimentation should be',\n",
       "   'dation system has on click-throughs and on conversation rates. The results of online experimentation should be \\nintegrated with the model registry capability to facilitate the decision about releasing the model to production. Online \\nexperimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models \\nand to promote well-performing ones. Key functionalities in online experimentation include the following:\\n‚Ä¢ Support canary and shadow deployments.\\n‚Ä¢ Support traffic splitting and A/B tests.\\n‚Ä¢ Support multi-armed bandit (MAB) tests.\\nModel monitoring\\nThe model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production \\nto ensure predictive quality and business continuity. This capability informs you if your models are stale and need to \\nbe investigated and updated. Key functionalities in model monitoring include the following:',\n",
       "   'behavior of a given model before it is released. These feedba ck loops can take different forms, but\\nthey are all more difÔ¨Åcult to detect and address if they occur gradually over time, as may be the case\\nwhen models are updated infrequently.\\nDirect Feedback Loops. A model may directly inÔ¨Çuence the selection of its own future training\\ndata. It is common practice to use standard supervised algor ithms, although the theoretically correct\\nsolution would be to use bandit algorithms. The problem here is that bandit algorithms (such as\\ncontextual bandits ) do not necessarily scale well to the size of action spaces typically required for\\nreal-world problems. It is possible to mitigate these effec ts by using some amount of randomization\\n, or by isolating certain parts of data from being inÔ¨Çuenc ed by a given model.\\nHidden Feedback Loops. Direct feedback loops are costly to analyze, but at least the y pose a',\n",
       "   'stractions to support ML systems. Zheng recently made a comp elling comparison of the state ML\\nabstractions to the state of database technology , maki ng the point that nothing in the machine\\nlearning literature comes close to the success of the relati onal database as a basic abstraction. What\\nis the right interface to describe a stream of data, or a model , or a prediction?\\nFor distributed learning in particular, there remains a lac k of widely accepted abstractions. It could\\nbe argued that the widespread use of Map-Reduce in machine le arning was driven by the void of\\nstrong distributed learning abstractions. Indeed, one of t he few areas of broad agreement in recent\\nyears appears to be that Map-Reduce is a poor abstraction for iterative ML algorithms.\\n5\\nThe parameter-server abstraction seems much more robust, b ut there are multiple competing speci-\\nÔ¨Åcations of this basic idea . The lack of standard abst ractions makes it all too easy to blur the\\nlines between components.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.625,\n",
       "    'reason': \"The score is 0.62 because irrelevant nodes, such as those discussing legacy features and configuration systems, are correctly ranked lower than relevant nodes that mention 'feature drift' or provide specific examples, like Covid-19 and fairy tales.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'feature drift\\' which is the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not mention anything about data versioning or model development, which are not relevant to the topic of feature drift.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This section talks about legacy features, bundled features, and correlated features, but it\\'s not directly related to feature drift.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions examples of feature A, B, C, D, D\\', Z, Q, and R, which are all relevant to the topic of feature drift.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This section talks about configuration systems and how they should be easy to modify correctly, but it\\'s not directly related to feature drift.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions participants citing Covid as an example of unnatural data drift, which is relevant to the topic of feature drift.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This section talks about natural data drift and how frequent model retrains solve this problem, but it\\'s not directly related to feature drift.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions an example of a fairy tale (Goldilocks) which is not relevant to the topic of feature drift.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the contextual recall score indicates that there are some supportive reasons for attributing sentences to nodes in the retrieval context, but also some unsupportive reasons where sentences cannot be attributed, suggesting a moderate level of alignment between the expected output and the retrieval context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'Model development\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'some products. A year later, the code that stops populating t he database with the old numbers is\\\\ndeleted.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Underutilized data dependencies can creep into a model in se veral ways.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Legacy Features. The most common case is that a feature Fis included in a model early in\\\\nits development.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Because of deadline pressures or similar effects, all the fe atures in the bundle are added to\\\\nthe model together, possibly including features that add li ttle or no value.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'\\\\u2022\\\\u01eb-Features. As machine learning researchers, it is tempting to improve m odel accuracy\\\\neven when the accuracy gain is very small or when the complexi ty overhead might be high.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Consider the following examples. Feature Awas incorrectly logged from 9/14 to 9/17.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Feature Bis\\\\nnot available on data before 10/7.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'The code used to compute fe atureChas to change for data before\\\\nand after 11/1 because of changes to the logging format.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Feat ureDis not available in production, so\\\\na substitute features D\\\\u2032andD\\\\u2032\\\\u2032must be used when querying the model in a live setting.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'If feat ure\\\\nZis used, then jobs for training must be given extra memory due to lookup tables or they will train\\\\ninef\\\\ufb01ciently.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Feature Qprecludes the use of feature Rbecause of latency constraints.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'All this messiness makes con\\\\ufb01guration hard to modify correc tly, and hard to reason about.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'How-\\\\never, mistakes in con\\\\ufb01guration can be costly, leading to ser ious loss of time, waste of computing\\\\nresources, or production issues.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'\\\\u2022It should be easy to specify a con\\\\ufb01guration as a small change f rom a previous con\\\\ufb01guration.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'participants cited Covid as an example, but there are other\\\\n(better) everyday instances of unnatural data drift.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'P6 de-\\\\nscribed a bug where users had inconsistent definitions of the\\\\nsame word, complicating the deployment of a service to a\\\\nnew user.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'P7 mentioned a bug where data from users in a\\\\ncertain geographic region arrived more sporadically than\\\\nusual.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'P10 discussed a bug where the format of raw data was\\\\noccasionally corrupted: \\\\u201cTables didn\\\\u2019t always have headers\\\\nin the same place, even though they were the same tables.\\\\u201d\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'\\\\u2022Natural data drift: Surprisingly, participants didn\\\\u2019t seem\\\\ntoo worried about slower, expected natural data drift over\\\\ntime\\\\u2014they noted that frequent model retrains solved this\\\\nproblem (P6, P7, P8, P12, P15, P16, P17).\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'As an anecdote, we\\\\nasked P17 to give an example of a natural data drift problem\\\\ntheir company faced, and they could not think of a good\\\\nexample.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'P14 also said they don\\\\u2019t have natural data drift\\\\nproblems:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\\\ncharacter, looks for things that are not too big or not too small, things that are \\\\u201cjust\\\\nright.\\\\u201d\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Operationalizing Machine Learning: An Interview Study\\\\nThe model gets retrained every day, so we don\\\\u2019t have the\\\\nscenario of like: Oh, our models got stale and we need to re-\\\\ntrain it because it\\\\u2019s starting to make mistakes because data\\\\nhas drifted...fortunately we\\\\u2019ve never had to deal with [such\\\\na] scenario.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Sometimes there are bad jobs, but\\\\nwe can always effectively roll back to a different .\\'\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5641025641025641,\n",
       "    'reason': \"The score is 0.56 because the retrieval context contained general information about configuration and irrelevant statements, but one statement in the context ('It involves tracking and managing different versions of the data...') is actually relevant to the input question 'O que √© feature drift?'\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It involves tracking and managing different versions of the data, allowing for traceability of results and the ability to revert to previous states if necessary.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The concept of a feature store is then introduced as a centralized repository for storing and managing features used in model training.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Feature stores promote consistency and reusability of features across different models and projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By having a dedicated system for feature management, teams can ensure they use the most relevant and up-to-date features.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"some products.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A year later, the code that stops populating t he database with the old numbers is deleted.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This will not be a good day for the maintainers of the ML system.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Underutilized data dependencies can creep into a model in several ways.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Legacy Features. The most common case is that a feature Fis included in a model early in its development. Over time, Fis made redundant by new features but this goes undetected.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Bundled Features. Sometimes, a group of features is evaluated and found to be beneficial. Because of deadline pressures or similar effects, all the fe atures in the bundle are added to the model together, possibly including features that add li ttle or no value.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u01eb-Features. As machine learning researchers, it is tempting to improve m odel accuracy even when the accuracy gain is very small or when the complexi ty overhead might be high.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Correlated Features. Often two features are strongly correlated, but one is more d irectly\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Consider the following examples.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained general information about configuration, but it has nothing to do with \\'feature drift\\'.\"\\n            },\\n            {\\n                \"statement\": \"Feature Awas incorrectly logged from 9/14 to 9/17.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Feature Bis not available on data before 10/7.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The code used to compute fe atureChas to change for data before and after 11/1 because of changes to the logging format.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Feat ureDis not available in production, so a substitute features D\\\\u2032andD\\\\u2032\\\\u2032must be used when querying the model in a live setting.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"If feat ure Zis used, then jobs for training must be given extra memory due to lookup tables or they will train inefficiently.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Feature Qprecludes the use of feature Rbecause of latency constraints.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"All this messiness makes con\\\\ufb01guration hard to modify correctly, and hard to reason about.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained general information about configuration, but it has nothing to do with \\'feature drift\\'.\"\\n            },\\n            {\\n                \"statement\": \"However, mistakes in con\\\\ufb01guration can be costly, leading to serious loss of time, waste of computing resources, or production issues.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained general information about configuration, but it has nothing to do with \\'feature drift\\'.\"\\n            },\\n            {\\n                \"statement\": \"This leads us to articulat e the following principles of good con\\\\ufb01guration systems:\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained general information about configuration, but it has nothing to do with \\'feature drift\\'.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"participants cited Covid as an example\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"there are other (better) everyday instances of unnatural data drift\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P6 described a bug where users had inconsistent definitions of the same word, complicating the deployment of a service to a new user.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P7 mentioned a bug where data from users in a certain geographic region arrived more sporadically than usual.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P10 discussed a bug where the format of raw data was occasionally corrupted: \\\\u201cTables didn\\\\u2019t always have headers in the same place, even though they were the same tables.\\\\u201d\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Natural data drift: Surprisingly, participants didn\\\\u2019t seem too worried about slower, expected natural data drift over time\\\\u2014they noted that frequent model retrains solved this problem (P6, P7, P8, P12, P15, P16, P17).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"As an anecdote, we asked P17 to give an example of a natural data drift problem their company faced, and they could not think of a good example.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P14 also said they don\\\\u2019t have natural data drift problems:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"asked P17 to give an example of a natural data drift problem\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"5Goldilocks and the Three Bears is a popular Western fairy tale.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'5Goldilocks and the Three Bears...\\' when it has nothing to do with feature drift.\"\\n            },\\n            {\\n                \"statement\": \"Operationalizing Machine Learning: An Interview Study\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Operationalizing Machine Learning: An Interview Study\\' when it has nothing to do with feature drift.\"\\n            },\\n            {\\n                \"statement\": \"The model gets retrained every day, so we don\\\\u2019t have the scenario of like: Oh, our models got stale and we need to re- train it because it\\\\u2019s starting to make mistakes because data has drifted...\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Sometimes there are bad jobs, but we can always effectively roll back to a different .\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Sometimes there are bad jobs...\\' when it has nothing to do with feature drift.\"\\n            },\\n            {\\n                \"statement\": \"However, a few engineers mentioned that natural data shift could cause some hand-curated features and data quality checks to corrupt (P3, P6, P8).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P6 discussed a histogram used\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'P6 discussed a histogram used\\' when it has nothing to do with feature drift.\"\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the answer perfectly addresses the question about feature drift, with no irrelevant information present.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"**Feature drift** occurs when the characteristics of input data change over time.\",\\n    \"This can happen for various reasons such as **inconsistent definitions**, **regional variation**, **data corruption**, or **changes in data behavior**.\",\\n    \"Some may worry about *natural drift* (slow and expected changes in data), but many projects resolve this by retraining models frequently.\",\\n    \"It\\'s important to monitor and handle drift to ensure the model remains precise and efficient.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The statement provides a clear definition of feature drift, which is relevant to addressing the input question.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the actual output contradicts the retrieval context by making a claim unrelated to data or machine learning, despite the context not mentioning these topics.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"Einstein won the noble prize for his discovery of the photoelectric effect in 1968.\",\\n    \"The photoelectric effect is a phenomenon that laid the foundation for quantum mechanics.\"\\n] \\n \\nClaims:\\n[\\n    \"Ethereal drift occurs when the features of input data change over time, affecting the performance of a model.\",\\n    \"Feature drift can happen due to inconsistent definitions, regional variation, corrupted data, or changes in data behavior.\",\\n    \"Some people may worry about natural drift (slow and expected changes in data), but many projects resolve this by retraining models frequently.\",\\n    \"It is important to monitor and handle feature drift to ensure the model remains precise and efficient.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not mention anything about data or machine learning, so the claim is factually incorrect but non-contradictory.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context only talks about Einstein\\'s discovery and has no relation to feature drift or model performance.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© feature drift?',\n",
       "  'actual_output': 'Ol√°! üòä Vamos entender o que √© **feature drift**.\\n\\nNo contexto de machine learning, **feature drift** (tamb√©m conhecido como *drift de dados*) ocorre quando as caracter√≠sticas (features) dos dados de entrada mudam ao longo do tempo, afetando a performance do modelo. Isso pode acontecer por v√°rias raz√µes, como:\\n\\n- **Defini√ß√µes inconsistentes**: Por exemplo, uma mesma palavra pode ter significados diferentes em diferentes contextos, dificultando a previs√£o do modelo.\\n- **Varia√ß√£o regional**: Dados de usu√°rios de uma regi√£o espec√≠fica podem ter padr√µes diferentes dos demais.\\n- **Corrup√ß√£o de dados**: O formato dos dados pode mudar, como tabelas sem headers consistentes.\\n- **Mudan√ßas no comportamento dos dados**: Mesmo varia√ß√µes lentas e naturais ao longo do tempo (como mudan√ßas na forma como os dados s√£o coletados) podem impactar o modelo.\\n\\nAl√©m disso, o contexto menciona que, embora alguns possam se preocupar com o chamado *drift natural* (mudan√ßas lentas e esperadas nos dados), muitos projetos resolvem isso retrainando os modelos com frequ√™ncia (como diariamente). No entanto, √© importante monitorar e lidar com o drift para garantir que o modelo continue preciso e eficiente.\\n\\nEspero que tenha entendido melhor! Se tiver mais d√∫vidas, √© s√≥ perguntar. üòä',\n",
       "  'expected_output': '√â a mudan√ßa na distribui√ß√£o estat√≠stica das features usadas pelo modelo ao longo do tempo.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['Data versioning plays a pivotal role in maintaining the integrity and reproducibility of data analysis. It involves tracking and managing different versions of the data, allowing for traceability of results and the ability to revert to previous states if necessary. Versioning ensures that others can replicate and verify analyses, promoting transparency and reliability in data science projects.\\n\\nThe concept of a feature store is then introduced as a centralized repository for storing and managing features used in model training. Feature stores promote consistency and reusability of features across different models and projects. By having a dedicated system for feature management, teams can ensure they use the most relevant and up-to-date features.\\n\\nModel development',\n",
       "   'some products. A year later, the code that stops populating t he database with the old numbers is\\ndeleted. This will not be a good day for the maintainers of the ML system.\\nUnderutilized data dependencies can creep into a model in se veral ways.\\n‚Ä¢Legacy Features. The most common case is that a feature Fis included in a model early in\\nits development. Over time, Fis made redundant by new features but this goes undetected.\\n‚Ä¢Bundled Features. Sometimes, a group of features is evaluated and found to be be neÔ¨Åcial.\\nBecause of deadline pressures or similar effects, all the fe atures in the bundle are added to\\nthe model together, possibly including features that add li ttle or no value.\\n‚Ä¢«´-Features. As machine learning researchers, it is tempting to improve m odel accuracy\\neven when the accuracy gain is very small or when the complexi ty overhead might be high.\\n‚Ä¢Correlated Features. Often two features are strongly correlated, but one is more d irectly',\n",
       "   'Consider the following examples. Feature Awas incorrectly logged from 9/14 to 9/17. Feature Bis\\nnot available on data before 10/7. The code used to compute fe atureChas to change for data before\\nand after 11/1 because of changes to the logging format. Feat ureDis not available in production, so\\na substitute features D‚Ä≤andD‚Ä≤‚Ä≤must be used when querying the model in a live setting. If feat ure\\nZis used, then jobs for training must be given extra memory due to lookup tables or they will train\\ninefÔ¨Åciently. Feature Qprecludes the use of feature Rbecause of latency constraints.\\nAll this messiness makes conÔ¨Åguration hard to modify correc tly, and hard to reason about. How-\\never, mistakes in conÔ¨Åguration can be costly, leading to ser ious loss of time, waste of computing\\nresources, or production issues. This leads us to articulat e the following principles of good conÔ¨Ågu-\\nration systems:\\n‚Ä¢It should be easy to specify a conÔ¨Åguration as a small change f rom a previous conÔ¨Åguration.',\n",
       "   'participants cited Covid as an example, but there are other\\n(better) everyday instances of unnatural data drift. P6 de-\\nscribed a bug where users had inconsistent definitions of the\\nsame word, complicating the deployment of a service to a\\nnew user. P7 mentioned a bug where data from users in a\\ncertain geographic region arrived more sporadically than\\nusual. P10 discussed a bug where the format of raw data was\\noccasionally corrupted: ‚ÄúTables didn‚Äôt always have headers\\nin the same place, even though they were the same tables.‚Äù\\n‚Ä¢Natural data drift: Surprisingly, participants didn‚Äôt seem\\ntoo worried about slower, expected natural data drift over\\ntime‚Äîthey noted that frequent model retrains solved this\\nproblem (P6, P7, P8, P12, P15, P16, P17). As an anecdote, we\\nasked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:',\n",
       "   'asked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:\\n5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\ncharacter, looks for things that are not too big or not too small, things that are ‚Äújust\\nright.‚Äù\\nOperationalizing Machine Learning: An Interview Study\\nThe model gets retrained every day, so we don‚Äôt have the\\nscenario of like: Oh, our models got stale and we need to re-\\ntrain it because it‚Äôs starting to make mistakes because data\\nhas drifted...fortunately we‚Äôve never had to deal with [such\\na] scenario. Sometimes there are bad jobs, but\\nwe can always effectively roll back to a different .\\nHowever, a few engineers mentioned that natural data shift\\ncould cause some hand-curated features and data quality\\nchecks to corrupt (P3, P6, P8). P6 discussed a histogram used'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': \"The score is 0.50 because the irrelevant nodes (nodes 1, 3, and 5) are correctly ranked lower than the relevant nodes (nodes 2 and 4), but there's still room for improvement as some relevant nodes (node 6) are not ranked higher than others.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This document does not contain any information about concept drift or its effects on machine learning models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions that the model gets retrained every day, which suggests that the team is aware of and addresses concept drift.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This document does not provide any specific examples or discussions about concept drift.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions that some engineers mentioned natural data shift could cause hand-curated features and data quality checks to corrupt, which is related to concept drift.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This document does not provide any specific information about concept drift or its effects on machine learning models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions that the model is retrained when there is noticeable performance degradation, which could be caused by concept drift.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This document does not provide any specific information about concept drift or its effects on machine learning models.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the contextual recall score indicates that there are some supportive reasons for attributing sentences in the expected output to nodes in the retrieval context, but also some unsupportive reasons where sentences cannot be attributed to any parts of the retrieval context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 1st node: \\'some products. A year later, the code that stops populating t he database with the old numbers is\\\\ndeleted.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 2nd node: \\'Underutilized data dependencies can creep into a model in se veral ways.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 3rd node: \\'\\\\u2022Legacy Features. The most common case is that a feature Fis included in a model early in\\\\nits development.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 4th node: \\'\\\\u2022Bundled Features. Sometimes, a group of features is evaluated and found to be be ne\\\\ufb01cial.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 5th node: \\'\\\\u2022\\\\u01eb-Features. As machine learning researchers, it is tempting to improve m odel accuracy\\\\neven when the accuracy gain is very small or when the complexi ty overhead might be high.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 6th node: \\'\\\\u2022Correlated Features. Often two features are strongly correlated, but one is more d irectly\\', \\'object recognition, probabilities or likelihoods as embeddings). P1\\\\ndescribed a push at their company to rely more on neural networks:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 7th node: \\'A general trend is to try to move more into the neural\\\\nnetwork, and to combine models wherever possible so\\\\nthere are fewer bigger models. Then you don\\\\u2019t have\\\\nthese intermediate dependencies that cause drift and\\\\nperformance regressions...you eliminate entire classes of\\\\nbugs and and issues by consolidating all these different\\\\npiecemeal stacks.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 8th node: \\'4.5.6 Organizationally Supporting ML Engineers Requires Delib-\\\\nerate Practices. Our interviewees reported various organizational\\\\nprocesses for sustaining models as part of their ML infrastructure.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 9th node: \\'P6, P12, P14, P16, P18, and P19 described on-call processes for su-\\\\npervising production ML models. For each model, at any point in\\\\ntime, some ML engineer would be on call, or primarily responsible\\\\nfor it.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 10th node: \\'participants cited Covid as an example, but there are other\\\\n(better) everyday instances of unnatural data drift.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 11th node: \\'P6 described a bug where users had inconsistent definitions of the\\\\nsame word, complicating the deployment of a service to a\\\\nnew user.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 12th node: \\'P7 mentioned a bug where data from users in a\\\\ncertain geographic region arrived more sporadically than\\\\nusual.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 13th node: \\'P10 discussed a bug where the format of raw data was\\\\noccasionally corrupted: \\\\u201cTables didn\\\\u2019t always have headers\\\\nin the same place, even though they were the same tables.\\\\u201d\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 14th node: \\'\\\\u2022Natural data drift: Surprisingly, participants didn\\\\u2019t seem\\\\ntoo worried about slower, expected natural data drift over\\\\ntime\\\\u2014they noted that frequent model retrains solved this\\\\nproblem (P6, P7, P8, P12, P15, P16, P17).\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 15th node: \\'As an anecdote, we\\\\nasked P17 to give an example of a natural data drift problem\\\\ntheir company faced, and they could not think of a good\\\\nexample.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 16th node: \\'P14 also said they don\\\\u2019t have natural data drift\\\\nproblems:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 17th node: \\'5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\\\ncharacter, looks for things that are not too big or not too small, things that are \\\\u201cjust\\\\nright.\\\\u201d\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 18th node: \\'Operationalizing Machine Learning: An Interview Study\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 19th node: \\'The model gets retrained every day, so we don\\\\u2019t have the\\\\nscenario of like: Oh, our models got stale and we need to re-\\\\ntrain it because it\\\\u2019s starting to make mistakes because data\\\\nhas drifted...fortunately we\\\\u2019ve never had to deal with [such\\\\na] scenario.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 20th node: \\'Sometimes there are bad jobs, but\\\\nwe can always effectively roll back to a different .\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 21st node: \\'However, a few engineers mentioned that natural data shift\\\\ncould cause some hand-curated features and data quality\\\\nchecks to corrupt (P3, P6, P8).\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 22nd node: \\'P6 discussed a histogram used\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 23rd node: \\'On availability of new training data: New data isn\\'t systematically available for the ML\\\\nsystem and instead is available on an ad hoc basis when new data is collected and\\\\nmade available in the source databases.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 24th node: \\'On model performance degradation: The model is retrained when there is noticeable\\\\nperformance degradation.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"Attributed to 25th node: \\'On significant changes in the data distributions (concept drift\\\\nXA0(https://en.wikipedia.org/wiki/Concept_drift)).\\'\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.43243243243243246,\n",
       "    'reason': \"The score is 0.43 because the retrieval context contains irrelevant information about natural data drift, legacy features, and bugs, which are not related to concept drift, as stated in reasons such as 'don‚Äôt have natural data drift problems' and '\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"some products.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A year later, the code that stops populating t he database with the old numbers is deleted.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This will not be a good day for the maintainers of the ML system.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Underutilized data dependencies can creep into a model in several ways.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Legacy Features. The most common case is that a feature Fis included in a model early in its development. Over time, Fis made redundant by new features but this goes undetected.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Bundled Features. Sometimes, a group of features is evaluated and found to be beneficial. Because of deadline pressures or similar effects, all the features in the bundle are added to the model together, possibly including features that add little or no value.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u01eb-Features. As machine learning researchers, it is tempting to improve m odel accuracy even when the accuracy gain is very small or when the complexity overhead might be high.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Correlated Features. Often two features are strongly correlated, but one is more directly\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"object recognition\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"probabilities or likelihoods as embeddings)\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A general trend is to try to move more into the neural network, and to combine models wherever possible so there are fewer bigger models.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Then you don\\\\u2019t have these intermediate dependencies that cause drift and performance regressions...you eliminate entire classes of bugs and and issues by consolidating all these different piecemeal stacks.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4.5.6 Organizationally Supporting ML Engineers Requires Delib-erate Practices.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Our interviewees reported various organizational processes for sustaining models as part of their ML infrastructure.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P6, P12, P14, P16, P18, and P19 described on-call processes for supervising production ML models.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For each model, at any point in time, some ML engineer would be on call, or primarily responsible for it.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Any bug or incident observed (e.g., user complaint, pipeline\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"participants cited Covid as an example\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"there are other (better) everyday instances of unnatural data drift\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P6 described a bug where users had inconsistent definitions of the same word, complicating the deployment of a service to a new user.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P7 mentioned a bug where data from users in a certain geographic region arrived more sporadically than usual.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P10 discussed a bug where the format of raw data was occasionally corrupted: \\\\u201cTables didn\\\\u2019t always have headers in the same place, even though they were the same tables.\\\\u201d\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Natural data drift: Surprisingly, participants didn\\\\u2019t seem too worried about slower, expected natural data drift over time\\\\u2014they noted that frequent model retrains solved this problem (P6, P7, P8, P12, P15, P16, P17).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"As an anecdote, we asked P17 to give an example of a natural data drift problem their company faced, and they could not think of a good example.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P14 also said they don\\\\u2019t have natural data drift problems:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"asked P17 to give an example of a natural data drift problem\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P14 also said they don\\\\u2019t have natural data drift problems:\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'don\\\\u2019t have natural data drift problems\\' when it has nothing to do with concept drift.\"\\n            },\\n            {\\n                \"statement\": \"Goldilocks, the main character, looks for things that are not too big or not too small, things that are \\\\u201cjust right.\\\\u201d\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"\\\\\"Goldilocks\\\\\" and \\\\\"Three Bears\\\\\" have nothing to do with concept drift.\"\\n            },\\n            {\\n                \"statement\": \"The model gets retrained every day, so we don\\\\u2019t have the scenario of like: Oh, our models got stale and we need to re- train it because it\\\\u2019s starting to make mistakes because data has drifted...\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Sometimes there are bad jobs, but we can always effectively roll back to a different .\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"\\\\\"bad jobs\\\\\" and \\\\\"roll back to a different\\\\\" have nothing to do with concept drift.\"\\n            },\\n            {\\n                \"statement\": \"However, a few engineers mentioned that natural data shift could cause some hand-curated features and data quality checks to corrupt (P3, P6, P8).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P6 discussed a histogram used\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'P6 discussed a histogram used\\' when it has nothing to do with concept drift.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"On availability of new training data: New data isn\\'t systematically available for the ML system and instead is available on an ad hoc basis when new data is collected and made available in the source databases.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"On model performance degradation: The model is retrained when there is noticeable performance degradation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"On significant changes in the data distributions (concept drift).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It\\'s hard to assess the complete performance of the online model, but you notice significant changes on the data distributions of the features that are used to perform the prediction.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These changes suggest that your model has gone stale, and that needs to be retrained on fresh data.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the answer perfectly addresses the question about concept drift, with no irrelevant statements present.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"O concept drift (tamb√©m conhecido como drift de conceito) √© um fen√¥meno em sistemas de machine learning onde as mudan√ßas significativas nos dados ou na distribui√ß√£o das caracter√≠sticas que o modelo utiliza para fazer previs√µes indicam que o modelo est√° ficando obsoleto ou menos preciso.\",\\n    \"Imagine que voc√™ treina um modelo para prever o tempo do dia com base em dados hist√≥ricos.\",\\n    \"Se, por algum motivo, os padr√µes de dados mudarem (por exemplo, devido a mudan√ßas na esta√ß√£o ou em fatores ambientais), o modelo antigo pode come√ßar a dar respostas menos precisas.\",\\n    \"O concept drift √© quando essas mudan√ßas s√£o detectadas, indicando que √© necess√°rio reatrinar o modelo com novos dados para mant√™-lo preciso e eficiente.\",\\n    \"No contexto de sistemas de machine learning, o concept drift √© um dos principais desafios para garantir que os modelos continuem funcionando bem ao longo do tempo.\",\\n    \"Se n√£o for detectado e corrigido, pode levar a p√©ssimas previs√µes e at√© mesmo a falhas no sistema.\",\\n    \"No texto mencionado, h√° uma refer√™ncia a esse problema quando se fala sobre a necessidade de reatrinar os modelos quando h√° mudan√ßas significativas nos dados.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8,\n",
       "    'reason': 'The score is 0.80 because although there are no direct contradictions with the retrieval context, the actual output mentions potential issues with poor predictions and system failures due to concept drift, which is indirectly addressed in the context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The code that stops populating the database with old numbers is deleted a year later.\",\\n    \"Some products have underutilized data dependencies.\",\\n    \"Legacy Features can creep into a model in several ways.\",\\n    \"Bundled Features can include features that add little or no value.\",\\n    \"«´-Features can be added to improve model accuracy, even when the gain is small.\",\\n    \"Correlated Features can be strongly correlated but one may be more directly related to object recognition.\",\\n    \"The trend is to move towards neural networks and combine models to eliminate intermediate dependencies.\",\\n    \"Some ML engineers are on-call for supervising production ML models.\",\\n    \"There are various organizational processes for sustaining models as part of ML infrastructure.\",\\n    \"Covid-19 was cited as an example of unnatural data drift.\",\\n    \"Natural data drift can be solved by frequent model retrains.\",\\n    \"The model gets retrained every day, so it doesn\\'t get stale.\",\\n    \"New training data is not systematically available and instead is available on an ad hoc basis.\",\\n    \"The model is retrained when there is noticeable performance degradation.\",\\n    \"Significant changes in the data distributions suggest that the model has gone stale and needs to be retrained.\"\\n] \\n \\nClaims:\\n[\\n    \"O **concept drift** (tamb√©m conhecido como **drift de conceito**) √© um fen√¥meno em sistemas de machine learning onde as **mudan√ßas significativas nos dados** ou na **distribui√ß√£o das caracter√≠sticas** (features) que o modelo utiliza para fazer previs√µes indicam que o modelo est√° ficando obsoleto ou menos preciso.\",\\n    \"O concept drift √© quando essas mudan√ßas s√£o detectadas, indicando que √© necess√°rio **reatrinar o modelo** com novos dados para mant√™-lo preciso e eficiente.\",\\n    \"No contexto de sistemas de machine learning, o concept drift √© um dos principais desafios para garantir que os modelos continuem funcionando bem ao longo do tempo.\",\\n    \"Se n√£o for detectado e corrigido, pode levar a **p√©ssimas previs√µes** e at√© mesmo a falhas no sistema.\",\\n    \"Isso √© essencial para evitar que o modelo fique \\'desatualizado\\' e perca sua capacidade de previs√£o.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claims state that concept drift can lead to poor predictions and even system failures, which is not directly contradicted by the retrieval context. However, it does mention the importance of detecting and correcting concept drift to avoid model staleness.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© concept drift?',\n",
       "  'actual_output': 'O **concept drift** (tamb√©m conhecido como **drift de conceito**) √© um fen√¥meno em sistemas de machine learning onde as **mudan√ßas significativas nos dados** ou na **distribui√ß√£o das caracter√≠sticas** (features) que o modelo utiliza para fazer previs√µes indicam que o modelo est√° ficando obsoleto ou menos preciso.\\n\\n### Explica√ß√£o simples:\\nImagine que voc√™ treina um modelo para prever o tempo do dia com base em dados hist√≥ricos. Se, por algum motivo, os padr√µes de dados mudarem (por exemplo, devido a mudan√ßas na esta√ß√£o ou em fatores ambientais), o modelo antigo pode come√ßar a dar respostas menos precisas. O concept drift √© quando essas mudan√ßas s√£o detectadas, indicando que √© necess√°rio **reatrinar o modelo** com novos dados para mant√™-lo preciso e eficiente.\\n\\n### Por que √© importante?\\nNo contexto de sistemas de machine learning, o concept drift √© um dos principais desafios para garantir que os modelos continuem funcionando bem ao longo do tempo. Se n√£o for detectado e corrigido, pode levar a **p√©ssimas previs√µes** e at√© mesmo a falhas no sistema.\\n\\n### Exemplo no contexto:\\nNo texto mencionado, h√° uma refer√™ncia a esse problema quando se fala sobre a necessidade de **reatrinar os modelos** quando h√° mudan√ßas significativas nos dados. Isso √© essencial para evitar que o modelo fique \"desatualizado\" e perca sua capacidade de previs√£o.\\n\\nSe precisar de mais detalhes ou exemplos, √© s√≥ perguntar! üòä',\n",
       "  'expected_output': '√â quando a rela√ß√£o entre as features e a vari√°vel alvo muda, tornando o modelo menos eficaz.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['some products. A year later, the code that stops populating t he database with the old numbers is\\ndeleted. This will not be a good day for the maintainers of the ML system.\\nUnderutilized data dependencies can creep into a model in se veral ways.\\n‚Ä¢Legacy Features. The most common case is that a feature Fis included in a model early in\\nits development. Over time, Fis made redundant by new features but this goes undetected.\\n‚Ä¢Bundled Features. Sometimes, a group of features is evaluated and found to be be neÔ¨Åcial.\\nBecause of deadline pressures or similar effects, all the fe atures in the bundle are added to\\nthe model together, possibly including features that add li ttle or no value.\\n‚Ä¢«´-Features. As machine learning researchers, it is tempting to improve m odel accuracy\\neven when the accuracy gain is very small or when the complexi ty overhead might be high.\\n‚Ä¢Correlated Features. Often two features are strongly correlated, but one is more d irectly',\n",
       "   'object recognition, probabilities or likelihoods as embeddings). P1\\ndescribed a push at their company to rely more on neural networks:\\nA general trend is to try to move more into the neural\\nnetwork, and to combine models wherever possible so\\nthere are fewer bigger models. Then you don‚Äôt have\\nthese intermediate dependencies that cause drift and\\nperformance regressions...you eliminate entire classes of\\nbugs and and issues by consolidating all these different\\npiecemeal stacks.\\n4.5.6 Organizationally Supporting ML Engineers Requires Delib-\\nerate Practices. Our interviewees reported various organizational\\nprocesses for sustaining models as part of their ML infrastructure.\\nP6, P12, P14, P16, P18, and P19 described on-call processes for su-\\npervising production ML models. For each model, at any point in\\ntime, some ML engineer would be on call, or primarily responsible\\nfor it. Any bug or incident observed (e.g., user complaint, pipeline',\n",
       "   'participants cited Covid as an example, but there are other\\n(better) everyday instances of unnatural data drift. P6 de-\\nscribed a bug where users had inconsistent definitions of the\\nsame word, complicating the deployment of a service to a\\nnew user. P7 mentioned a bug where data from users in a\\ncertain geographic region arrived more sporadically than\\nusual. P10 discussed a bug where the format of raw data was\\noccasionally corrupted: ‚ÄúTables didn‚Äôt always have headers\\nin the same place, even though they were the same tables.‚Äù\\n‚Ä¢Natural data drift: Surprisingly, participants didn‚Äôt seem\\ntoo worried about slower, expected natural data drift over\\ntime‚Äîthey noted that frequent model retrains solved this\\nproblem (P6, P7, P8, P12, P15, P16, P17). As an anecdote, we\\nasked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:',\n",
       "   'asked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:\\n5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\ncharacter, looks for things that are not too big or not too small, things that are ‚Äújust\\nright.‚Äù\\nOperationalizing Machine Learning: An Interview Study\\nThe model gets retrained every day, so we don‚Äôt have the\\nscenario of like: Oh, our models got stale and we need to re-\\ntrain it because it‚Äôs starting to make mistakes because data\\nhas drifted...fortunately we‚Äôve never had to deal with [such\\na] scenario. Sometimes there are bad jobs, but\\nwe can always effectively roll back to a different .\\nHowever, a few engineers mentioned that natural data shift\\ncould cause some hand-curated features and data quality\\nchecks to corrupt (P3, P6, P8). P6 discussed a histogram used',\n",
       "   \"On availability of new training data: New data isn't systematically available for the ML\\nsystem and instead is available on an ad hoc basis when new data is collected and\\nmade available in the source databases.11/13/25, 11:39 PM MLOps: Continuous delivery and automation pipelines in machine learning | Cloud Architecture Center | Google Cloud Do‚Ä¶\\nhttps://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning 12/18\\nOn model performance degradation: The model is retrained when there is noticeable\\nperformance degradation.\\nOn significant changes in the data distributions (concept drift\\n\\xa0(https://en.wikipedia.org/wiki/Concept_drift)). It's hard to assess the complete\\nperformance of the online model, but you notice significant changes on the data\\ndistributions of the features that are used to perform the prediction. These changes\\nsuggest that your model has gone stale, and that needs to be retrained on fresh data.\\nChallenges\"],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7095238095238094,\n",
       "    'reason': \"The score is 0.71 because irrelevant nodes, such as those discussing data quality issues (node 3) and minimizing bias in ML models (node 7), should be ranked lower than relevant nodes like those mentioning MLflow's orchestration capabilities (node 1) and experimentation importance (nodes 2 and 5).\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions MLflow as an orchestration tool and a framework for machine learning, which is relevant to the question about what MLflow serves.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about data collection or preprocessing, which is not directly related to the question.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of experimentation and testing in machine learning operations, which aligns with the expected output\\'s mention of registering metrics.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about prediction serving or continuous monitoring, which are not directly related to the question.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions MLflow as a tool for managing and automating machine learning pipelines, which is relevant to the expected output\\'s mention of registering metrics and storing models.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about data quality issues or software engineering practices, which are not directly related to the question.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of experimentation and testing in machine learning operations, which aligns with the expected output\\'s mention of registering metrics.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about minimizing bias in ML models or building infrastructure for ML pipelines, which are not directly related to the question.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5333333333333333,\n",
       "    'reason': 'The score is 0.53 because the contextual recall score indicates that most of the expected output sentences can be attributed to specific nodes in the retrieval context, but there are some sentences that do not have a clear connection to any node.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'https://mlopsnow.com/blog/what-is-mlops/\\'... This sentence is attributed to the 1st node in the retrieval context, which discusses the definition of MLOps and its importance in machine learning.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Data Collection and Data Preprocessing play a critical role...\\'... This sentence is attributed to the 2nd node in the retrieval context, which highlights the significance of data collection and preprocessing in MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'Orchestration in ML Ops involves managing and automating...\\'... This sentence is attributed to the 3rd node in the retrieval context, which discusses the role of orchestration in MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'Optimisation plays a crucial role in maximising...\\'... This sentence is attributed to the 4th node in the retrieval context, which highlights the importance of optimization in MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'Leveraging Open Source Tools and Frameworks...\\'... This sentence is attributed to the 5th node in the retrieval context, which discusses the role of open-source tools and frameworks in MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node: \\'MLOps: An end-to-end workflow...\\'... This sentence is attributed to the 6th node in the retrieval context, which provides a simplified flow for MLOps processes.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node: \\'Figure 3 shows a simplified but canonical flow...\\'... This sentence is attributed to the 7th node in the retrieval context, which provides a diagram for MLOps processes.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"8th node: \\'This is not a waterfall workflow...\\'... This sentence is attributed to the 8th node in the retrieval context, which discusses the flow of MLOps processes.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5806451612903226,\n",
       "    'reason': \"The score is 0.58 because the retrieval context contains statements about machine learning operations (MLOps) and architecture, which are unrelated to the input question 'Para que serve o MLflow?' that asks about the purpose of MLflow. The relevant statements in the retrieval context focus on topics like data collection, orchestration, and model management, whereas MLflow is a tool for tracking and managing machine learning experiments.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"designed architecture ensures smooth collaboration between different teams and streamlines the entire machine learning lifecycle.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data Collection and Data Prep play a critical role in the ML Ops architecture.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"To build accurate and reliable machine learning models, it is essential to have high-quality data from various sources.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data engineers and data scientists work together, leveraging tools like Google Cloud Storage and BigQuery to collect, store, and preprocess the data, making it suitable for model training.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Orchestration in ML Ops involves managing and automating the end-to-end machine learning pipeline.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It plays a significant role in simplifying complex workflows and facilitating collaboration.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Some widely-used orchestration tools include Kubeflow, Apache Airflow, and MLflow.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In addition to orchestration tools, ML Ops practices also focus on testing\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'testing\\' when it has nothing to do with what MLflow is used for.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"workflow must be capable of scaling seamlessly.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Optimisation plays a crucial role in maximising the performance and efficiency of machine learning models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Leveraging open source tools and frameworks such as MLflow and Kubeflow can play a significant role in accelerating the development and\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Prediction serving is about serving the model that is deployed in production for inference.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Continuous monitoring is about monitoring the effectiveness and efficiency of a deployed model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data and model management is a central, cross-cutting function for governing ML artifacts to support audit - ability, traceability, and compliance. Data and model management can also promote shareability, reusability, and discoverability of ML assets.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps: An end-to-end workflow\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Figure 3 shows a simplified but canonical flow for how the MLOps processes interact with each other, focusing on high-level flow of control and on key inputs and outputs.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This is not a waterfall workflow that has to sequentially pass through all the processes. The processes can be skipped, or the flow can repeat a given phase or a subsequence of the processes.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The core activity during this ML development phase is experimentation. As data scientists and ML researchers -\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"on Kandel et al.\\\\u2019s work\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"exploring aspects such as collaboration, code practices, and tools , all centered on gen-eral data analysis and data science\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Many ML-related interview stud-ies focus on a single tool, task, or challenge in the workflow\\\\u2014for example, AutoML , data iteration , model training , minimizing bias in ML models , and building infras-structure for ML pipelines .\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Sambasivan et al. study data quality issues during machine learning, as opposed to challenges in MLOps.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Other ML-related interview studies focus on specific applications of ML, such as medicine , customer service , and interview processing .\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Some interview studies report on software engineering practices for ML development; however, they focus only on a few applications and primarily on engineering, not operational, challenges .\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Our interview study aims to be both broad and focused: we consider many applications and companies,\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Takeaway.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The MLOps anti-patterns described in this section reveal that ML engineering, as a field, is changing faster than educational resources can keep up.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"We see this as opportunities for new resources, such as classroom material (e.g., textbooks, courses) to prescribe the right engineering practices and rigor for the highly experimental discipline that is production ML, and automated documentation assistance for ML pipelines in organizations.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps tool builders may be interested in an organization of the dozens of tools, libraries, and services MLEs use to run ML and data processing pipelines.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Although multiple MLEs reported having to \\\\u201cglue\\\\u201d open-source solutions together and having to build \\\\u201chomegrown\\\\u201d infrastructure as part of their work (P1, P2, P5, P6, P10, P12), an analysis of the various deployments reveals that tools\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Shreya Shankar\\\\u2217, Rolando Garcia\\\\u2217, Joseph M. Hellerstein, Aditya G. Parameswaran Run Layer\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the answer directly addresses the question about the purpose of MLflow, making it highly relevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"MLflow is an open-source tool designed to accelerate the development, deployment, and monitoring of machine learning pipelines.\",\\n    \"Its main features include Experiment Management, Model Packaging and Deployment, Automatic Documentation, and Integration with Orchestration Tools.\",\\n    \"Experiment Management helps organize and compare different model experiments, controlling parameters, metrics, and data versions.\",\\n    \"Model Packaging and Deployment facilitates packaging and deploying models in production, integrating with infrastructure like Docker and Kubernetes.\",\\n    \"Automatic Documentation generates documentation for ML pipelines, making it easier to collaborate between teams.\",\\n    \"Integration with Orchestration Tools combines with other frameworks like Kubeflow and Apache Airflow to manage complex workflows.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The ML Ops architecture ensures smooth collaboration between different teams and streamlines the entire machine learning lifecycle.\",\\n    \"Data Collection and Data Preprocessing play a critical role in the ML Ops architecture.\",\\n    \"Orchestration in ML Ops involves managing and automating the end-to-end machine learning pipeline.\",\\n    \"Some widely-used orchestration tools include Kubeflow, Apache Airflow, and MLflow.\",\\n    \"In addition to orchestration tools, ML Ops practices also focus on testing workflow.\",\\n    \"The infrastructure supporting ML applications ought to be elastic, adjusting resources based on the workload automatically.\",\\n    \"Optimisation plays a crucial role in maximising the performance and efficiency of machine learning models.\",\\n    \"Techniques such as hyperparameter tuning, model pruning, and implementation of efficient algorithms enable the creation of highly performant models without sacrificing accuracy.\",\\n    \"Monitoring tools can provide insights into model performance, allowing for proactive optimisation to maintain satisfactory results.\",\\n    \"Leveraging open source tools and frameworks such as MLflow and Kubeflow can play a significant role in accelerating the development and deployment of machine learning models.\",\\n    \"Prediction serving is about serving the model that is deployed in production for inference.\",\\n    \"Continuous monitoring is about monitoring the effectiveness and efficiency of a deployed model.\",\\n    \"Data and model management is a central, cross-cutting function for governing ML artifacts to support audit-ability, traceability, and compliance.\",\\n    \"The MLOps processes interact with each other through an end-to-end workflow.\",\\n    \"The core activity during the ML development phase is experimentation.\",\\n    \"The MLOps anti-patterns reveal that ML engineering as a field is changing faster than educational resources can keep up.\"\\n] \\n \\nClaims:\\n[\\n    \"MLflow is an open-source tool designed to accelerate the development, deployment, and monitoring of machine learning pipelines.\",\\n    \"MLflow\\'s main features include Experiment Management, Model Packaging and Deployment, Automatic Documentation, and Integration with Orchestration Tools.\",\\n    \"Experiment Management helps organize and compare different model experiments, controlling parameters, metrics, and data versions.\",\\n    \"Model Packaging and Deployment facilitates packaging and deploying models in production, integrating with infrastructure like Docker and Kubernetes.\",\\n    \"Automatic Documentation generates documentation for ML pipelines, making it easier to collaborate between teams.\",\\n    \"MLflow integrates with other frameworks like Kubeflow and Apache Airflow to manage complex workflows.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'Para que serve o MLflow?',\n",
       "  'actual_output': 'O **MLflow** √© uma ferramenta de c√≥digo aberto projetada para acelerar o desenvolvimento, implanta√ß√£o e monitoramento de pipelines de machine learning. Suas principais funcionalidades incluem:\\n\\n1. **Gest√£o de Experimentos**:  \\n   Ajuda a organizar e comparar diferentes experimentos de modelos, controlando par√¢metros, m√©tricas e vers√µes de dados.\\n\\n2. **Modelagem e Implanta√ß√£o**:  \\n   Facilita a empacotamento e implanta√ß√£o de modelos em produ√ß√£o, integrando-se com infraestruturas como Docker e Kubernetes.\\n\\n3. **Documenta√ß√£o Autom√°tica**:  \\n   Gera documenta√ß√£o para pipelines de ML, tornando mais f√°cil a colabora√ß√£o entre equipes.\\n\\n4. **Integra√ß√£o com Ferramentas de Orquestra√ß√£o**:  \\n   Combina-se com outros frameworks como **Kubeflow** e **Apache Airflow** para gerenciar workflows complexos.\\n\\nEm resumo, o MLflow √© essencial para tornar o processo de ML mais eficiente, estruturado e repet√≠vel, especialmente em ambientes de produ√ß√£o.',\n",
       "  'expected_output': 'Gerenciar experimentos, registrar m√©tricas e armazenar modelos.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['https://mlopsnow.com/blog/what-is-mlops/ 7/11\\ndesigned architecture ensures smooth collaboration between different\\nteams and streamlines the entire machine learning lifecycle.\\nData Collection and Data Pr ep play a critical role in the ML Ops\\narchitecture. T o build accurate and reliable machine learning models, it is\\nessential to have high-quality data from various sources. Data engineers\\nand data scientists work together, leveraging tools like Google Cloud\\nStorage and BigQuer y to collect, store, and preprocess the data, making it\\nsuitable for model training.\\nOrchestration and T esting T ools\\nOrchestration in ML Ops involves managing and automating the end-to-\\nend machine learning pipeline. It plays a significant role in simplifying\\ncomplex workflows and facilitating collaboration. Some widely-used\\norchestration tools include Kubeflow , Apache Air flow, and MLflow .\\nIn addition to orchestration tools, ML Ops practices also focus on testing',\n",
       "   'workflow must be capable of scaling seamlessly. The infrastructure\\nsupporting ML applications ought to be elastic, adjusting resources based\\non the workload automatically.\\nOptimisation plays a crucial role in maximising the performance and\\nefficiency of machine learning models. T echniques such as hyperparameter\\ntuning, model pruning, and implementation of efficient algorithms enable\\nthe creation of highly performant models without sacrificing accuracy.\\nAdditionally, monitoring tools can provide insights into model11/11/25, 9:50 PM MLOps Now - The MLOps Platform: Revolutionising Machine Learning Efficiency\\nhttps://mlopsnow.com/blog/mlops-platforms-revolutionising-machine-learning/ 5/10\\nperformance, allowing for proactive optimisation to maintain satisfactory\\nresults.\\nLeveraging Open Sour ce Tools and\\nFramew orks\\nMLflow and Kubeflow\\nLeveraging open source tools and frameworks such as MLflow and\\nKubeflow can play a significant role in accelerating the development and',\n",
       "   '8\\n‚Ä¢ Prediction serving is about serving the model that is deployed in production for inference.\\n‚Ä¢ Continuous monitoring is about monitoring the effectiveness and efficiency of a deployed model.\\n‚Ä¢ Data and model management is a central, cross-cutting function for governing ML artifacts to support audit -\\nability, traceability, and compliance. Data and model management can also promote shareability, reusability, \\nand discoverability of ML assets.\\nMLOps: An end-to-end workflow\\nFigure 3 shows a simplified but canonical flow for how the MLOps processes interact with each other, focusing on \\nhigh-level flow of control and on key inputs and outputs.\\nThis is not a waterfall workflow that has to sequentially pass through all the processes. The processes can be \\nskipped, or the flow can repeat a given phase or a subsequence of the processes. The diagram shows the following \\nflow:\\n1. The core activity during this ML development phase is experimentation. As data scientists and ML research -',\n",
       "   'on Kandel et al.‚Äôs work, exploring aspects such as collaboration,\\ncode practices, and tools , all centered on gen-\\neral data analysis and data science, as opposed to transitioning\\nworkflows in ML to production. Many ML-related interview stud-\\nies focus on a single tool, task, or challenge in the workflow‚Äîfor\\nexample, AutoML , data iteration , model training ,\\nminimizing bias in ML models , and building infras-\\ntructure for ML pipelines . Sambasivan et al. study data\\nquality issues during machine learning, as opposed to challenges\\nin MLOps. Other ML-related interview studies focus on specific\\napplications of ML, such as medicine , customer service ,\\nand interview processing . Some interview studies report on\\nsoftware engineering practices for ML development; however, they\\nfocus only on a few applications and primarily on engineering, not\\noperational, challenges . Our interview study aims to be both\\nbroad and focused: we consider many applications and companies,',\n",
       "   'Takeaway. The MLOps anti-patterns described in this section re-\\nveal that ML engineering, as a field, is changing faster than educa-\\ntional resources can keep up. We see this as opportunities for new\\nresources, such as classroom material (e.g., textbooks, courses) to\\nprescribe the right engineering practices and rigor for the highly\\nexperimental discipline that is production ML, and automated doc-\\numentation assistance for ML pipelines in organizations.\\n5.3 Characterizing the ‚ÄúMLOps Stack‚Äù for Tool\\nBuilders\\nMLOps tool builders may be interested in an organization of the\\ndozens of tools, libraries, and services MLEs use to run ML and\\ndata processing pipelines. Although multiple MLEs reported hav-\\ning to ‚Äúglue‚Äù open-source solutions together and having to build\\n‚Äúhomegrown‚Äù infrastructure as part of their work (P1, P2, P5, P6,\\nP10, P12), an analysis of the various deployments reveals that tools\\nShreya Shankar‚àó, Rolando Garcia‚àó, Joseph M. Hellerstein, Aditya G. Parameswaran\\nRun Layer'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7555555555555555,\n",
       "    'reason': \"The score is 0.76 because irrelevant nodes like 'MLOps level 0' and 'seamless integration of ML into existing processes' are correctly ranked lower than relevant nodes that discuss canary deployment strategies, such as the first node mentioning 'canary deployment', and the third node highlighting the importance of monitoring model performance.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'canary deployment\\' which matches the expected output\\'s mention of a strategy to validate performance before rollout.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not explicitly state what \\'MLOps level 0\\' is, making it irrelevant to the question about canary deployment in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of monitoring model performance and detecting degradation, which aligns with the expected output\\'s mention of validating performance before rollout.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about \\'seamless integration of ML into existing processes\\', making it irrelevant to the question about canary deployment in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions the importance of adopting sound software engineering practices and taking into account factors that make operationalizing ML different from other types of software, which aligns with the expected output\\'s mention of validating performance before rollout.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the contextual recall score indicates that half of the expected output can be attributed to nodes in the retrieval context, while the other half appears to be original statements that do not match any part of the provided context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 1st node of the retrieval context: \\'Deployment refers to the prediction service...\\' This is because the sentence starts with \\'\\\\u00c9 uma estrat\\\\u00e9gia\\' which is a direct quote from the first node.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence cannot be attributed to any part of the retrieval context. It appears to be an original statement about ML model deployment and does not match any part of the provided context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 2nd node of the retrieval context: \\'Lack of active performance monitoring...\\' This is because the sentence talks about tracking or logging model predictions, which is mentioned in this node as a requirement for detecting model performance degradation.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence cannot be attributed to any part of the retrieval context. It appears to be an original statement about ML Ops and does not match any part of the provided context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 3rd node of the retrieval context: \\'The engineering team might have their own complex setup...\\' This is because the sentence talks about API configuration, testing, and deployment, which are mentioned in this node as part of the engineering team\\'s process.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence cannot be attributed to any part of the retrieval context. It appears to be an original statement about ML Ops and does not match any part of the provided context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 4th node of the retrieval context: \\'In addition, production deployment...\\' This is because the sentence talks about A/B testing or online experiments before promoting a model to serve all prediction request traffic, which is mentioned in this node as part of the production deployment process.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence cannot be attributed to any part of the retrieval context. It appears to be an original statement about ML Ops and does not match any part of the provided context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 5th node of the retrieval context: \\'MLOps is more than just...\\' This is because the sentence talks about MLOps being a coordinated approach to ML projects, which is mentioned in this node as part of its definition.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence cannot be attributed to any part of the retrieval context. It appears to be an original statement about ML Ops and does not match any part of the provided context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 6th node of the retrieval context: \\'By adopting an ML...\\' This is because the sentence talks about organisations positioning themselves for better scalability and faster deployment of ML models, which is mentioned in this node as a benefit of adopting MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence cannot be attributed to any part of the retrieval context. It appears to be an original statement about ML Ops and does not match any part of the provided context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 7th node of the retrieval context: \\'Machine Learning Operations...\\' This is because the sentence talks about MLOps standing for Machine Learning Operations, which is mentioned in this node as its definition.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence cannot be attributed to any part of the retrieval context. It appears to be an original statement about ML Ops and does not match any part of the provided context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 8th node of the retrieval context: \\'Capgemini Research noted...\\' This is because the sentence talks about the top three challenges faced by organizations in achieving deployments at scale, which is mentioned in this node as part of a study.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence cannot be attributed to any part of the retrieval context. It appears to be an original statement about ML Ops and does not match any part of the provided context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 9th node of the retrieval context: \\'Organizations need...\\' This is because the sentence talks about organizations needing an automated and streamlined ML process, which is mentioned in this node as a requirement for successfully deploying ML models.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence cannot be attributed to any part of the retrieval context. It appears to be an original statement about ML Ops and does not match any part of the provided context.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the retrieval context provides information about deployment, monitoring, and management of machine learning models, which is not directly relevant to understanding what a canary deployment in ML is. The relevant statements focus on the process of deploying models, whereas the input question seeks a definition or explanation of canary deployment.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Deployment refers to the prediction service: The process is concerned only with deploying the trained model as a prediction service (for example, a microservice with a REST API), rather than deploying the entire ML system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Lack of active performance monitoring: The process doesn\\'t track or log the model predictions and actions, which are required in order to detect model performance degradation and other model behavioral drifts.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The engineering team might have their own complex setup for API configuration, testing, and deployment, including security, regression, and load and canary testing.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In addition, production deployment of a new version of an ML model usually goes through A/B testing or online experiments before the model is promoted to serve all the prediction request traffic.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps level 0 is common in many businesses that are beginning to apply ML to their use cases. This manual, data-scientist-driven process might be sufficient when models are\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"\\\\\"when models are\\\\\" - The statement does not provide any relevant information about canary deployment in ML.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"seamless and efficient integration of ML into existing processes.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps is more than just the technical side of ML lifecycle management; it also incorporates best practices and methods used in software development and DevOps.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Bridging the gap between data scientists, ML engineers, and DevOps, ML Ops enables a more coordinated approach to ML projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Teams can more easily track, reproduce, and iterate on models, ensuring stability and performance in production environments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By adopting an ML Ops approach, organisations not only position themselves for better scalability and faster deployment of ML models, but also optimise resources and reduce risk.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"As a result, businesses can leverage data more effectively, enhancing their decision-making processes and achieving better outcomes in the competitive marketplace.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Fundamentals of ML Ops\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Machine Learning Operations\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps stands for Machine L earning Oper ations . It is an IT practice that\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"from their investments in ML.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Capgemini Research noted that the top three challenges faced by organizations in achieving deployments at scale are lack of mid- to senior-level talent, lack of change-management processes, and lack of strong governance models for achieving scale.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"They also cannot be built without adopting and applying sound software engineering practices, while taking into account the factors that make operationalizing ML different from operational -izing other types of software.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Organizations need an automated and streamlined ML process.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"ly, they can be created by combining vendor tools that each are best suited to particular tasks, developed as custom services, or created as a combination of these approaches.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In most cases, the processes are deployed in stages rather than all at once in a single deployment.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"An organization\\\\u2019s plan for adopting these processes and capabilities should align with business priorities and with the organization\\\\u2019s technical and skills maturity.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For example, many organizations start by focusing on the processes for ML development, model deployment, and prediction serving.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For these organizations, continuous training and continuous monitoring might not be necessary if they are piloting a relatively small number of ML systems.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Figure 4 shows the core set of technical capabilities that are generally required for MLOps. They are abstracted as functional components that can have many-to-many mappings to specific products and technologies.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"MLOps processes take place on an integrated ML platform that has the required development and operations capabilities (described later).\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Infrastructure engineers can provision this type of platform in different environments (like development, test, staging, and production) using configuration management and infrastructure-as-code (IaC) tools like Terraform .\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Each environment is configured with its own set of required compute resources, data access, and subset of MLOps capability services.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Experimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the answer directly addresses the question about what a canary deployment is in Machine Learning, making it highly relevant and accurate.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Canary deployment em ML is an approach to gradual release of a new model or version of machine learning.\",\\n    \"It involves redirecting a small part of the workload (for example, 5% or 10%) to the new model version.\",\\n    \"This allows you to test the new version in a controlled production environment before promoting it for all traffic.\",\\n    \"The technique is often used together with A/B testing or online experiments to compare the performance of the new version with the previous one and ensure that it does not introduce problems before being expanded to all users.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.25,\n",
       "    'reason': 'The score is 0.25 because the actual output does not directly address the concept of canary deployment discussed in the claims, nor does it explicitly mention the specific approach to deploying machine learning models mentioned in the claims.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"MLOps stands for Machine Learning Operations.\",\\n    \"The process of deploying a trained model as a prediction service is concerned only with deploying the trained model and not the entire ML system.\",\\n    \"Lack of active performance monitoring is a characteristic of MLOps level 0.\",\\n    \"MLOps incorporates best practices and methods used in software development and DevOps.\",\\n    \"ML Ops enables a more coordinated approach to ML projects by bridging the gap between data scientists, ML engineers, and DevOps.\",\\n    \"Organizations can leverage data more effectively and achieve better outcomes in the competitive marketplace by adopting an ML Ops approach.\",\\n    \"The top three challenges faced by organizations in achieving deployments at scale are lack of mid- to senior-level talent, lack of change-management processes, and lack of strong governance models for achieving scale.\",\\n    \"ML systems cannot be built in an ad hoc manner, isolated from other IT initiatives like DataOps and DevOps.\",\\n    \"Organizations need an automated and streamlined ML process to successfully deploy ML models in production and manage risk when scaling the number of ML systems.\",\\n    \"The processes are deployed in stages rather than all at once in a single deployment.\",\\n    \"An organization\\'s plan for adopting MLOps processes and capabilities should align with business priorities and with the organization\\'s technical and skills maturity.\",\\n    \"Many organizations start by focusing on the processes for ML development, model deployment, and prediction serving.\",\\n    \"MLOps processes take place on an integrated ML platform that has the required development and operations capabilities.\",\\n    \"Infrastructure engineers can provision this type of platform in different environments (like development, test, staging, and production) using configuration management and infrastructure-as-code (IaC) tools like Terraform.\"\\n] \\n \\nClaims:\\n[\\n    \"Canary deployment √© uma abordagem de lan√ßamento gradual de um novo modelo ou vers√£o de um modelo de machine learning.\",\\n    \"A canary deployment redireciona uma pequena parte da carga de trabalho (por exemplo, 5% ou 10%) para a nova vers√£o do modelo.\",\\n    \"A canary deployment permite que voc√™ teste a nova vers√£o em um ambiente de produ√ß√£o controlado antes de promov√™-la para todo o tr√°fego.\",\\n    \"Essa t√©cnica √© frequentemente usada em conjunto com A/B testing ou experimentos online para comparar o desempenho da nova vers√£o com a vers√£o anterior e garantir que ela n√£o introduza problemas antes de ser expandida para todos os usu√°rios.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claims do not directly contradict the retrieval context, but they are not explicitly mentioned either. The concept of canary deployment is not discussed in the provided text.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claims describe a specific approach to deploying machine learning models, which is not addressed in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claims discuss canary deployment as a technique for testing and validating new model versions, whereas the retrieval context focuses on MLOps processes and capabilities.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© canary deployment em ML?',\n",
       "  'actual_output': 'Canary deployment em ML √© uma abordagem de lan√ßamento gradual de um novo modelo ou vers√£o de um modelo de machine learning. Nessa abordagem, uma pequena parte da carga de trabalho (por exemplo, 5% ou 10%) √© redirecionada para a nova vers√£o do modelo. Isso permite que voc√™ teste a nova vers√£o em um ambiente de produ√ß√£o controlado antes de promov√™-la para todo o tr√°fego.\\n\\nEssa t√©cnica √© frequentemente usada em conjunto com A/B testing ou experimentos online para comparar o desempenho da nova vers√£o com a vers√£o anterior e garantir que ela n√£o introduza problemas antes de ser expandida para todos os usu√°rios.',\n",
       "  'expected_output': '√â uma estrat√©gia onde uma nova vers√£o do modelo √© implantada para uma pequena parcela do tr√°fego para validar performance antes do rollout completo.',\n",
       "  'context': None,\n",
       "  'retrieval_context': [\"Deployment refers to the prediction service: The process is concerned only with\\ndeploying the trained model as a prediction service (for example, a microservice with\\na REST API), rather than deploying the entire ML system.\\nLack of active performance monitoring: The process doesn't track or log the model\\npredictions and actions, which are required in order to detect model performance\\ndegradation and other model behavioral drifts.\\nThe engineering team might have their own complex setup for API configuration, testing,\\nand deployment, including security, regression, and load and canary testing. In addition,\\nproduction deployment of a new version of an ML model usually goes through A/B testing\\nor online experiments before the model is promoted to serve all the prediction request\\ntraffic.\\nChallenges\\nMLOps level 0 is common in many businesses that are beginning to apply ML to their use\\ncases. This manual, data-scientist-driven process might be sufficient when models are\",\n",
       "   'seamless and efficient integration of ML into existing processes.\\nMLOps is more than just the technical side of ML lifecycle management; it\\nalso incorporates best practices and methods used in software\\ndevelopment and DevOps. Bridging the gap between data scientists, ML\\nengineers, and DevOps, ML Ops enables a more coordinated approach to\\nML projects. T eams can more easily track, reproduce, and iterate on\\nmodels, ensuring stability and performance in production environments.\\nBy adopting an ML Ops approach, organisations not only position\\nthemselves for better scalability and faster deployment of ML models, but\\nalso optimise resources and reduce risk. As a result, businesses can\\nleverage data more effectively, enhancing their decision-making processes\\nand achieving better outcomes in the competitive marketplace.\\nFundamentals o f ML Ops\\nMachine Learning Operations\\nMLOps stands for Machine L earning Oper ations . It is an IT practice that',\n",
       "   'from their investments in ML. Capgemini Research noted that the top three challenges faced by organizations in \\nachieving deployments at scale are lack of mid- to senior-level talent, lack of change-management processes, and \\nlack of strong governance models for achieving scale.\\nThe common theme in these and other studies is that ML systems cannot be built in an ad hoc manner, isolated from \\nother IT initiatives like DataOps and DevOps. They also cannot be built without adopting and applying sound software \\nengineering practices, while taking into account the factors that make operationalizing ML different from operational -\\nizing other types of software.\\nOrganizations need an automated and streamlined ML process. This process does not just help the organization \\nsuccessfully deploy ML models in production. It also helps manage risk when organizations scale the number of',\n",
       "   'ly, they can be created by combining vendor tools that each are best suited to particular tasks, developed as custom \\nservices, or created as a combination of these approaches.\\nIn most cases, the processes are deployed in stages rather than all at once in a single deployment. An organization‚Äôs \\nplan for adopting these processes and capabilities should align with business priorities and with the organization‚Äôs \\ntechnical and skills maturity. For example, many organizations start by focusing on the processes for ML develop -\\nment, model deployment, and prediction serving. For these organizations, continuous training and continuous moni -\\ntoring might not be necessary if they are piloting a relatively small number of ML systems.\\nFigure 4 shows the core set of technical capabilities that are generally required for MLOps. They are abstracted as \\nfunctional components that can have many-to-many mappings to specific products and technologies.\\n10',\n",
       "   'tween tasks, the key artifacts created by the tasks, and the relationship of tasks to other upstream and downstream \\nprocesses. In this section, you learn about concrete details of tasks like running a continuous training pipeline, de -\\nploying a model, and monitoring predictive performance of the model.\\n16\\nMLOps processes take place on an integrated ML platform that has the required development and operations capa -\\nbilities (described later). Infrastructure engineers can provision this type of platform in different environments (like \\ndevelopment, test, staging, and production) using configuration management and infrastructure-as-code (IaC) tools \\nlike Terraform . Each environment is configured with its own set of required compute resources, data access, and \\nsubset of MLOps capability services.\\nML development\\nExperimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7555555555555555,\n",
       "    'reason': 'The score is 0.76 because irrelevant nodes, such as those discussing serving trained models (ranked 3) or not providing information about training models (ranked 2), are correctly ranked lower than the relevant nodes that explain what a pipeline is and how it relates to machine learning (ranked 1 and 4).',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'pipeline\\' multiple times, which is directly related to the input question about what a pipeline is.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about training models or retraining them with new data, which is mentioned in the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains what a pipeline is and how it relates to machine learning, which is relevant to the input question.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about serving trained models as prediction services, which is mentioned in the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains how pipelines are used in machine learning and how they can be automated, which is relevant to the input question.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the expected output seems to be related to the development and experimentation stage (1st node) and model continuous delivery stage (5th node), but lacks clear connections to other nodes in the retrieval context, resulting in a moderate recall score.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Pipeline autom\\\\u00e1tico que treina novamente o modelo com novos dados ou drift.\\' can be attributed to the 1st node of the retrieval context, which describes the development and experimentation stage.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific nodes in the retrieval context are attributed to this sentence. It appears to be a standalone statement about pipeline automation.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'You build source code and run various tests.\\' can be attributed to the 2nd node of the retrieval context, which describes the continuous integration stage.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific nodes in the retrieval context are attributed to this sentence. It appears to be a standalone statement about pipeline deployment.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'P10 mentioned that there were parts of a pipeline that no one touched because it was already running in production...\\' can be attributed to the 5th node of the retrieval context, which describes the model continuous delivery stage.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific nodes in the retrieval context are attributed to this sentence. It appears to be a standalone statement about pipeline maintenance.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'aging these pipelines, detecting errors and recovering from failures are all difficult and costly.\\' can be attributed to the 5th node of the retrieval context, which describes the model continuous delivery stage.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific nodes in the retrieval context are attributed to this sentence. It appears to be a standalone statement about pipeline maintenance costs.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'Pipeline jungles can only be avoided by thinking holistically about data collection and feature extraction.\\' can be attributed to the 5th node of the retrieval context, which describes the model continuous delivery stage.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific nodes in the retrieval context are attributed to this sentence. It appears to be a standalone statement about pipeline design.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node: \\'Glue code and pipeline jungles are symptomatic of integration issues that may have a root cause in overly separated \\\\u201cresearch\\\\u201d and \\\\u201cengineering\\\\u201d roles.\\' can be attributed to the 5th node of the retrieval context, which describes the model continuous delivery stage.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific nodes in the retrieval context are attributed to this sentence. It appears to be a standalone statement about pipeline integration issues.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node: \\'\\\\u2022 Trigger pipelines on demand, on a schedule, or in response to specified events.\\' can be attributed to the 4th node of the retrieval context, which describes automated triggering.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific nodes in the retrieval context are attributed to this sentence. It appears to be a standalone statement about pipeline triggers.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"8th node: \\'this phase, data engineers work together with data scientists to prepare and preprocess the data...\\' can be attributed to the 1st node of the retrieval context, which describes the development and experimentation stage.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific nodes in the retrieval context are attributed to this sentence. It appears to be a standalone statement about data preparation.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6333333333333333,\n",
       "    'reason': 'The score is 0.63 because the retrieval context contains statements about pipeline jungles, difficulties in making changes, and the importance of thinking holistically about data collection and feature extraction, which are all relevant to the concept of a pipeline de-retraining model, but not directly related to the definition of what it is.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Development and experimentation: You iteratively try out new ML algorithms and new modeling where the experiment steps are orchestrated.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Pipeline continuous integration: You build source code and run various tests.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Pipeline continuous delivery: You deploy the artifacts produced by the CI stage to the target environment.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Automated triggering: The pipeline is automatically executed in production based on a schedule or in response to a trigger.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model continuous delivery: You serve the trained model as a prediction service for the\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"P10 mentioned that there were parts of a pipeline that no one touched because it was already running in production, and the principal developer who knew most about it had left the company.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P16 said that \\\\u201cmost of the, like, actual models were trained before time.\\\\u201d\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P14 described a \\\\u201cpipeline jungle\\\\u201d that was difficult to maintain:\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"You end up with this pipeline jungle where everything\\\\u2019s super entangled, and it\\\\u2019s really hard to make changes, because just to make one single change, you have to hold so much context in your brain. You\\\\u2019re trying to think about like, okay this one change is gonna affect this system which affects this system, [which creates]...the pipeline got to the point where it was very difficult to make even simple changes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"While writing down institutional knowledge can be straightforward to do once, P6 discussed that in the ML setting, they learn faster than they can document; moreover, people don\\\\u2019t want to read so many different versions of documentation:\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about institutional knowledge and documentation when it has nothing to do with pipeline de retreinamento de modelo.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"aging these pipelines, detecting errors and recovering from failures are all difficult and costly.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing such pipelines often requires expensive end-to-end integration tests.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Pipeline jungles can only be avoided by thinking holistically about data collection and feature extraction.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground up is indeed a major investment of engineering effort, but one that can dramatically reduce ongoing costs and speed further innovation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Glue code and pipeline jungles are symptomatic of integration issues that may have a root cause in overly separated \\\\u201cresearch\\\\u201d and \\\\u201cengineering\\\\u201d roles.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"When ML packages are developed in an ivory-tower setting, the result may appear like black boxes to the teams that employ them in practice.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A hybrid research approach where engineers and researchers are embedded together on the same teams\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'A hybrid research approach...\\' when it has nothing to do with pipeline de-retraining of models.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Trigger pipelines on demand, on a schedule, or in response to specified events.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Enable local interactive execution for debugging during ML development.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Integrate with the ML metadata tracking capability to capture pipeline execution parameters and to produce artifacts.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Provide a set of built-in components for common ML tasks and also allow custom components.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Run on different environments, including local machines and scalable cloud platforms.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Optionally, provide GUI-based tools for designing and building pipelines.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model registry\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Register, organize, track, and version your trained and deployed ML models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Store model metadata and runtime dependencies for deployability.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"this phase, data engineers work together with data scientists to prepare and preprocess the data, performing featur e engineering to ensure the data has the right format and structure.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"During model creation, various data pipelines are developed, enabling the smooth flow of information between the different stages of the machine learning process.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model T raining Once the model has been created, it is trained using a suitable dataset. Model training is an iterative process that involves feeding data into the model for it to learn and make predictions.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Several techniques can be applied during the model training phase, including hyperparameter optimisation, cross-validation, and regularisation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about what a pipeline of retraining a model is, making it highly relevant to the input.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"The pipeline of model retraining is a set of automated steps that allows updating and retraining an existing machine learning model with new data or different parameters.\",\\n    \"This is part of the Model Continuous Delivery, where the model is served as a prediction service and later managed by the Model Registry for governance and discovery.\",\\n    \"Retraining is a way to update the model without having to recreate the entire pipeline from scratch, avoiding the complexity of the \\'jungle of pipelines\\' mentioned.\",\\n    \"The retraining pipeline is an essential part to keep models updated and efficient, especially when there are new data or changes in the production environment.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement is not directly about what a pipeline of model retraining is, but it provides supporting information about the process.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The ML pipeline has iterative stages: development and experimentation, pipeline continuous integration, pipeline continuous delivery, automated triggering, and model continuous delivery.\",\\n    \"Pipelines can become complex and difficult to maintain, referred to as \\'pipeline jungles\\'.\",\\n    \"It is challenging to make changes to these pipelines due to their complexity.\",\\n    \"Documentation of institutional knowledge can be straightforward, but it may not keep pace with the speed at which ML teams learn.\",\\n    \"The technical debt associated with maintaining these pipelines can be costly.\",\\n    \"Testing such pipelines often requires expensive end-to-end integration tests.\",\\n    \"Pipelines jungles can be avoided by thinking holistically about data collection and feature extraction.\",\\n    \"A clean-slate approach to redesigning a pipeline jungle can reduce ongoing costs and speed further innovation.\",\\n    \"Glue code and pipeline jungles are symptoms of integration issues that may have a root cause in overly separated \\'research\\' and \\'engineering\\' roles.\",\\n    \"The model registry capability lets you govern the lifecycle of ML models in a central repository, ensuring quality and enabling model discovery.\",\\n    \"Key functionalities in the model registry include registering, organizing, tracking, and versioning trained and deployed ML models, as well as storing model metadata and runtime dependencies for deployability.\"\\n] \\n \\nClaims:\\n[\\n    \"The pipeline of model retraining is a set of automated steps that allows updating and retraining an existing machine learning model with new data or different parameters.\",\\n    \"This process is part of the Model Continuous Delivery, where the model is served as a prediction service and later managed by the Model Registry for governance and discovery.\",\\n    \"Model retraining is a way to update the model without having to recreate the entire pipeline from scratch, avoiding the complexity of the \\'jungle of pipelines\\' mentioned.\",\\n    \"The pipeline of model retraining is an essential part to keep models updated and efficient, especially when there are new data or changes in the production environment.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© pipeline de retreinamento de modelo?',\n",
       "  'actual_output': 'Ol√°! O **pipeline de retreinamento de modelo** √© um conjunto de etapas automatizadas que permite atualizar e reentrenar um modelo de machine learning existente com novos dados ou diferentes par√¢metros, garantindo que ele continue eficiente ao longo do tempo.\\n\\nNo contexto apresentado, isso faz parte da **Model Continuous Delivery**, onde o modelo √© servido como um servi√ßo de predi√ß√£o e, posteriormente, gerenciado pelo **Model Registry** para governan√ßa e descoberta. O retreinamento √© uma forma de atualizar o modelo sem precisar recriar todo o pipeline do zero, evitando assim a complexidade da \"jungle de pipelines\" mencionada.\\n\\nEm resumo, o pipeline de retreinamento √© uma parte essencial para manter os modelos atualizados e eficientes, especialmente quando h√° novos dados ou mudan√ßas no ambiente de produ√ß√£o. üòä\\n\\nSe voc√™ tiver mais d√∫vidas sobre algum passo espec√≠fico, √© s√≥ perguntar!',\n",
       "  'expected_output': 'Pipeline autom√°tico que treina novamente o modelo com novos dados ou drift.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['1. Development and experimentation: You iteratively try out new ML algorithms and new\\nmodeling where the experiment steps are orchestrated. The output of this stage is the\\nsource code of the ML pipeline steps that are then pushed to a source repository.\\n2. Pipeline continuous integration: You build source code and run various tests. The\\noutputs of this stage are pipeline components (packages, executables, and artifacts)\\nto be deployed in a later stage.\\n3. Pipeline continuous delivery: You deploy the artifacts produced by the CI stage to the\\ntarget environment. The output of this stage is a deployed pipeline with the new\\nimplementation of the model.\\n4. Automated triggering: The pipeline is automatically executed in production based on a\\nschedule or in response to a trigger. The output of this stage is a trained model that is\\npushed to the model registry.\\n5. Model continuous delivery: You serve the trained model as a prediction service for the',\n",
       "   'P10 mentioned that there were parts of a pipeline that no one\\ntouched because it was already running in production, and the\\nprincipal developer who knew most about it had left the company.\\nP16 said that ‚Äúmost of the, like, actual models were trained before\\n time.‚Äù P14 described a ‚Äúpipeline jungle‚Äù that was difficult to\\nmaintain:\\nYou end up with this pipeline jungle where everything‚Äôs\\nsuper entangled, and it‚Äôs really hard to make changes,\\nbecause just to make one single change, you have to\\nhold so much context in your brain. You‚Äôre trying to\\nthink about like, okay this one change is gonna affect\\nthis system which affects this system, [which\\ncreates]...the pipeline got to the point where it was very\\ndifficult to make even simple changes.\\nWhile writing down institutional knowledge can be straightfor-\\nward to do once, P6 discussed that in the ML setting, they learn\\nfaster than they can document; moreover, people don‚Äôt want to\\nread so many different versions of documentation:',\n",
       "   'aging these pipelines, detecting errors and recovering fro m failures are all difÔ¨Åcult and costly .\\nTesting such pipelines often requires expensive end-to-en d integration tests. All of this adds to\\ntechnical debt of a system and makes further innovation more costly.\\nPipeline jungles can only be avoided by thinking holistical ly about data collection and feature ex-\\ntraction. The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground\\nup is indeed a major investment of engineering effort, but on e that can dramatically reduce ongoing\\ncosts and speed further innovation.\\nGlue code and pipeline jungles are symptomatic of integrati on issues that may have a root cause in\\noverly separated ‚Äúresearch‚Äù and ‚Äúengineering‚Äù roles. When M L packages are developed in an ivory-\\ntower setting, the result may appear like black boxes to the t eams that employ them in practice. A\\nhybrid research approach where engineers and researchers a re embedded together on the same teams',\n",
       "   '‚Ä¢ Trigger pipelines on demand, on a schedule, or in response to specified events.\\n‚Ä¢ Enable local interactive execution for debugging during ML development.\\n‚Ä¢ Integrate with the ML metadata tracking capability to capture pipeline execution parameters and to produce \\nartifacts.\\n‚Ä¢ Provide a set of built-in components for common ML tasks and also allow custom components.\\n‚Ä¢ Run on different environments, including local machines and scalable cloud platforms.\\n‚Ä¢ Optionally, provide GUI-based tools for designing and building pipelines.\\nModel registry\\nThe model registry capability lets you govern the lifecycle of the ML models in a central repository. This ensures the \\nquality of the production models and enables model discovery. Key functionalities in the model registry include the \\nfollowing:\\n‚Ä¢ Register, organize, track, and version your trained and deployed ML models.\\n‚Ä¢ Store model metadata and runtime dependencies for deployability.',\n",
       "   'this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8541666666666666,\n",
       "    'reason': \"The score is 0.85 because the relevant nodes (nodes 1, 2, 4 and 6) that discuss 'MLOps', versioning, pipelines, monitoring, managing data science projects, and maintaining ML models are ranked higher than irrelevant nodes (nodes 3 and 5) that don't provide information about logging, data validation, reproducible processes, continuous training pipelines, or data acquisition/preprocessing.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'MLOps\\' which is directly related to the topic of characterizing a good MLOps environment.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text discusses the importance of versioning, pipelines, and monitoring in an MLOps environment, all of which are relevant to the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not provide any information about logging or data validation, which are also important aspects of a good MLOps environment.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text explains that MLOps helps manage the lifecycle of data science projects and ensures best practices are followed at each stage, which is relevant to the topic of characterizing a good MLOps environment.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not provide any information about reproducible processes or continuous training pipelines, which are also important aspects of a good MLOps environment.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text discusses the importance of monitoring and maintaining ML models, which is relevant to the topic of characterizing a good MLOps environment.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not provide any information about data acquisition or preprocessing, which are also important aspects of a good MLOps environment.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.4444444444444444,\n",
       "    'reason': 'The score is 0.44 because the contextual recall score indicates that some sentences in the expected output can be attributed to specific nodes in the retrieval context, while others do not have a clear connection to these nodes.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The phrase \\'MLOps processes take place on an integrated ML platform\\' can be attributed to the 2nd node in the retrieval context, which describes the relationship of tasks to other upstream and downstream processes.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The phrase \\'Experimentation is the core activity in ML development\\' can be attributed to the 3rd node in the retrieval context, which describes concrete details of tasks like running a continuous training pipeline.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The phrase \\'MLOps helps manage the lifecycle of data science projects\\' can be attributed to the 5th node in the retrieval context, which describes the relationship between MLOps and DevOps.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The phrase \\'MLOps is a methodology for ML engineering that unifies ML system development with ML system operations\\' can be attributed to the 9th node in the retrieval context, which describes MLOps as a set of standardized processes and technology capabilities.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7586206896551724,\n",
       "    'reason': \"The score is 0.76 because, despite the lack of direct mentions of 'Data Science' or 'Machine Learning', the retrieval context provides relevant information about MLOps characteristics, such as its lifecycle stages (data acquisition, preprocessing, feature engineering, model training, evaluation, deployment, and monitoring) and concerns like model fairness and adversarial attacks. These statements demonstrate a clear understanding of MLOps principles, making the retrieval context partially relevant to the input.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"MLOps processes take place on an integrated ML platform that has the required development and operations capabilities (described later).\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Infrastructure engineers can provision this type of platform in different environments (like development, test, staging, and production) using configuration management and infrastructure-as-code (IaC) tools like Terraform .\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Each environment is configured with its own set of required compute resources, data access, and subset of MLOps capability services.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Experimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"MLOps helps manage the lifecycle of data science projects and ensures that best practices are followed at each stage.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"DevOps is a combination of development (Dev) and operations (Ops) practices, aimed at unifying software development and IT operations.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The context does not mention \\'Data Science\\' or \\'Machine Learning\\', which are the main topics related to MLOps.\"\\n            },\\n            {\\n                \"statement\": \"This allows data scientists to focus on their core tasks while IT professionals handle operational aspects, creating a more effective and efficient workflow.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A typical data science project consists of several stages: 1. Data acquisition: Obtaining raw data from various sources, such as databases, sensors, or external APIs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"2. Data preprocessing: Cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"3. Feature engineering: Selecting the most relevant data attributes, or \\\\u201cfeatures,\\\\u201d and converting them into a suitable format for ML algorithms.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Model training: Applying ML algorithms to the preprocessed data to create a predictive model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"5. Model evaluation: Assessing the performance of the model and making adjustments to improve its accuracy.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"6. Model deployment: Implementing the ML model into a product, service, or system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"7. Monitoring and maintenance: Continuously monitoring the performance of the ML model and updating it as needed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Handling concerns about model fairness and adversarial attacks.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps is a methodology for ML engineering that unifies ML system development (the ML element) with ML system operations (the Ops element).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It advocates formalizing and (when beneficial) automating critical steps of ML system construction.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps provides a set of standardized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps supports ML development and deployment in the way that DevOps and DataOps support application engineering and data engineering (analytics).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The difference is that when you deploy a web service, you care about resilience, queries per second, load balancing, and so on.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"This statement does not relate to MLOps or its characteristics.\"\\n            },\\n            {\\n                \"statement\": \"When you deploy an ML model, you also need to worry about changes in the data, changes in the model, users trying to game the system, and so on.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"such as business intelligence systems, line of business applications, process control systems, and embedded sys -\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Integrating an ML model into an application is a critical task that involves making sure first that the deployed model is used effectively by the applications, and then monitoring model performance.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In addition to this, you should also collect and monitor relevant business KPIs (for example, click-through rate, revenue uplift, and user experience).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This information helps you understand the impact of the ML model on the business and adapt accordingly.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The MLOps lifecycle encompasses seven integrated and iterative processes, as shown in figure 2.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The processes can consist of the following:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 ML development concerns experimenting and developing a robust and reproducible model training proce -\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about what characterizes a good environment for MLOps, making all statements highly relevant to the input.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"A good MLOps environment is characterized by complete integration of the life cycle.\",\\n    \"It groups all phases of model development and implementation into a single platform, facilitating collaboration between teams and automation of processes.\",\\n    \"Automation of processes uses tools like Terraform and automated pipelines to manage infrastructure from setup to monitoring, reducing errors and increasing efficiency.\",\\n    \"Reproducibility of experiments ensures that each test is replicable, with version control of data, models, and code, avoiding irreproducibility issues.\",\\n    \"Real-time monitoring detects changes in model performance and collects business metrics to ensure system sustainability.\",\\n    \"Operationalization in different environments supports development to production, with specific configurations for each project phase.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"MLOps is a methodology for ML engineering that unifies ML system development with ML system operations.\",\\n    \"MLOps provides a set of standardized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably.\",\\n    \"The MLOps lifecycle encompasses seven integrated and iterative processes.\",\\n    \"These processes can consist of the following: ML development concerns experimenting and developing a robust and reproducible model training process.\",\\n    \"Data acquisition is one stage in the typical data science project.\",\\n    \"Data preprocessing is one stage in the typical data science project.\",\\n    \"Featur e engineering is one stage in the typical data science project.\",\\n    \"Model training is one stage in the typical data science project.\",\\n    \"Model evaluation is one stage in the typical data science project.\",\\n    \"Model deployment is one stage in the typical data science project.\",\\n    \"Monitoring and maintenance is one stage in the typical data science project.\",\\n    \"MLOps helps manage the lifecycle of data science projects and ensures that best practices are followed at each stage.\",\\n    \"The primary goal of DevOps is to reduce the time taken from code changes to operational deployment.\",\\n    \"DevOps is a combination of development (Dev) and operations (Ops) practices, aimed at unifying software development and IT operations.\"\\n] \\n \\nClaims:\\n[\\n    \"E um bom ambiente de MLOps √© caracterizado por integra√ß√£o completa do ciclo de vida.\",\\n    \"Um bom ambiente de MLOps utiliza ferramentas como Terraform e pipelines automatizados para gerenciar desde a infraestrutura at√© o monitoramento, reduzindo erros e aumentando a efici√™ncia.\",\\n    \"E um bom ambiente de MLOps garante que cada teste seja replic√°vel, com controle de vers√µes de dados, modelos e c√≥digo, evitando problemas de irreprodutibilidade.\",\\n    \"Um bom ambiente de MLOps detecta mudan√ßas no desempenho do modelo e coleta m√©tricas de neg√≥cios para garantir a sustentabilidade do sistema.\",\\n    \"E um bom ambiente de MLOps suporta desde desenvolvimento at√© produ√ß√£o, com configura√ß√µes espec√≠ficas para cada fase do projeto.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que caracteriza um bom ambiente de MLOps?',\n",
       "  'actual_output': 'Um bom ambiente de MLOps √© caracterizado por:\\n\\nüîπ **Integra√ß√£o completa do ciclo de vida**: Agrupa todas as fases do desenvolvimento e implanta√ß√£o de modelos ML em uma √∫nica plataforma, facilitando a colabora√ß√£o entre equipes e a automa√ß√£o de processos.\\n\\nüîπ **Automatiza√ß√£o de processos**: Utiliza ferramentas como Terraform e pipelines automatizados para gerenciar desde a infraestrutura at√© o monitoramento, reduzindo erros e aumentando a efici√™ncia.\\n\\nüîπ **Reprodutibilidade de experimentos**: Garante que cada teste seja replic√°vel, com controle de vers√µes de dados, modelos e c√≥digo, evitando problemas de irreprodutibilidade.\\n\\nüîπ **Monitoramento em tempo real**: Detecta mudan√ßas no desempenho do modelo e coleta m√©tricas de neg√≥cios para garantir a sustentabilidade do sistema.\\n\\nüîπ **Operacionaliza√ß√£o em diferentes ambientes**: Suporta desde desenvolvimento at√© produ√ß√£o, com configura√ß√µes espec√≠ficas para cada fase do projeto.\\n\\nEssas caracter√≠sticas permitem que equipes de dados e opera√ß√µes trabalhem de forma alinhada, otimizando o desenvolvimento e implanta√ß√£o de modelos ML. Quer explorar algum desses pontos em mais detalhes? üòä',\n",
       "  'expected_output': 'Um ambiente com versionamento consistente, pipelines automatizados, monitoramento cont√≠nuo, logging estruturado, valida√ß√£o de dados e processos reprodut√≠veis.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['tween tasks, the key artifacts created by the tasks, and the relationship of tasks to other upstream and downstream \\nprocesses. In this section, you learn about concrete details of tasks like running a continuous training pipeline, de -\\nploying a model, and monitoring predictive performance of the model.\\n16\\nMLOps processes take place on an integrated ML platform that has the required development and operations capa -\\nbilities (described later). Infrastructure engineers can provision this type of platform in different environments (like \\ndevelopment, test, staging, and production) using configuration management and infrastructure-as-code (IaC) tools \\nlike Terraform . Each environment is configured with its own set of required compute resources, data access, and \\nsubset of MLOps capability services.\\nML development\\nExperimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for',\n",
       "   '6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.\\nMLOps helps manage the lifecycle of data science projects and ensures\\nthat best practices are followed at each stage. This allows data scientists to\\nfocus on their core tasks while IT professionals handle operational aspects,\\ncreating a more effective and efficient workflow.\\nFor a more in-depth comparison of Data Science and ML Ops check out\\nour other blog post.\\nMLOps and DevOps\\nThe DevOps P aradigm\\nDevOps is a combination of development (Dev) and operations (Ops)\\npractices, aimed at unifying software development and IT operations. The\\nprimary goal of DevOps is to reduce the time taken from code changes to\\noperational deployment. This is achieved by embracing automation for11/11/25, 10:05 PM MLOps Now - What is MLOps? Demystifying Machine Learning Operations',\n",
       "   'https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.',\n",
       "   '‚Ä¢ Handling concerns about model fairness and adversarial attacks.\\nMLOps is a methodology for ML engineering that unifies ML system development (the ML element) with ML system \\noperations (the Ops element). It advocates formalizing and (when beneficial) automating critical steps of ML system \\nconstruction. MLOps provides a set of standardized processes and technology capabilities for building, deploying, \\nand operationalizing ML systems rapidly and reliably.\\nMLOps supports ML development and deployment in the way that DevOps and DataOps support application engi -\\nneering and data engineering (analytics). The difference is that when you deploy a web service, you care about resil -\\nience, queries per second, load balancing, and so on. When you deploy an ML model, you also need to worry about \\nchanges in the data, changes in the model, users trying to game the system, and so on. This is what MLOps is about.',\n",
       "   'such as business intelligence systems, line of business applications, process control systems, and embedded sys -\\ntems. Integrating an ML model into an application is a critical task that involves making sure first that the deployed \\nmodel is used effectively by the applications, and then monitoring model performance. In addition to this, you should \\nalso collect and monitor relevant business KPIs (for example, click-through rate, revenue uplift, and user experience). \\nThis information helps you understand the impact of the ML model on the business and adapt accordingly.\\nFigure 1. The relationship of data engineering, ML engineering, and app engineering\\n7\\nThe MLOps lifecycle\\nThe MLOps lifecycle encompasses seven integrated and iterative processes, as shown in figure 2.\\nThe processes can consist of the following:\\n‚Ä¢ ML development concerns experimenting and developing a robust and reproducible model training proce -'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.9166666666666666,\n",
       "    'reason': 'The score is 0.92 because irrelevant nodes (nodes 3) are correctly ranked lower than relevant nodes, with the first two nodes providing direct explanations of what a machine learning model is, while node 3 focuses on the process of developing and managing models without defining what they are.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'MLOps emphasizes the comprehensive management of the machine learning model lifecycle\\', which is directly related to the topic of what a machine learning model is.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text explains that MLOps focuses on the practical implementation and ongoing management of machine learning models, which aligns with the expected output\\'s description of a machine learning model as an algoritmo treinado com dados para fazer previs\\\\u00f5es ou classifica\\\\u00e7\\\\u00f5es.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about what a machine learning model is, and instead focuses on the process of developing and managing them.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'Model development is a core phase in the data science process\\', which is relevant to understanding what a machine learning model is.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about what a machine learning model is, and instead focuses on the technical creation of models.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6,\n",
       "    'reason': \"The score is 0.60 because the model's ability to partially match the expected output with relevant concepts in the retrieval context, such as machine learning model lifecycle and model development, indicates a decent recall but still leaves some room for improvement.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 1st node in the retrieval context, which mentions \\'machine learning model lifecycle\\' and \\'comprehensive management\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or phrases from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 2nd node in the retrieval context, which discusses \\'model development\\' and \\'constructing and refining machine learning models\\'.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or phrases from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 3rd node in the retrieval context, which mentions \\'correction models\\' and \\'improvement deadlock\\'.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8787878787878788,\n",
       "    'reason': \"The score is 0.88 because the retrieval context provides relevant information about machine learning models, such as their development lifecycle, training, evaluation, deployment, and ongoing management, which are all closely related to the input question 'What is a machine learning model?' The statements in the retrieval context that are actually relevant to the input include phrases like 'Model development', 'Model training', 'Model evaluation', and 'Model deployment', which provide insight into the process of creating and managing machine learning models. These connections demonstrate the contextual relevance between the input question and the retrieval context, resulting in a score of 0.88.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"MLOps emphasizes the comprehensive management of the machine learning model lifecycle\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"When necessary, models are updated to ensure that they continue to function effectively\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The goal is to streamline the deployment process, guarantee models operate at their peak efficiency and foster an environment of continuous improvement\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By focusing on these areas, MLOps ensures that machine learning models meet the immediate needs of their applications and adapt over time to maintain relevance and effectiveness in changing conditions\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"While ML focuses on the technical creation of models, MLOps focuses on the practical implementation and ongoing management of those models in a real-world setting\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Model development\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model development is a core phase in the data science process, focusing on constructing and refining machine learning models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"An essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This process helps optimize model performance and ensures that the development process is transparent and reproducible.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"more expensive to analyze improvements to that model in the future.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The cost increases when correction models are cascaded, with a model for problem A\\\\u2032\\\\u2032learned on top of m\\\\u2032 a, and so on,\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Once in place, a correction cascade can create an improvement deadlock, as improving the accuracy of any individual component actually leads to system-level detriments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Mitigation strategies are to augment learn the corrections directly within the same model by adding features to distinguish among the cases, or to accept the cost of creating a separate model for A\\\\u2032.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Undeclared Consumers. Oftentimes, a prediction from a machine learning model mais made widely accessible, either at runtime or by writing to \\\\ufb01les or logs that may later be consumed by other systems.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without access controls, some of these consu mers may be undeclared , silently using the output of a given model as an input to another system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In mo re classical software engineering,\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'In more classical software engineering\\' when it has nothing to do with what is a machine learning model.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"this phase, data engineers work together with data scientists to prepare and preprocess the data, performing featur e engineering to ensure the data has the right format and structure.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"During model creation, various data pipelines are developed, enabling the smooth flow of information between the different stages of the machine learning process.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Tools such as data engineering platforms can be used to design, test and maintain these pipelines.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Once the model has been created, it is trained using a suitable dataset.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model training is an iterative process that involves feeding data into the model for it to learn and make predictions.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The model is continually adjusted, and its performance is evaluated against a validation dataset to fine-tune its accuracy and effectiveness.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Several techniques can be applied during the model training phase, including hyperparameter optimisation, cross-validation, and regularisation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A typical data science project consists of several stages: 1. Data acquisition: Obtaining raw data from various sources, such as databases, sensors, or external APIs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"2. Data preprocessing: Cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"3. Feature engineering: Selecting the most relevant data attributes, or \\\\u201cfeatures,\\\\u201d and converting them into a suitable format for ML algorithms.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Model training: Applying ML algorithms to the preprocessed data to create a predictive model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"5. Model evaluation: Assessing the performance of the model and making adjustments to improve its accuracy.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"6. Model deployment: Implementing the ML model into a product, service, or system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"7. Monitoring and maintenance: Continuously monitoring the performance of the ML model and updating it as needed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about what a machine learning model is, making all statements highly relevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Um modelo de machine learning √© um algoritmo ou conjunto de regras criado a partir de dados.\",\\n    \"Ele tem a capacidade de aprender padr√µes e fazer previs√µes ou tomar decis√µes.\",\\n    \"O modelo √© treinado com dados para reconhecer esses padr√µes.\",\\n    \"Posteriormente, pode ser aplicado a novos dados para gerar resultados confi√°veis.\",\\n    \"Ele √© constru√≠do a partir de t√©cnicas como aprendizado de m√°quina.\",\\n    \"O modelo √© ajustado iterativamente durante o treinamento.\",\\n    \"Utilizando m√©todos como otimiza√ß√£o de hiperpar√¢metros, valida√ß√£o cruzada e regulariza√ß√£o para melhorar sua precis√£o e efic√°cia.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"MLOps emphasizes the comprehensive management of the machine learning model lifecycle.\",\\n    \"The goal of MLOps is to streamline the deployment process, guarantee models operate at their peak efficiency and foster an environment of continuous improvement.\",\\n    \"MLOps focuses on the practical implementation and ongoing management of machine learning models in a real-world setting.\",\\n    \"Model development is a core phase in the data science process, focusing on constructing and refining machine learning models.\",\\n    \"The objective of model development is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\",\\n    \"Maintaining and tracking experiments is an essential aspect of model development.\",\\n    \"Detailed records of different model iterations, hyperparameter configurations used, and outcomes of various experiments are critical for comparing different models and configurations.\",\\n    \"Optimizing model performance and ensuring that the development process is transparent and reproducible is a goal of model development.\",\\n    \"The cost increases when analyzing improvements to a model in the future.\",\\n    \"A correction cascade can create an improvement deadlock, as improving the accuracy of any individual component actually leads to system-level detriments.\",\\n    \"Mitigation strategies for correction cascades include augmenting to learn corrections directly within the same model or creating a separate model for A‚Ä≤.\",\\n    \"Undeclared consumers may silently use the output of a given model as an input to another system without access controls.\",\\n    \"The data science process consists of several stages: data acquisition, data preprocessing, feature engineering, model training, model evaluation, model deployment, and monitoring and maintenance.\",\\n    \"A typical data science project involves obtaining raw data from various sources, cleaning, transforming, and structuring the data, selecting relevant data attributes, applying ML algorithms to create a predictive model, assessing the performance of the model, implementing the ML model into a product or system, and continuously monitoring the performance of the ML model.\"\\n] \\n \\nClaims:\\n[\\n    \"A machine learning model is an algorithm or set of rules created from data that has the ability to learn patterns and make predictions or take decisions.\",\\n    \"A machine learning model is trained with data to recognize patterns, and can be applied to new data to generate reliable results.\",\\n    \"The development process of a machine learning model involves training it with data using techniques such as optimization of hyperparameters, cross-validation, and regularization to improve its precision and effectiveness.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The claims align with the context, which emphasizes the comprehensive management of machine learning model lifecycle. The claims describe the training process and capabilities of a machine learning model, which is consistent with the context.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© um modelo de machine learning?',\n",
       "  'actual_output': 'Um modelo de machine learning √© um algoritmo ou conjunto de regras criado a partir de dados, que tem a capacidade de aprender padr√µes e fazer previs√µes ou tomar decis√µes. Durante o processo de desenvolvimento, ele √© treinado com dados para reconhecer esses padr√µes e, posteriormente, pode ser aplicado a novos dados para gerar resultados confi√°veis.\\n\\nEle √© constru√≠do a partir de t√©cnicas como aprendizado de m√°quina, onde o modelo √© ajustado iterativamente durante o treinamento, utilizando m√©todos como otimiza√ß√£o de hiperpar√¢metros, valida√ß√£o cruzada e regulariza√ß√£o para melhorar sua precis√£o e efic√°cia.',\n",
       "  'expected_output': 'Um modelo de machine learning √© um algoritmo treinado com dados para fazer previs√µes ou classifica√ß√µes.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['\"MLOps emphasizes the comprehensive management of the machine learning model lifecycle, covering everything from deploying models into production environments to monitoring their performance. When necessary, models are updated to ensure that they continue to function effectively. The goal is to streamline the deployment process, guarantee models operate at their peak efficiency and foster an environment of continuous improvement. By focusing on these areas, MLOps ensures that machine learning models meet the immediate needs of their applications and adapt over time to maintain relevance and effectiveness in changing conditions.\\n\\nWhile ML focuses on the technical creation of models, MLOps focuses on the practical implementation and ongoing management of those models in a real-world setting.',\n",
       "   'Model development\\n\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks. The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\n\\nAn essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments. Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.',\n",
       "   'more expensive to analyze improvements to that model in the f uture. The cost increases when\\ncorrection models are cascaded, with a model for problem A‚Ä≤‚Ä≤learned on top of m‚Ä≤\\na, and so on,\\nfor several slightly different test distributions. Once in place, a correction cascade can create an\\nimprovement deadlock, as improving the accuracy of any indi vidual component actually leads to\\nsystem-level detriments. Mitigation strategies are to aug mentmato learn the corrections directly\\nwithin the same model by adding features to distinguish amon g the cases, or to accept the cost of\\ncreating a separate model for A‚Ä≤.\\nUndeclared Consumers. Oftentimes, a prediction from a machine learning model mais made\\nwidely accessible, either at runtime or by writing to Ô¨Åles or logs that may later be consumed by\\nother systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,',\n",
       "   'this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps',\n",
       "   'https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': \"The score is 0.50 because the relevant nodes (2nd and 4th) are ranked higher than irrelevant nodes (1st and 3rd), which do not provide definitions for 'treinamento de modelo'. The first node's reason is that it doesn't mention the term at all, while the third node talks about machine learning models but doesn't define 'treinamento de modelo'.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context does not mention \\'treinamento de modelo\\' at all.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text clearly explains what treinamento de modelo is, stating that it\\'s the process of adjusting model parameters using labeled or unlabeled data.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context talks about machine learning models and their development, but does not provide a definition for \\'treinamento de modelo\\'.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text explains that model training is part of the data science process, which involves constructing and refining machine learning models.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context discusses model evaluation, deployment, and monitoring, but does not provide a definition for \\'treinamento de modelo\\'.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5614035087719298,\n",
       "    'reason': 'The score is 0.56 because the contextual recall score indicates that the expected output sentence about Treinamento being the process of adjusting model parameters using labeled or unlabeled data can be attributed to the node(s) in retrieval context, but not all sentences can be attributed.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Treinamento \\\\u00e9 o processo de ajustar os par\\\\u00e2metros do modelo usando dados rotulados ou n\\\\u00e3o rotulados.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'more expensive to analyze improvements to that model in the f uture. The cost increases when\\\\ncorrection models are cascaded, with a model for problem A\\\\u2032\\\\u2032learned on top of m\\\\u2032\\\\na, and so on,\\\\nfor several slightly different test distributions.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Once in place, a correction cascade can create an\\\\nimprovement deadlock, as improving the accuracy of any indi vidual component actually leads to\\\\nsystem-level detriments.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Mitigation strategies are to aug mentmato learn the corrections directly\\\\nwithin the same model by adding features to distinguish amon g the cases, or to accept the cost of\\\\ncreating a separate model for A\\\\u2032.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Undeclared Consumers. Oftentimes, a prediction from a machine learning model mais made\\\\nwidely accessible, either at runtime or by writing to \\\\ufb01les or logs that may later be consumed by\\\\nother systems.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Without access controls, some of these consu mers may be undeclared , silently using\\\\nthe output of a given model as an input to another system.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'In mo re classical software engineering,\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Continuous Integration.\\\\nMonit oring identifies model drif t over time.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Without model monitoring,\\\\nproduction systems are flying blind.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'By monitoring for model drift the data\\\\nscience team is able to proactively work rather than reactively.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Testing ensur es the accuracy and r eliability o f models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Validating both\\\\nthe model\\\\u2019s predictions and the data sets used is a fundamental step in\\\\ngreenlighting models for production.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Use A/B t esting t o identif y best models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'A/B testing is sometimes\\\\noverlooked in Machine Learning but is a great way to introduce new\\\\nmodels.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Rather than swapping models out straight away you can introduce\\\\nthe new model alongside the old. This weighted approach allows you to\\\\nsee the efficacy of the new model in production before committing to it.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'4. Version Contr ol\\\\nVersion control is a significant aspect of ML Ops.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'It allows teams to track\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Model development\\\\n\\\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'An essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'This process helps optimize model performance and ensures that the development process is transparent and reproducible.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Evaluation is critical to ensure that the models perform well in real-world scenarios.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Following this, the model is deployed to production.\\'\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.9354838709677419,\n",
       "    'reason': \"The score is 0.94 because the retrieval context discusses machine learning models, their development, evaluation, and monitoring, which are all relevant topics to training a machine learning model. For example, statements like 'Model development is a core phase in the data science process...' and 'Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment.' demonstrate a clear connection to the input question about training a machine learning model.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"more expensive to analyze improvements to that model in the future.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The cost increases when correction models are cascaded, with a model for problem A\\\\u2032\\\\u2032learned on top of m\\\\u2032 a, and so on, for several slightly different test distributions.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Once in place, a correction cascade can create an improvement deadlock, as improving the accuracy of any individual component actually leads to system-level detriments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Mitigation strategies are to augment learn the corrections directly within the same model by adding features to distinguish among the cases, or to accept the cost of creating a separate model for A\\\\u2032.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Undeclared Consumers. Oftentimes, a prediction from a machine learning model mais made widely accessible, either at runtime or by writing to \\\\ufb01les or logs that may later be consumed by other systems.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without access controls, some of these consu mers may be undeclared , silently using the output of a given model as an input to another system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In mo re classical software engineering,\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'In mo re classical software engineering,\\' when it has nothing to do with training a machine learning model.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous Integration.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monit oring identifies model drif t over time.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without model monitoring, production systems are flying blind.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By monitoring for model drift the data science team is able to proactively work rather than reactively.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing ensur es the accuracy and r eliability o f models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Validating both the model\\\\u2019s predictions and the data sets used is a fundamental step in greenlighting models for production.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Use A/B t esting t o identif y best models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A/B testing is sometimes overlooked in Machine Learning but is a great way to introduce new models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Rather than swapping models out straight away you can introduce the new model alongside the old. This weighted approach allows you to see the efficacy of the new model in production before committing to it.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Version Contr ol\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Model development\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model development is a core phase in the data science process, focusing on constructing and refining machine learning models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"An essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This process helps optimize model performance and ensures that the development process is transparent and reproducible.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Evaluation is critical to ensure that the models perform well in real-world scenarios.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about what training a model means, making all statements highly relevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"O treinamento de modelo √© o primeiro passo do desenvolvimento de modelos.\",\\n    \"Os dados preparados s√£o utilizados para ensinar o modelo a fazer previs√µes ou decis√µes.\",\\n    \"Durante esse processo, o modelo aprende padr√µes e rela√ß√µes nos dados.\",\\n    \"O modelo se torna eficaz em suas tarefas.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The cost of analyzing improvements to a machine learning model increases when correction models are cascaded.\",\\n    \"A correction cascade can create an improvement deadlock, where improving the accuracy of any individual component leads to system-level detriments.\",\\n    \"It is possible for a prediction from a machine learning model to be made widely accessible without access controls, allowing undeclared consumers to use the output as input to another system.\",\\n    \"Model monitoring identifies model drift over time and allows data science teams to proactively work rather than reactively.\",\\n    \"Testing ensures the accuracy and reliability of models by validating both the model\\'s predictions and the data sets used.\",\\n    \"A/B testing is a way to introduce new models and see their efficacy in production before committing to them.\",\\n    \"Version control is a significant aspect of ML Ops, allowing teams to track changes and maintain optimal model performance.\",\\n    \"Continuous monitoring of model performance plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.\",\\n    \"Model development involves constructing and refining machine learning models through training and evaluation.\",\\n    \"Evaluation metrics such as accuracy, precision, recall, and fairness measures gauge how well a model meets project objectives.\",\\n    \"Careful evaluation is necessary to identify and address potential issues with bias or overfitting in machine learning models.\"\\n] \\n \\nClaims:\\n[\\n    \"The training of model is the first step in the development of models.\",\\n    \"The prepared data are used to teach the model to make predictions or decisions during this process.\",\\n    \"The model learns patterns and relationships in the data to become effective in its tasks.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© treinamento de modelo?',\n",
       "  'actual_output': 'O treinamento de modelo √© o primeiro passo do desenvolvimento de modelos, onde os dados preparados s√£o utilizados para ensinar o modelo a fazer previs√µes ou decis√µes. Durante esse processo, o modelo aprende padr√µes e rela√ß√µes nos dados para se tornar eficaz em suas tarefas.',\n",
       "  'expected_output': 'Treinamento √© o processo de ajustar os par√¢metros do modelo usando dados rotulados ou n√£o rotulados.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['more expensive to analyze improvements to that model in the f uture. The cost increases when\\ncorrection models are cascaded, with a model for problem A‚Ä≤‚Ä≤learned on top of m‚Ä≤\\na, and so on,\\nfor several slightly different test distributions. Once in place, a correction cascade can create an\\nimprovement deadlock, as improving the accuracy of any indi vidual component actually leads to\\nsystem-level detriments. Mitigation strategies are to aug mentmato learn the corrections directly\\nwithin the same model by adding features to distinguish amon g the cases, or to accept the cost of\\ncreating a separate model for A‚Ä≤.\\nUndeclared Consumers. Oftentimes, a prediction from a machine learning model mais made\\nwidely accessible, either at runtime or by writing to Ô¨Åles or logs that may later be consumed by\\nother systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,',\n",
       "   'Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track',\n",
       "   'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes. Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.',\n",
       "   'Model development\\n\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks. The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\n\\nAn essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments. Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.',\n",
       "   'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios. Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment. Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\n\\nModel deployment'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7095238095238094,\n",
       "    'reason': \"The score is 0.71 because irrelevant nodes (nodes 2 and 5) were correctly ranked lower than relevant nodes (nodes 1, 3, 4, and 6), with reasons such as 'overfitting' and 'prototype smells or configuration debt' not being directly related to the topic of separating training and testing.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'separar treino e teste\\', which is directly related to the input question about separating training and testing.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not mention anything about overfitting, which is a key concept in machine learning that would be relevant to the topic of separating training and testing.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses continuous integration and testing, which is related to the input question about separating training and testing.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not mention anything about prototype smells or configuration debt, which are not directly relevant to the topic of separating training and testing.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions monitoring model drift over time, which is a key concept in machine learning that would be relevant to the topic of separating training and testing.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not mention anything about A/B testing or version control, which are not directly relevant to the topic of separating training and testing.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses data science steps for ML, including defining business use cases and establishing success criteria, which is related to the input question about separating training and testing.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not mention anything about continuous delivery or testing, which are not directly relevant to the topic of separating training and testing.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': \"The score is 0.50 because the original expected output sentence 'A separa√ß√£o evita overfitting e garante avalia√ß√£o imparcial da performance.' cannot be attributed to any node in the retrieval context, making it an unsupportive reason.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'A separa\\\\u00e7\\\\u00e3o evita overfitting e garante avalia\\\\u00e7\\\\u00e3o imparcial da performance.\\' can be attributed to the retrieval context as it is a statement about the importance of separation in machine learning, which is discussed in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the benefits of separation.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Monitoring and Testing.\\' can be attributed to the retrieval context as it is a heading that discusses monitoring and testing in machine learning, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the importance of comprehensiveness in monitoring.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'Comprehensiv e live monitoring of system behavior\\\\nin real time combined with automated response is critical fo r long-term system reliability.\\' can be attributed to the retrieval context as it discusses comprehensiveness in monitoring, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the importance of long-term system reliability.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'The key question is: what to monitor?\\' can be attributed to the retrieval context as it discusses the importance of monitoring, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the importance of asking questions.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'Testable invariants ar e not always obvious given that many\\\\nML systems are intended to adapt over time.\\' can be attributed to the retrieval context as it discusses testability and ML systems, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the challenges of adapting ML systems.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node: \\'We offer the follo wing starting points.\\' can be attributed to the retrieval context as it discusses starting points for monitoring, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about offering starting points.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node: \\'\\\\u2022Prediction Bias.\\' can be attributed to the retrieval context as it discusses prediction bias, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about prediction bias.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"8th node: \\'In a system that is working as intended, it should usually be t he case that\\\\nthe distribution of predicted labels is equal to the distrib ution of observed labels.\\' can be attributed to the retrieval context as it discusses prediction bias and system performance, which are topics covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about prediction bias.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"9th node: \\'However, using multiple languages often incre ases the cost of effective testing\\\\nand can increase the dif\\\\ufb01culty of transferring ownership to other individuals.\\' can be attributed to the retrieval context as it discusses the challenges of using multiple languages in ML systems, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the challenges of using multiple languages.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"10th node: \\'\\\\u2022Prototype Smell.\\' can be attributed to the retrieval context as it discusses prototype smell, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about prototype smell.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"11th node: \\'It is convenient to test new ideas in small scale via prototyp es.\\' can be attributed to the retrieval context as it discusses prototyping, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the convenience of prototyping.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"12th node: \\'How-\\\\never, regularly relying on a prototyping environment may be an indicator that the full-scale\\\\nsystem is brittle, dif\\\\ufb01cult to change, or could bene\\\\ufb01t from i mproved abstractions and inter-\\\\nfaces.\\' can be attributed to the retrieval context as it discusses the limitations of prototyping, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the limitations of prototyping.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"13th node: \\'Maintaining a prototyping environment carries its o wn cost, and there is a signi\\\\ufb01cant\\\\ndanger that time pressures may encourage a prototyping syst em to be used as a production\\\\nsolution.\\' can be attributed to the retrieval context as it discusses the costs and limitations of prototyping, which are topics covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the dangers of using prototyping as production.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"14th node: \\'Another potentially surprising area where debt can accumul ate is in the con\\\\ufb01guration of machine\\' can be attributed to the retrieval context as it discusses configuration debt, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about configuration debt.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"15th node: \\'Continuous Integration.\\\\nMonit oring identifies model drif t over time.\\' can be attributed to the retrieval context as it discusses continuous integration and monitoring, which are topics covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the importance of monitoring model drift.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"16th node: \\'Without model monitoring,\\\\nproduction systems are flying blind.\\' can be attributed to the retrieval context as it discusses the importance of model monitoring, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the dangers of not monitoring models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"17th node: \\'By monitoring for model drift the data\\\\nscience team is able to proactively work rather than reactively.\\' can be attributed to the retrieval context as it discusses proactive work in response to model drift, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the benefits of proactive work.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"18th node: \\'Testing ensur es the accuracy and r eliability o f models.\\' can be attributed to the retrieval context as it discusses testing, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the importance of testing models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"19th node: \\'Validating both\\\\nthe model\\\\u2019s predictions and the data sets used is a fundamental step in\\\\ngreenlighting models for production.\\' can be attributed to the retrieval context as it discusses validation, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the importance of validating models and data sets.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"20th node: \\'Use A/B t esting t o identif y best models.\\' can be attributed to the retrieval context as it discusses A/B testing, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the benefits of using A/B testing.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"21st node: \\'A/B testing is sometimes\\\\noverlooked in Machine Learning but is a great way to introduce new\\\\nmodels.\\' can be attributed to the retrieval context as it discusses A/B testing and introducing new models, which are topics covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the benefits of using A/B testing for introducing new models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"22nd node: \\'Rather than swapping models out straight away you can introduce\\\\nthe new model alongside the old.\\' can be attributed to the retrieval context as it discusses introducing new models, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the benefits of introducing new models alongside old ones.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"23rd node: \\'4. Version Contr ol\\\\nVersion control is a significant aspect of ML Ops.\\' can be attributed to the retrieval context as it discusses version control, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the importance of version control.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"24th node: \\'However, in ML, there are a few notable differences:\\\\nCI is no longer only about testing and validating code and components, but also\\\\ntesting and validating data, data schemas, and models.\\' can be attributed to the retrieval context as it discusses the differences between traditional CI and ML, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the differences between traditional CI and ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"25th node: \\'By monitoring for model drift the data\\\\nscience team is able to proactively work rather than reactively.\\' can be attributed to the retrieval context as it discusses proactive work in response to model drift, which is a topic covered in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes or parts that can be attributed to the retrieval context. It is a standalone statement about the benefits of proactive work.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7368421052631579,\n",
       "    'reason': 'The score is 0.74 because the retrieval context discusses software module or package, continuous delivery, and testing, whereas the input asks about separating training and test, which are distinct concepts.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"in which thresholds are learned via simple evaluation on heldout validation data.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring and Testing.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Unit testing of individual components and end-to-end tests of running systems are valuable, but in the face of a changing world such tests are not suf\\\\ufb01cient to provide evidence that a system is working as intended.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Comprehensiv e live monitoring of system behavior in real time combined with automated response is critical fo r long-term system reliability.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The key question is: what to monitor?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testable invariants ar e not always obvious given that many ML systems are intended to adapt over time.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"We offer the follo wing starting points.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u2022Prediction Bias. In a system that is working as intended, it should usually be t he case that the distribution of predicted labels is equal to the distrib ution of observed labels.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This is by no means a comprehensive test, as it can be met by a null mode l that simply predicts\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"a given language, especially when that language has a convenient library or syntax for the task at hand.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"However, using multiple languages often increases the cost of effective testing and can increase the difficulty of transferring ownership to other individuals.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Prototype Smell. It is convenient to test new ideas in small scale via prototypes. However, regularly relying on a prototyping environment may be an indicator that the full-scale system is brittle, difficult to change, or could benefit from improved abstractions and interfaces.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Maintaining a prototyping environment carries its own cost, and there is a significant danger that time pressures may encourage a prototyping system to be used as a production solution.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Additionally, results found at small scale rarely reflect the reality at full scale.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"6 Configuration Debt Another potentially surprising area where debt can accumulate is in the configuration of machine\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous Integration.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monit oring identifies model drif t over time.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without model monitoring, production systems are flying blind.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By monitoring for model drift the data science team is able to proactively work rather than reactively.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing ensur es the accuracy and r eliability o f models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Validating both the model\\\\u2019s predictions and the data sets used is a fundamental step in greenlighting models for production.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Use A/B t esting t o identif y best models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A/B testing is sometimes overlooked in Machine Learning but is a great way to introduce new models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Rather than swapping models out straight away you can introduce the new model alongside the old. This weighted approach allows you to see the efficacy of the new model in production before committing to it.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Version Contr ol\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"testing, integration testing, and continuous delivery of the software module or the package.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The context discusses software module or package, whereas the input asks about separating training and test.\"\\n            },\\n            {\\n                \"statement\": \"CD is no longer about a single software package or a service, but a system (an ML training pipeline) that should automatically deploy another service (model prediction service).\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The context discusses continuous delivery in the context of ML, whereas the input asks about separating training and test.\"\\n            },\\n            {\\n                \"statement\": \"CT is a new property, unique to ML systems, that\\'s concerned with automatically retraining and serving the models.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The context discusses CT as a new property in ML, whereas the input asks about separating training and test.\"\\n            },\\n            {\\n                \"statement\": \"Data science steps for ML In any ML project, after you define the business use case and establish the success criteria, the process of delivering an ML model to production involves the following steps. These steps can be completed manually or can be completed by an automatic pipeline.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The context discusses data science steps for ML, whereas the input asks about separating training and test.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous integration\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In this setup, the pipeline and its components are built, tested, and packaged when new code is committed or pushed to the source code repository.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Besides building packages, container images, and executables, the CI process can include the following tests:\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Unit testing your feature engineering logic.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Unit testing the different methods implemented in your model. For example, you have a function that accepts a categorical data column and you encode the function as a one-hot feature.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing that your model training converges (that is, the loss of your model goes down by iterations and overfits a few sample records).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing that your model training doesn\\'t produce NaN values due to dividing by zero or manipulating small or large values.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing that each component in the pipeline produces the expected artifacts.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the response directly addresses the input question, providing a clear and relevant answer.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Separar os dados de treino e teste √© uma pr√°tica essencial em machine learning.\",\\n    \"Evitar que o modelo memorize os dados, em vez de aprender padr√µes √∫teis para fazer previs√µes novas √© uma raz√£o importante.\",\\n    \"Se voc√™ s√≥ estudar as quest√µes que vai ter na prova, voc√™ vai aprender muito bem aquelas quest√µes espec√≠ficas, mas n√£o vai saber responder outras quest√µes diferentes.\",\\n    \"Se voc√™ usar todos os dados para treinar o modelo, ele pode simplesmente decorar as caracter√≠sticas desses dados.\",\\n    \"Quando voc√™ separa uma parte dos dados para teste, voc√™ est√° criando uma \\'prova\\' que o modelo nunca viu antes.\",\\n    \"Voc√™ est√° verificando se o modelo realmente aprendeu algo √∫til e se ele √© capaz de generalizar.\",\\n    \"O modelo precisa lidar com novas entradas que nunca foram vistas antes em sistemas de produ√ß√£o.\",\\n    \"Se ele tivesse sido validado apenas com os dados de treino, voc√™ n√£o saberia se ele funcionaria bem no mundo real.\",\\n    \"Separar treino e teste √© como garantir que o seu modelo seja um bom aluno antes de lev√°-lo para a sala de aula (ou para a produ√ß√£o)!\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement is not directly related to the input, but it provides supporting information about the importance of separating training and testing data.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement is not directly related to the input, but it provides supporting information about the importance of validating a model\\'s performance on new data.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"Evidence of system reliability is not provided solely through unit testing and end-to-end tests.\",\\n    \"Comprehensive live monitoring of system behavior in real-time combined with automated response is critical for long-term system reliability.\",\\n    \"The distribution of predicted labels should usually be equal to the distribution of observed labels in a system that is working as intended.\",\\n    \"A null model can meet this prediction bias test by simply predicting a given language.\",\\n    \"Using multiple languages often increases the cost of effective testing and can increase the difficulty of transferring ownership to other individuals.\",\\n    \"Regularly relying on a prototyping environment may be an indicator that the full-scale system is brittle, difficult to change, or could benefit from improved abstractions and interfaces.\",\\n    \"Maintaining a prototyping environment carries its own cost, and there is a significant danger that time pressures may encourage a prototyping system to be used as a production solution.\",\\n    \"Results found at small scale rarely reflect the reality at full scale.\",\\n    \"Monitoring identifies model drift over time.\",\\n    \"Without model monitoring, production systems are flying blind.\",\\n    \"Model monitoring allows data science teams to proactively work rather than reactively.\",\\n    \"Testing ensures the accuracy and reliability of models.\",\\n    \"Validating both the model\\'s predictions and the data sets used is a fundamental step in greenlighting models for production.\",\\n    \"A/B testing is a great way to introduce new models and see their efficacy in production before committing to them.\",\\n    \"Version control is a significant aspect of ML Ops, allowing teams to track changes and collaborate effectively.\",\\n    \"CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.\",\\n    \"CD is no longer about a single software package or service, but a system (an ML training pipeline) that should automatically deploy another service (model prediction service).\",\\n    \"CT is a new property, unique to ML systems, concerned with automatically retraining and serving the models.\"\\n] \\n \\nClaims:\\n[\\n    \"Separar os dados de treino e teste √© uma pr√°tica essencial em machine learning por uma raz√£o muito importante: evitar que o modelo memorize os dados, em vez de aprender padr√µes √∫teis para fazer previs√µes novas.\",\\n    \"Se voc√™ usar todos os dados para treinar o modelo, ele pode simplesmente decorar as caracter√≠sticas desses dados.\",\\n    \"When you separate a part of the data for testing, you are creating a \\'test\\' that the model has never seen before.\",\\n    \"That\\'s crucial because, in production systems, the model needs to handle new inputs that have never been seen before.\",\\n    \"Se ele tivesse sido validado apenas com os dados de treino, voc√™ n√£o saberia se ele funcionaria bem no mundo real.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'Por que separar treino e teste?',\n",
       "  'actual_output': 'Ol√°! Separar os dados de treino e teste √© uma pr√°tica essencial em machine learning por uma raz√£o muito importante: **evitar que o modelo memorize os dados, em vez de aprender padr√µes √∫teis para fazer previs√µes novas.**\\n\\nImagine que voc√™ est√° estudando para um teste. Se voc√™ s√≥ estudar as quest√µes que vai ter na prova, voc√™ vai aprender muito bem aquelas quest√µes espec√≠ficas, mas n√£o vai saber responder outras quest√µes diferentes. Da mesma forma, se voc√™ usar todos os dados para treinar o modelo, ele pode simplesmente decorar as caracter√≠sticas desses dados.\\n\\nQuando voc√™ separa uma parte dos dados para teste, voc√™ est√° criando uma \"prova\" que o modelo nunca viu antes. Assim, voc√™ pode verificar se o modelo realmente aprendeu algo √∫til e se ele √© capaz de generalizar, ou seja, fazer bom desempenho em novos dados que n√£o foram usados durante o treino.\\n\\nIsso √© crucial porque, em sistemas de produ√ß√£o, o modelo precisa lidar com novas entradas que nunca foram vistas antes. Se ele tivesse sido validado apenas com os dados de treino, voc√™ n√£o saberia se ele funcionaria bem no mundo real.\\n\\nPortanto, separar treino e teste √© como garantir que o seu modelo seja um bom aluno antes de lev√°-lo para a sala de aula (ou para a produ√ß√£o)!',\n",
       "  'expected_output': 'A separa√ß√£o evita overfitting e garante avalia√ß√£o imparcial da performance.',\n",
       "  'context': None,\n",
       "  'retrieval_context': [', in which thresholds are learned via simple evaluation on heldout validation data.\\nMonitoring and Testing. Unit testing of individual components and end-to-end tests of running\\nsystems are valuable, but in the face of a changing world such tests are not sufÔ¨Åcient to provide\\nevidence that a system is working as intended. Comprehensiv e live monitoring of system behavior\\nin real time combined with automated response is critical fo r long-term system reliability.\\nThe key question is: what to monitor? Testable invariants ar e not always obvious given that many\\nML systems are intended to adapt over time. We offer the follo wing starting points.\\n‚Ä¢Prediction Bias. In a system that is working as intended, it should usually be t he case that\\nthe distribution of predicted labels is equal to the distrib ution of observed labels. This is\\nby no means a comprehensive test, as it can be met by a null mode l that simply predicts',\n",
       "   'a given language, especially when that language has a conven ient library or syntax for the\\ntask at hand. However, using multiple languages often incre ases the cost of effective testing\\nand can increase the difÔ¨Åculty of transferring ownership to other individuals.\\n‚Ä¢Prototype Smell. It is convenient to test new ideas in small scale via prototyp es. How-\\never, regularly relying on a prototyping environment may be an indicator that the full-scale\\nsystem is brittle, difÔ¨Åcult to change, or could beneÔ¨Åt from i mproved abstractions and inter-\\nfaces. Maintaining a prototyping environment carries its o wn cost, and there is a signiÔ¨Åcant\\ndanger that time pressures may encourage a prototyping syst em to be used as a production\\nsolution. Additionally, results found at small scale rarel y reÔ¨Çect the reality at full scale.\\n6 ConÔ¨Åguration Debt\\nAnother potentially surprising area where debt can accumul ate is in the conÔ¨Åguration of machine',\n",
       "   'Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track',\n",
       "   \"testing, integration testing, and continuous delivery of the software module or the package.\\nHowever, in ML, there are a few notable differences:\\nCI is no longer only about testing and validating code and components, but also\\ntesting and validating data, data schemas, and models.\\nCD is no longer about a single software package or a service, but a system (an ML\\ntraining pipeline) that should automatically deploy another service (model prediction\\nservice).\\nCT is a new property, unique to ML systems, that's concerned with automatically\\nretraining and serving the models.\\nThe following section discusses the typical steps for training and evaluating an ML model\\nto serve as a prediction service.\\nData science steps for ML\\nIn any ML project, after you define the business use case and establish the success criteria,\\nthe process of delivering an ML model to production involves the following steps. These\\nsteps can be completed manually or can be completed by an automatic pipeline.\",\n",
       "   \"Continuous integration\\nIn this setup, the pipeline and its components are built, tested, and packaged when new\\ncode is committed or pushed to the source code repository. Besides building packages,\\ncontainer images, and executables, the CI process can include the following tests:\\nUnit testing your feature engineering logic.\\nUnit testing the different methods implemented in your model. For example, you have\\na function that accepts a categorical data column and you encode the function as a\\none-hot\\xa0(https://en.wikipedia.org/wiki/One-hot) feature.\\nTesting that your model training converges (that is, the loss of your model goes down\\nby iterations and overfits\\xa0(https://en.wikipedia.org/wiki/Overfitting) a few sample records).\\nTesting that your model training doesn't produce NaN\\xa0(https://en.wikipedia.org/wiki/NaN)\\nvalues due to dividing by zero or manipulating small or large values.\\nTesting that each component in the pipeline produces the expected artifacts.\"],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.2,\n",
       "    'reason': \"The score is 0.20 because irrelevant nodes (nodes 1-4) are correctly ranked lower than the relevant node (node 5), with a clear distinction between topics such as software engineering, ML system smells, data management, and ML Ops, which do not relate to inference, allowing the correct context mentioning 'infer√™ncia √© o uso de um modelo treinado para gerar previs√µes em novos dados' to rank higher.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context does not mention anything about inference, which is the topic of the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text talks about software engineering and ML system smells, but it\\'s not related to inference.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text discusses data management and ML Ops, but it\\'s not relevant to the topic of inference.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context is about machine learning operations and does not mention anything about inference.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"This context mentions \\'infer\\\\u00eancia \\\\u00e9 o uso de um modelo treinado para gerar previs\\\\u00f5es em novos dados\\', which matches the expected output.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.48936170212765956,\n",
       "    'reason': 'The score is 0.49 because the original expected output does not match well with the nodes in the retrieval context, indicating a moderate level of contextual recall.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Infer\\\\u00eancia \\\\u00e9 o uso de um modelo treinado para gerar previs\\\\u00f5es em novos dados.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Common Smells. In software engineering, a design smell may indicate an underlying problem in\\\\na component or system .\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Plain-Old-Data Type Smell. The rich information used and produced by ML systems is\\\\nall to often encoded with plain data types like raw \\\\ufb02oats and i ntegers.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Multiple-Language Smell. It is often tempting to write a particular piece of a system in\\\\na given language, especially when that language has a conven ient library or syntax for the\\\\ntask at hand.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Prototype Smell. It is convenient to test new ideas in small scale via prototyp es.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'6 Con\\\\ufb01guration Debt\\\\nAnother potentially surprising area where debt can accumul ate is in the con\\\\ufb01guration of machine\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'privilege of working with real data in development. This privilege comes\\\\nwith a lot of responsibility.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Use encr yption t o protect data in transit and at r est.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Access contr ols to contr ol access t o data and models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Regular audits t o confirm compliance with r egulations such as GDPR and\\\\nHIPAA.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Challenges\\\\nWhile it is crucial to follow best practices in ML Ops, it is also important to\\\\nunderstand and prepare for the challenges\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Data Management\\\\nOne of the most common challenges in ML Ops is data management.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'To understand ML Ops, it\\\\u2019s essential to be familiar with the development\\\\nlifecycle of data science projects.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'A typical data science project consists of\\\\nseveral stages:\\\\n1. Data acquisition: Obtaining raw data from various sources, such as\\\\ndatabases, sensors, or external APIs.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\\\nto prepare it for analysis.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'3. Featur e engineering: Selecting the most relevant data attributes, or\\\\n\\\\u201cfeatures,\\\\u201d and converting them into a suitable format for ML\\\\nalgorithms.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'4. Model training: Applying ML algorithms to the preprocessed data to\\\\ncreate a predictive model.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'5. Model ev aluation: Assessing the performance of the model and\\\\nmaking adjustments to improve its accuracy.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'6. Model deployment: Implementing the ML model into a product,\\\\nservice, or system.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'7. Monit oring and maint enance: Continuously monitoring the\\\\nperformance of the ML model and updating it as needed.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'ful and reasonable for why things should be good, but\\\\nthe most defining characteristic of [my most productive\\\\ncolleague] is that he has the highest pace of experi-\\\\nmentation out of anyone.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'He\\\\u2019s always running exper-\\\\nments, always trying everything. I think this is rel-\\\\natively common\\\\u2014people just try everything and then\\\\nbackfit some nice-sounding explanation for why it works.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'We wondered, why was it even necessary to have an expla-\\\\nnation for why something worked? Why not simply accept that,\\\\nunlike in software, we may not have elegant, principled reasons for\\\\nsuccessful ML experiments?\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence cannot be attributed to any parts of the retrieval context.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6136363636363636,\n",
       "    'reason': \"The score is 0.61 because the retrieval context contains statements about software engineering and design smells, which are unrelated to the input question 'O que √© infer√™ncia?' that asks for a definition of inference. The relevant statements in the retrieval context are mostly about machine learning and data management, whereas the input question is focused on a general concept.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"The lack of standard abst ractions makes it all too easy to blur the lines between components.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'What \\\\u00e9 infer\\\\u00eancia?\\' when it has nothing to do with software engineering or design smells.\"\\n            },\\n            {\\n                \"statement\": \"In software engineering, a design smell may indicate an underlying problem in a component or system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"We identify a few ML system smells, not hard-and-fast rules, but as subjective indicators.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Plain-Old-Data Type Smell. The rich information used and produced by ML systems is all to often encoded with plain data types like raw \\\\ufb02oats and i ntegers.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A model parameter should know if it is a log-odds multiplier o r a decision threshold, and a prediction should know various pieces of information about the model that produced it and how it should be consumed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It is often tempting to write a particular piece of a system in a given language, especially when that language has a conven ient library or syntax for the task at hand.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"However, using multiple languages often incre ases the cost of effective testing\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"a given language, especially when that language has a convenient library or syntax for the task at hand.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"However, using multiple languages often increases the cost of effective testing and can increase the difficulty of transferring ownership to other individuals.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Prototype Smell. It is convenient to test new ideas in small scale via prototypes. However, regularly relying on a prototyping environment may be an indicator that the full-scale system is brittle, difficult to change, or could benefit from improved abstractions and interfaces.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Maintaining a prototyping environment carries its own cost, and there is a significant danger that time pressures may encourage a prototyping system to be used as a production solution.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Additionally, results found at small scale rarely reflect the reality at full scale.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"6 Configuration Debt Another potentially surprising area where debt can accumulate is in the configuration of machine\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"privilege of working with real data in development.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This privilege comes with a lot of responsibility.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Use encr yption t o protect data in transit and at r est.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Encrypting data ensures that the data sets used in the training pipeline are secure, even if leaked.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Access contr ols to contr ol access t o data and models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"An extra layer on top of encryption is access controls to ensure only relevant users can view data and models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Regular audits t o confirm compliance with r egulations such as GDPR and HIPAA.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"When working with customer data it is imperative that it is done in an ethical manner.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Liase with your Cyber Security and Ethics teams to ensure you meet these requirements.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Challenges\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"While it is crucial to follow best practices in ML Ops, it is also important to understand and prepare for the challenges\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data Management\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"One of the most common challenges in ML Ops is data management.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps Engineers aren\\\\u2019t directly responsible for ingestion and processing\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"To understand ML Ops, it\\\\u2019s essential to be familiar with the development lifecycle of data science projects.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A typical data science project consists of several stages:\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data acquisition: Obtaining raw data from various sources, such as databases, sensors, or external APIs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data preprocessing: Cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Featur e engineering: Selecting the most relevant data attributes, or \\\\u201cfeatures,\\\\u201d and converting them into a suitable format for ML algorithms.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model training: Applying ML algorithms to the preprocessed data to create a predictive model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model evaluation: Assessing the performance of the model and making adjustments to improve its accuracy.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model deployment: Implementing the ML model into a product, service, or system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring and maintenance: Continuously monitoring the performance of the ML model and updating it as needed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"ful and reasonable for why things should be good\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"the most defining characteristic of [my most productive colleague] is that he has the highest pace of experimentation out of anyone.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"He\\\\u2019s always running experiments, always trying everything. I think this is relatively common\\\\u2014people just try everything and then backfit some nice-sounding explanation for why it works.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"We wondered, why was it even necessary to have an explanation for why something worked? Why not simply accept that, unlike in software, we may not have elegant, principled reasons for successful ML experiments?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P2 hypothesized that such retrofitted explanations could guide future experiment ideas over a longer horizon.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Alternatively, P7 mentioned that their customers sometimes demanded explanations for certain predictions:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Do I know why? No idea. I have to convince people that, okay, we try our best. We try to correlations. We try to similarities.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Why is it different? I have to make conjectures.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 0.8,\n",
       "    'reason': 'The score is 0.80 because although the answer is mostly relevant, it contains one irrelevant statement about the lack of information on inference concept in the context provided.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"N√£o h√° informa√ß√µes no contexto fornecido sobre o conceito de infer√™ncia.\",\\n    \"Posso ajudar com outros t√≥picos relacionados ao contexto\",\\n    \"MLOps √© um t√≥pico relacionado ao contexto\",\\n    \"Ciclo de vida de projetos de ci√™ncia de dados √© um t√≥pico relacionado ao contexto\",\\n    \"Padr√µes de design em sistemas de aprendizado de m√°quina √© um t√≥pico relacionado ao contexto\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"N\\\\u00e3o h\\\\u00e1 informa\\\\u00e7\\\\u00f5es no contexto fornecido sobre o conceito de infer\\\\u00eancia.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the actual output appears to be discussing the development lifecycle of data science projects and ML Ops, whereas the context does not mention inference, indicating a mismatch between the two.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The development lifecycle of data science projects typically consists of 7 stages: Data acquisition, Data preprocessing, Feature engineering, Model training, Model evaluation, Model deployment, and Monitoring and maintenance.\",\\n    \"A typical data science project involves obtaining raw data from various sources, cleaning, transforming, and structuring the data to prepare it for analysis.\",\\n    \"ML systems often encode rich information with plain data types like raw floats and integers.\",\\n    \"The use of multiple languages in a system can increase the cost of effective testing and make it more difficult to transfer ownership to other individuals.\",\\n    \"Regularly relying on prototyping environments may be an indicator that the full-scale system is brittle, difficult to change, or could benefit from improved abstractions and interfaces.\",\\n    \"It is crucial to follow best practices in ML Ops while also understanding and preparing for challenges such as data management.\",\\n    \"The development lifecycle of data science projects includes stages like Data acquisition, Data preprocessing, Feature engineering, Model training, Model evaluation, Model deployment, and Monitoring and maintenance.\"\\n] \\n \\nClaims:\\n[\\n    \"Inelizmente, n√£o h√° informa√ß√µes no contexto fornecido sobre o conceito de infer√™ncia.\",\\n    \"O AI pode ajudar com outros t√≥picos relacionados ao contexto, como MLOps, ciclo de vida de projetos de ci√™ncia de dados ou padr√µes de design em sistemas de aprendizado de m√°quina.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided context does not mention inference, but it describes the development lifecycle of data science projects and mentions ML Ops, which is a different topic.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© infer√™ncia?',\n",
       "  'actual_output': 'Infelizmente, n√£o h√° informa√ß√µes no contexto fornecido sobre o conceito de infer√™ncia. \\n\\nPosso ajudar com outros t√≥picos relacionados ao contexto, como MLOps, ciclo de vida de projetos de ci√™ncia de dados ou padr√µes de design em sistemas de aprendizado de m√°quina?',\n",
       "  'expected_output': 'Infer√™ncia √© o uso de um modelo treinado para gerar previs√µes em novos dados.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['Ô¨Åcations of this basic idea . The lack of standard abst ractions makes it all too easy to blur the\\nlines between components.\\nCommon Smells. In software engineering, a design smell may indicate an underlying problem in\\na component or system . We identify a few ML system smells, not hard-and-fast rules, but as\\nsubjective indicators.\\n‚Ä¢Plain-Old-Data Type Smell. The rich information used and produced by ML systems is\\nall to often encoded with plain data types like raw Ô¨Çoats and i ntegers. In a robust system,\\na model parameter should know if it is a log-odds multiplier o r a decision threshold, and a\\nprediction should know various pieces of information about the model that produced it and\\nhow it should be consumed.\\n‚Ä¢Multiple-Language Smell. It is often tempting to write a particular piece of a system in\\na given language, especially when that language has a conven ient library or syntax for the\\ntask at hand. However, using multiple languages often incre ases the cost of effective testing',\n",
       "   'a given language, especially when that language has a conven ient library or syntax for the\\ntask at hand. However, using multiple languages often incre ases the cost of effective testing\\nand can increase the difÔ¨Åculty of transferring ownership to other individuals.\\n‚Ä¢Prototype Smell. It is convenient to test new ideas in small scale via prototyp es. How-\\never, regularly relying on a prototyping environment may be an indicator that the full-scale\\nsystem is brittle, difÔ¨Åcult to change, or could beneÔ¨Åt from i mproved abstractions and inter-\\nfaces. Maintaining a prototyping environment carries its o wn cost, and there is a signiÔ¨Åcant\\ndanger that time pressures may encourage a prototyping syst em to be used as a production\\nsolution. Additionally, results found at small scale rarel y reÔ¨Çect the reality at full scale.\\n6 ConÔ¨Åguration Debt\\nAnother potentially surprising area where debt can accumul ate is in the conÔ¨Åguration of machine',\n",
       "   'privilege of working with real data in development. This privilege comes\\nwith a lot of responsibility.\\nUse encr yption t o protect data in transit and at r est. Encrypting data\\nensures that the data sets used in the training pipeline are secure, even if\\nleaked.\\xa0\\nAccess contr ols to contr ol access t o data and models. An extra layer on\\ntop of encryption is access controls to ensure only relevant users can view\\ndata and models.\\xa0\\nRegular audits t o confirm compliance with r egulations such as GDPR and\\nHIPAA. When working with customer data it is imperative that it is done in\\nan ethical manner. Liase with your Cyber Security and Ethics teams to\\nensure you meet these requirements.\\xa0\\nChallenges\\nWhile it is crucial to follow best practices in ML Ops, it is also important to\\nunderstand and prepare for the challenges\\n1. Data Management\\nOne of the most common challenges in ML Ops is data management.\\xa0\\nMLOps Engineers aren‚Äôt directly responsible for ingestion and processing',\n",
       "   'https://mlopsnow.com/blog/what-is-mlops/ 2/11\\nTo understand ML Ops, it‚Äôs essential to be familiar with the development\\nlifecycle of data science projects. A typical data science project consists of\\nseveral stages:\\n1. Data acquisition: Obtaining raw data from various sources, such as\\ndatabases, sensors, or external APIs.\\n2. Data pr eprocessing: Cleaning, transforming, and structuring the data\\nto prepare it for analysis.\\n3. Featur e engineering: Selecting the most relevant data attributes, or\\n‚Äúfeatures,‚Äù and converting them into a suitable format for ML\\nalgorithms.\\n4. Model training: Applying ML algorithms to the preprocessed data to\\ncreate a predictive model.\\n5. Model ev aluation: Assessing the performance of the model and\\nmaking adjustments to improve its accuracy.\\n6. Model deployment: Implementing the ML model into a product,\\nservice, or system.\\n7. Monit oring and maint enance: Continuously monitoring the\\nperformance of the ML model and updating it as needed.',\n",
       "   'ful and reasonable for why things should be good, but\\nthe most defining characteristic of [my most productive\\ncolleague] is that he has the highest pace of experi-\\nmentation out of anyone. He‚Äôs always running exper-\\niments, always trying everything. I think this is rel-\\natively common‚Äîpeople just try everything and then\\nbackfit some nice-sounding explanation for why it works.\\nWe wondered, why was it even necessary to have an expla-\\nnation for why something worked? Why not simply accept that,\\nunlike in software, we may not have elegant, principled reasons for\\nsuccessful ML experiments? P2 hypothesized that such retrofitted\\nexplanations could guide future experiment ideas over a longer hori-\\nzon. Alternatively, P7 mentioned that their customers sometimes\\ndemanded explanations for certain predictions:\\nDo I know why? No idea. I have to convince people that,\\nokay, we try our best. We try to correlations.\\nWe try to similarities. Why is it different? I\\nhave to make conjectures.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6787301587301586,\n",
       "    'reason': \"The score of 0.68 is because, although irrelevant nodes (nodes 2, 4, 6, and 8) are ranked lower than relevant nodes (nodes 1, 3, 5, and 9), there's still room for improvement in ranking the most relevant nodes higher up the list.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'dataset\\' which is directly related to the expected output\\'s definition of a dataset.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The phrase \\'privilege of working with real data in development\\' does not provide any information about what a dataset is.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that datasets are used for training, validation or testing, which aligns with the expected output\\'s definition.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The section on \\'Challenges\\' does not provide any information about what a dataset is.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that datasets are used for model training, which aligns with the expected output\\'s definition.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The section on \\'Model Training\\' does not provide any information about what a dataset is.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that datasets are used for model evaluation and deployment, which aligns with the expected output\\'s definition.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The section on \\'Dataset and feature repository\\' does not provide any information about what a dataset is.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that datasets are used for training and inference, which aligns with the expected output\\'s definition.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The section on \\'ML metadata and artifact tracking\\' does not provide any information about what a dataset is.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5217391304347826,\n",
       "    'reason': 'The score is 0.52 because the contextual recall score indicates that the expected output is partially supported by the nodes in the retrieval context, with some sentences having clear connections to specific nodes and others not being directly attributed to any node.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'privilege of working with real data in development. This privilege comes\\\\nwith a lot of responsibility.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Use encr yption t o protect data in transit and at r est. Encrypting data\\\\nensures that the data sets used in the training pipeline are secure, even if\\\\nleaked.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Access contr ols to contr ol access t o data and models. An extra layer on\\\\ntop of encryption is access controls to ensure only relevant users can view\\\\ndata and models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Regular audits t o confirm compliance with r egulations such as GDPR and\\\\nHIPAA.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Challenges\\\\nWhile it is crucial to follow best practices in ML Ops, it is also important to\\\\nunderstand and prepare for the challenges\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Data Management\\\\nOne of the most common challenges in ML Ops is data management.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'MLOps Engineers aren\\\\u2019t directly responsible for ingestion and processing\\', \\'this phase, data engineers work together with data scientists to prepare\\\\nand preprocess the data, performing featur e engineering to ensure the\\\\ndata has the right format and structure.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Model T raining\\\\nOnce the model has been created, it is trained using a suitable dataset.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Several techniques can be applied during the model training phase,\\\\nincluding hyperparameter optimisation, cross-validation, and\\\\nregularisation.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'following:\\\\n\\\\u2022 Register, organize, track, and version your trained and deployed ML models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Dataset and feature repository\\\\nThe dataset and feature repository capability lets you unify the definition and the storage of the ML data assets.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Having a central repository of fresh, high-quality data assets enables shareability, discoverability, and reusability.\\'\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5813953488372093,\n",
       "    'reason': \"The score is 0.58 because the retrieval context contains statements about machine learning operations, model training, and data management, which are not relevant to the input question 'O que √© um dataset?' that asks for a definition of what a dataset is.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"privilege of working with real data in development.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Use encr yption t o protect data in transit and at r est.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Encrypting data ensures that the data sets used in the training pipeline are secure, even if leaked.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Access contr ols to contr ol access t o data and models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"An extra layer on top of encryption is access controls to ensure only relevant users can view data and models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Regular audits t o confirm compliance with r egulations such as GDPR and HIPAA.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"When working with customer data it is imperative that it is done in an ethical manner.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Liase with your Cyber Security and Ethics teams to ensure you meet these requirements.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Challenges\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"While it is crucial to follow best practices in ML Ops, it is also important to understand and prepare for the challenges\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"One of the most common challenges in ML Ops is data management.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps Engineers aren\\\\u2019t directly responsible for ingestion and processing\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"this phase, data engineers work together with data scientists to prepare and preprocess the data, performing featur e engineering to ensure the data has the right format and structure.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"During model creation, various data pipelines are developed, enabling the smooth flow of information between the different stages of the machine learning process.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Tools such as data engineering platforms can be used to design, test and maintain these pipelines.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Once the model has been created, it is trained using a suitable dataset.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model training is an iterative process that involves feeding data into the model for it to learn and make predictions.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The model is continually adjusted, and its performance is evaluated against a validation dataset to fine-tune its accuracy and effectiveness.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Several techniques can be applied during the model training phase, including hyperparameter optimisation, cross-validation, and regularisation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Utilising the right combination of these methods helps\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Register, organize, track, and version your trained and deployed ML models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Store model metadata and runtime dependencies for deployability.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Maintain model documentation and reporting\\\\u2014for example, using model cards .\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Integrate with the model evaluation and deployment capability and track online and offline evaluation metrics for the models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Govern the model launching process: review, approve, release, and roll back. These decisions are based on a number of offline performance and fairness metrics and on online experimentation results.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Dataset and feature repository\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement \\'Dataset and feature repository\\' does not contain relevant information about Einstein\\'s achievements.\"\\n            },\\n            {\\n                \"statement\": \"Having a central repository of fresh, high-quality data assets enables shareability, discoverability, and reusability.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement \\'Having a central repository of fresh, high-quality data assets enables shareability, discoverability, and reusability.\\' does not contain relevant information about Einstein\\'s achievements.\"\\n            },\\n            {\\n                \"statement\": \"The repository also provides data consistency for training and inference.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement \\'The repository also provides data consistency for training and inference.\\' does not contain relevant information about Einstein\\'s achievements.\"\\n            },\\n            {\\n                \"statement\": \"This helps data scientists and ML researchers\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement \\'This helps data scientists and ML researchers\\' does not contain relevant information about Einstein\\'s achievements.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"repository also provides data consistency for training and inference.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Enable shareability, discoverability, reusability, and versioning of data assets.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Allow real-time ingestion and low-latency serving for event streaming and online prediction workloads.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Allow high-throughput batch ingestion and serving for extract, transform, load (ETL) processes and model training, and for scoring workloads.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Enable feature versioning for point-in-time queries.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Support various data modalities, including tabular data, images, and text.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML data assets can be managed at the entity features level or at the full dataset level. For example, a feature repository\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'For example, a feature repository\\' when it has nothing to do with what is a dataset.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Support various data modalities, including tabular data, images, and text.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML data assets can be managed at the entity features level or at the full dataset level.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For example, a feature repository might contain an entity called customer, which includes features like age group, postal code, and gender.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"On the other hand, a dataset repository might include a customer churn dataset, which includes features from the customer and product entities, as well as purchase- and web-activity event logs.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML metadata and artifact tracking\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Various types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive statistics and data schemas, trained models, and evaluation results.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML metadata is the information about these artifacts, including their location, types, properties, and associations to experiments and runs.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about what a dataset is, making all statements highly relevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"A dataset is a structured set of data used in Machine Learning (ML) and data analysis projects.\",\\n    \"It contains organized information to allow AI models to learn patterns and make predictions.\",\\n    \"In the context of MLOps, a dataset can be managed in two main ways:\",\\n    \"One way is data-level management: a complete set of data, such as a tabular or multimedia file (images, text, etc.).\",\\n    \"For example, a customer churn dataset that includes customer, product, and web activity event data.\",\\n    \"The other way is resource-level management: dividing into smaller parts, such as features or entities.\",\\n    \"For example, a data repository containing an entity called \\'customer\\' with characteristics like age, zip code, and gender.\",\\n    \"Datasets are essential to ensure the quality, consistency, and security of data, as mentioned in context.\",\\n    \"They are stored in centralized repositories to facilitate their use at different stages of the ML pipeline.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7777777777777778,\n",
       "    'reason': \"The score is 0.78 because the actual output does not align with the context due to the lack of mention of specific terms like 'Gerenciamento em n√≠vel de dados' or 'Gerenciamento em n√≠vel de recursos', and also lacks information about specific datasets, such as *customer churn*, which are mentioned in the claim.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The privilege of working with real data in development comes with a lot of responsibility.\",\\n    \"Encryption can be used to protect data in transit and at rest.\",\\n    \"Encrypting data ensures that the data sets used in the training pipeline are secure, even if leaked.\",\\n    \"Access controls can be used to control access to data and models.\",\\n    \"Regular audits are necessary to confirm compliance with regulations such as GDPR and HIPAA.\",\\n    \"When working with customer data, it is imperative that it is done in an ethical manner.\",\\n    \"Liaising with Cyber Security and Ethics teams is necessary to ensure meeting these requirements.\",\\n    \"One of the most common challenges in ML Ops is data management.\",\\n    \"Data engineers work together with data scientists to prepare and preprocess data for model creation.\",\\n    \"Featur e engineering is used to ensure the data has the right format and structure.\",\\n    \"Various data pipelines are developed during model creation, enabling the smooth flow of information between stages.\",\\n    \"Tools such as data engineering platforms can be used to design, test, and maintain these pipelines.\",\\n    \"Model training is an iterative process that involves feeding data into the model for it to learn and make predictions.\",\\n    \"The model is continually adjusted, and its performance is evaluated against a validation dataset to fine-tune its accuracy and effectiveness.\",\\n    \"Hyperparameter optimisation, cross-validation, and regularisation can be applied during the model training phase.\",\\n    \"Registering, organizing, tracking, and versioning ML models is necessary.\",\\n    \"Storing model metadata and runtime dependencies for deployability is necessary.\",\\n    \"Maintaining model documentation and reporting is necessary.\",\\n    \"Integrating with the model evaluation and deployment capability is necessary.\",\\n    \"Tracking online and offline evaluation metrics for models is necessary.\",\\n    \"Governing the model launching process is necessary, including review, approval, release, and roll back decisions.\",\\n    \"The dataset and feature repository capability lets you unify the definition and storage of ML data assets.\",\\n    \"A central repository of fresh, high-quality data assets enables shareability, discoverability, and reusability.\",\\n    \"Having a central repository provides data consistency for training and inference.\",\\n    \"Data scientists and ML researchers can save time on data preparation and feature engineering with a central repository.\",\\n    \"The dataset and feature repository provides key functionalities such as enablement of shareability, discoverability, reusability, and versioning of data assets.\",\\n    \"The repository also allows real-time ingestion and low-latency serving for event streaming and online prediction workloads.\",\\n    \"ML metadata is the information about ML artifacts, including their location, types, properties, and associations to experiments and runs.\"\\n] \\n \\nClaims:\\n[\\n    \"A dataset is a structured set of data used in Machine Learning (ML) and data analysis projects.\",\\n    \"A dataset contains organized information to allow AI models to learn patterns and make predictions.\",\\n    \"A dataset can be managed in two main ways: Gerenciamento em n√≠vel de dados and Gerenciamento em n√≠vel de recursos.\",\\n    \"Gerenciamento em n√≠vel de dados refers to a complete set of data, such as a tabular or multimedia file (images, text, etc.).\",\\n    \"An example of a dataset is *customer churn* that includes customer, product, and web activity event data.\",\\n    \"Gerenciamento em n√≠vel de recursos divides the dataset into smaller parts, such as features or entities.\",\\n    \"A repository of data can contain an entity called *customer* with characteristics like age, zip code, and gender.\",\\n    \"Datasets are essential to ensure data quality, consistency, and security, according to context.\",\\n    \"Datasets are stored in centralized repositories to facilitate their use at different stages of the ML pipeline.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim does not directly contradict the context, but it is unclear whether the provided information about dataset management is accurate.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not mention \\'Gerenciamento em n\\\\u00edvel de dados\\' or \\'Gerenciamento em n\\\\u00edvel de recursos\\', which are specific terms used in the claim.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not provide information about specific datasets, such as *customer churn*, and the claim is not directly contradicted by any facts in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim does not provide enough information to determine whether it agrees or disagrees with the context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© um dataset?',\n",
       "  'actual_output': 'Um **dataset** √© um conjunto estruturado de dados usado em projetos de Machine Learning (ML) e an√°lise de dados. Ele cont√©m informa√ß√µes organizadas de forma a permitir que modelos de IA aprendam padr√µes e fa√ßam previs√µes.\\n\\nNo contexto da MLOps, um dataset pode ser gerenciado de duas formas principais:\\n\\n1. **Gerenciamento em n√≠vel de dados**:  \\n   Trata-se de um conjunto completo de dados, como um arquivo de dados tabulares ou multim√≠dia (imagens, texto, etc.). Exemplo: um dataset de *customer churn* (rotatividade de clientes) que inclui dados de clientes, produtos e eventos de atividade web.\\n\\n2. **Gerenciamento em n√≠vel de recursos**:  \\n   Divide-se em partes menores, como caracter√≠sticas (features) ou entidades. Exemplo: um reposit√≥rio de dados pode conter uma entidade chamada *customer* com caracter√≠sticas como idade, c√≥digo postal e g√™nero.\\n\\nAl√©m disso, os datasets s√£o essenciais para garantir a qualidade, consist√™ncia e seguran√ßa dos dados, conforme mencionado no contexto. Eles s√£o armazenados em reposit√≥rios centralizados para facilitar seu uso em diferentes est√°gios do pipeline de ML.',\n",
       "  'expected_output': 'Dataset √© uma cole√ß√£o estruturada de dados utilizada para treinamento, valida√ß√£o ou teste.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['privilege of working with real data in development. This privilege comes\\nwith a lot of responsibility.\\nUse encr yption t o protect data in transit and at r est. Encrypting data\\nensures that the data sets used in the training pipeline are secure, even if\\nleaked.\\xa0\\nAccess contr ols to contr ol access t o data and models. An extra layer on\\ntop of encryption is access controls to ensure only relevant users can view\\ndata and models.\\xa0\\nRegular audits t o confirm compliance with r egulations such as GDPR and\\nHIPAA. When working with customer data it is imperative that it is done in\\nan ethical manner. Liase with your Cyber Security and Ethics teams to\\nensure you meet these requirements.\\xa0\\nChallenges\\nWhile it is crucial to follow best practices in ML Ops, it is also important to\\nunderstand and prepare for the challenges\\n1. Data Management\\nOne of the most common challenges in ML Ops is data management.\\xa0\\nMLOps Engineers aren‚Äôt directly responsible for ingestion and processing',\n",
       "   'this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps',\n",
       "   'following:\\n‚Ä¢ Register, organize, track, and version your trained and deployed ML models.\\n‚Ä¢ Store model metadata and runtime dependencies for deployability.\\n‚Ä¢ Maintain model documentation and reporting‚Äîfor example, using model cards .\\n‚Ä¢ Integrate with the model evaluation and deployment capability and track online and offline evaluation metrics \\nfor the models.\\n‚Ä¢ Govern the model launching process: review, approve, release, and roll back. These decisions are based on a \\nnumber of offline performance and fairness metrics and on online experimentation results.\\nDataset and feature repository\\nThe dataset and feature repository capability lets you unify the definition and the storage of the ML data assets. \\nHaving a central repository of fresh, high-quality data assets enables shareability, discoverability, and reusability. The \\nrepository also provides data consistency for training and inference. This helps data scientists and ML researchers',\n",
       "   'repository also provides data consistency for training and inference. This helps data scientists and ML researchers \\nsave time on data preparation and feature engineering, which typically take up a significant amount of their time. Key \\nfunctionalities in the data and feature repository include the following:\\n15\\n‚Ä¢ Enable shareability, discoverability, reusability, and versioning of data assets.\\n‚Ä¢ Allow real-time ingestion and low-latency serving for event streaming and online prediction workloads. \\n‚Ä¢ Allow high-throughput batch ingestion and serving for extract, transform, load (ETL) processes and model \\ntraining, and for scoring workloads.\\n‚Ä¢ Enable feature versioning for point-in-time queries.\\n‚Ä¢ Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -',\n",
       "   '‚Ä¢ Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -\\ntory might contain an entity called customer, which includes features like age group, postal code, and gender. On the \\nother hand, a dataset repository might include a customer churn dataset, which includes features from the customer \\nand product entities, as well as purchase- and web-activity event logs.\\nML metadata and artifact tracking\\nVarious types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive \\nstatistics and data schemas, trained models, and evaluation results. ML metadata is the information about these \\nartifacts, including their location, types, properties, and associations to experiments and runs. The ML metadata and'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6396524110809825,\n",
       "    'reason': \"The score is 0.64 because irrelevant nodes like 'institutional knowledge', 'research' and 'engineering' roles, 'classroom material', 'textbooks', and 'data scientists' are ranked lower than relevant nodes that discuss pipelines, reproducibility, scalability, and their importance in ML tasks.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'pipelines\\' multiple times, which is directly related to the expected output\\'s mention of pipelines organizing and automating ML tasks.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The phrase \\'ward to do once\\' does not seem relevant to the topic of using pipelines in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the difficulties of documenting and maintaining pipelines, which is a key point mentioned in the expected output about the importance of reproducibility and scalability.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The mention of \\'institutional knowledge\\' does not seem directly related to the topic of using pipelines in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context highlights the challenges of testing and debugging pipelines, which is a key point mentioned in the expected output about the importance of reproducibility and scalability.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The mention of \\'research\\' and \\'engineering\\' roles does not seem directly related to the topic of using pipelines in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the need for a \\'clean-slate approach\\' to avoid pipeline jungles, which is a key point mentioned in the expected output about the importance of reproducibility and scalability.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The mention of \\'classroom material\\' does not seem directly related to the topic of using pipelines in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context highlights the need for a \\'hybrid research approach\\' to avoid pipeline jungles, which is a key point mentioned in the expected output about the importance of reproducibility and scalability.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The mention of \\'textbooks\\' does not seem directly related to the topic of using pipelines in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the need for a \\'standard CI/CD workflow\\' to deploy and manage pipelines, which is a key point mentioned in the expected output about the importance of reproducibility and scalability.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The mention of \\'data scientists\\' does not seem directly related to the topic of using pipelines in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context highlights the need for a \\'code-first technology\\' to have more flexibility and control over pipelines, which is a key point mentioned in the expected output about the importance of reproducibility and scalability.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the contextual recall score indicates that half of the expected output can be attributed to the nodes in the retrieval context, with some sentences strongly relating to specific nodes (e.g., sentence 2 relates to node 2) and others not containing any relevant information (unsupportive reasons).',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The phrase \\'P6 discussed that\\' refers to the 1st node in the retrieval context, which is about ML setting and learning faster than documentation.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence mentions \\'people don\\\\u2019t want to read so many different versions of documentation\\', which relates to the 2nd node in the retrieval context about institutional knowledge and documentation.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The phrase \\'P17 realized that\\' refers to the 3rd node in the retrieval context, which is about poorly documented pipelines and treating them as black boxes.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence mentions \\'aging these pipelines, detecting errors and recovering from failures are all difficult and costly\\', which relates to the 4th node in the retrieval context about technical debt and innovation.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The phrase \\'Pipeline jungles can only be avoided by thinking holistically about data collection and feature extraction\\' refers to the 5th node in the retrieval context, which is about avoiding pipeline jungles and redesigning from scratch.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence mentions \\'Glue code and pipeline jungles are symptomatic of integration issues that may have a root cause in overly separated \\\\u201cresearch\\\\u201d and \\\\u201cengineering\\\\u201d roles\\', which relates to the 6th node in the retrieval context about MLOps anti-patterns.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The phrase \\'Takeaway. The MLOps anti-patterns described in this section reveal that ML engineering, as a field, is changing faster than educational resources can keep up\\' refers to the 7th node in the retrieval context, which is about MLOps anti-patterns and educational resources.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence mentions \\'We see this as opportunities for new resources, such as classroom material (e.g., textbooks, courses) to prescribe the right engineering practices and rigor for the highly experimental discipline that is production ML\\', which relates to the 8th node in the retrieval context about MLOps anti-patterns.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The phrase \\'MLOps tool builders may be interested in an organization of the dozens of tools, libraries, and services MLEs use to run ML and data processing pipelines\\' refers to the 9th node in the retrieval context, which is about MLOps tool builders and their work.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence mentions \\'Although multiple MLEs reported having to \\\\u201cglue\\\\u201d open-source solutions together and having to build \\\\u201chomegrown\\\\u201d infrastructure as part of their work\\', which relates to the 10th node in the retrieval context about MLOps tool builders.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any nodes from the retrieval context.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5135135135135135,\n",
       "    'reason': \"The score is 0.51 because the retrieval context contains relevant statements about the challenges of using pipelines in Machine Learning (ML), such as poorly documented pipelines forcing practitioners to treat them as black boxes and the need for automated documentation assistance, which aligns with the input 'Por que usar pipelines em ML?'\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"ward to do once\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P6 discussed that in the ML setting, they learn faster than they can document;\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Moreover, people don\\\\u2019t want to read so many different versions of documentation:\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"There are people in the team, myself included, that have been on it for several years now, and so there\\\\u2019s some institutional knowledge embodied on the team that sometimes gets written down.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"But you know, even when it does get written down, maybe you will read them, but then, they kind of disappear to the ether.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Finally, P17 realized that poorly documented pipelines forced them to treat pipelines as black boxes:\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"\\\\u201cSome of our models are pretty old and not well documented, so I don\\\\u2019t have great expectations for what they should be doing.\\\\u201d\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without intuition for how pipelines should perform, practitioner productivity can be stunted.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Takeaway. The MLOps anti-patterns described in this section reveal that ML engineering, as a field, is changing faster than education-\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"aging these pipelines, detecting errors and recovering from failures are all difficult and costly.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing such pipelines often requires expensive end-to-end integration tests.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"All of this adds to technical debt of a system and makes further innovation more costly.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Pipeline jungles can only be avoided by thinking holistically about data collection and feature extraction.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground up is indeed a major investment of engineering effort, but one that can dramatically reduce ongoing costs and speed further innovation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Glue code and pipeline jungles are symptomatic of integration issues that may have a root cause in overly separated \\\\u201cresearch\\\\u201d and \\\\u201cengineering\\\\u201d roles.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"When ML packages are developed in an ivory-tower setting, the result may appear like black boxes to the teams that employ them in practice.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A hybrid research approach where engineers and researchers are embedded together on the same teams\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'A hybrid research approach...\\' when it has nothing to do with using pipelines in ML.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Takeaway. The MLOps anti-patterns described in this section re-veal that ML engineering, as a field, is changing faster than educational resources can keep up.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement does not mention pipelines or ML directly.\"\\n            },\\n            {\\n                \"statement\": \"We see this as opportunities for new resources, such as classroom material (e.g., textbooks, courses) to prescribe the right engineering practices and rigor for the highly experimental discipline that is production ML, and automated documentation assistance for ML pipelines in organizations.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"MLOps tool builders may be interested in an organization of the dozens of tools, libraries, and services MLEs use to run ML and data processing pipelines.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Although multiple MLEs reported having to \\\\u201cglue\\\\u201d open-source solutions together and having to build \\\\u201chomegrown\\\\u201d infrastructure as part of their work (P1, P2, P5, P6, P10, P12), an analysis of the various deployments reveals that tools\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Run Layer\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is a title or header and does not provide relevant information about pipelines.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"ing environments varies depending on standards that are established in a given organization.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Most organizations have at least one testing environment before production; some have more.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The specifics of the pipeline deployment process depend on the technology that is used to implement the pipeline.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"With some no-code solutions, data scientists and ML engineers don\\\\u2019t handle or even see the details.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Alternatively, if you use a code-first technology to have more flexibility and control over the ML pipelines, ML engineers can deploy the pipeline using standard CI/CD processes and tools.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This approach is what the diagram depicts.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The diagram shows a standard CI/CD workflow, which consists of these stages:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"1. In the CI stage, the source code is unit-tested, and the training pipeline is built and integration-tested.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Any artifacts that are created by the build are stored in an artifact repository.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Figure 6. The training operationalization process\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"We characterized ML engineers\\\\u2019 workflows into four high-level tasks, each of which employ a wide variety of tools.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data collection spans sourcing new data, wrangling data from sources into a centralized repository, and cleaning data.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data labeling can be outsourced (e.g., Mechanical Turk) or performed in-house with teams of annotators.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Since descriptions and interview studies of data collection, analysis, wrangling and labeling activities can be found in related papers , we focus our summary of findings on the other three tasks.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about focusing on specific tasks when it has nothing to do with the input \\'Por que usar pipelines em ML?\\'\"\\n            },\\n            {\\n                \"statement\": \"Feature Engineering and Model Experimentation. ML engineers\\\\u2019 workflows into four high-level tasks, each of which employ a wide variety of tools.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the answer directly addresses the question about using pipelines in Machine Learning, making it highly relevant and accurate.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Pipelines no ML are essential because they help to organize and automate the flow of data and processes.\",\\n    \"They ensure that models are reproducible and efficient.\",\\n    \"They avoid confusion from multiple loose tools (known as \\'jungle of pipelines\\').\",\\n    \"They allow teams to maintain well-documented and integrated pipelines.\",\\n    \"Without good documentation and integration, pipelines can become a problem (an anti-pattern).\",\\n    \"It may be possible to detail more about some specific aspect!\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement is not directly addressing the input, but it could be providing supporting information about pipelines in ML.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the actual output only partially aligns with the retrieval context, as it acknowledges the potential issue of poorly documented pipelines being treated as black boxes, which is a subtle contradiction to the original claim that pipelines are essential.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The MLOps anti-patterns described in this section reveal that ML engineering, as a field, is changing faster than educational resources can keep up.\",\\n    \"Pipelines forced practitioners to treat pipelines as black boxes: \\'Some of our models are pretty old and not well documented, so I don‚Äôt have great expectations for what they should be doing.\\'\",\\n    \"ML engineering, as a field, is changing faster than educational resources can keep up.\",\\n    \"The MLOps anti-patterns described in this section reveal that ML engineering, as a field, is changing faster than educational resources can keep up.\",\\n    \"Poorly documented pipelines forced practitioners to treat pipelines as black boxes.\",\\n    \"Some of our models are pretty old and not well documented, so I don‚Äôt have great expectations for what they should be doing.\",\\n    \"ML engineers use hacks to sustain high performance in production ML pipelines.\",\\n    \"The training operationalization process involves unit-testing the source code, building and integration-testing the training pipeline, and storing artifacts in an artifact repository.\",\\n    \"The specifics of the pipeline deployment process depend on the technology used to implement the pipeline.\",\\n    \"Some organizations have at least one testing environment before production; some have more.\",\\n    \"Run Layering environments vary depending on standards established in a given organization.\",\\n    \"There are people in the team, myself included, that have been on it for several years now, and so there‚Äôs some institutional knowledge embodied on the team that sometimes gets written down.\",\\n    \"Pipelines can only be avoided by thinking holistically about data collection and feature extraction.\",\\n    \"The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground up is indeed a major investment of engineering effort, but one that can dramatically reduce ongoing costs and speed further innovation.\"\\n] \\n \\nClaims:\\n[\\n    \"Pipelines no ML s√£o essenciais porque ajudam a organizar e automatizar o fluxo de dados e processos, garantindo que modelos sejam reproduz√≠veis e eficientes.\",\\n    \"Eles evitam a confus√£o de m√∫ltiplas ferramentas soltas (conhecido como \"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim states that pipelines are essential for organizing and automating data flow, which is not directly contradicted by the retrieval context. However, the context does mention that poorly documented pipelines forced practitioners to treat them as black boxes, implying that pipelines can be problematic if not well-documented.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'Por que usar pipelines em ML?',\n",
       "  'actual_output': 'Pipelines no ML s√£o essenciais porque ajudam a organizar e automatizar o fluxo de dados e processos, garantindo que modelos sejam reproduz√≠veis e eficientes. Eles evitam a confus√£o de m√∫ltiplas ferramentas soltas (conhecido como \"jungle of pipelines\") e permitem que equipes mantenham pipelines bem documentadas e integradas. No entanto, sem uma boa documenta√ß√£o e integra√ß√£o, pipelines podem se tornar um problema (um anti-pattern), dificultando a manuten√ß√£o e a inova√ß√£o. üòä\\n\\nSe quiser, posso detalhar mais sobre algum aspecto espec√≠fico!',\n",
       "  'expected_output': 'Pipelines organizam e automatizam as etapas do ciclo de vida de ML, garantindo reprodutibilidade e escalabilidade.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['ward to do once, P6 discussed that in the ML setting, they learn\\nfaster than they can document; moreover, people don‚Äôt want to\\nread so many different versions of documentation:\\nThere are people in the team, myself included, that\\nhave been on it for several years now, and so there‚Äôs\\nsome institutional knowledge embodied on the team\\nthat sometimes gets written down. But you know, even\\nwhen it does get written down, maybe you will read\\nthem, but then, they kind of disappear to the ether.\\nFinally, P17 realized that poorly documented pipelines forced\\nthem to treat pipelines as black boxes: ‚ÄúSome of our models are\\npretty old and not well documented, so I don‚Äôt have great expec-\\ntations for what they should be doing.‚Äù Without intuition for how\\npipelines should perform, practitioner productivity can be stunted.\\nTakeaway. The MLOps anti-patterns described in this section re-\\nveal that ML engineering, as a field, is changing faster than educa-',\n",
       "   'aging these pipelines, detecting errors and recovering fro m failures are all difÔ¨Åcult and costly .\\nTesting such pipelines often requires expensive end-to-en d integration tests. All of this adds to\\ntechnical debt of a system and makes further innovation more costly.\\nPipeline jungles can only be avoided by thinking holistical ly about data collection and feature ex-\\ntraction. The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground\\nup is indeed a major investment of engineering effort, but on e that can dramatically reduce ongoing\\ncosts and speed further innovation.\\nGlue code and pipeline jungles are symptomatic of integrati on issues that may have a root cause in\\noverly separated ‚Äúresearch‚Äù and ‚Äúengineering‚Äù roles. When M L packages are developed in an ivory-\\ntower setting, the result may appear like black boxes to the t eams that employ them in practice. A\\nhybrid research approach where engineers and researchers a re embedded together on the same teams',\n",
       "   'Takeaway. The MLOps anti-patterns described in this section re-\\nveal that ML engineering, as a field, is changing faster than educa-\\ntional resources can keep up. We see this as opportunities for new\\nresources, such as classroom material (e.g., textbooks, courses) to\\nprescribe the right engineering practices and rigor for the highly\\nexperimental discipline that is production ML, and automated doc-\\numentation assistance for ML pipelines in organizations.\\n5.3 Characterizing the ‚ÄúMLOps Stack‚Äù for Tool\\nBuilders\\nMLOps tool builders may be interested in an organization of the\\ndozens of tools, libraries, and services MLEs use to run ML and\\ndata processing pipelines. Although multiple MLEs reported hav-\\ning to ‚Äúglue‚Äù open-source solutions together and having to build\\n‚Äúhomegrown‚Äù infrastructure as part of their work (P1, P2, P5, P6,\\nP10, P12), an analysis of the various deployments reveals that tools\\nShreya Shankar‚àó, Rolando Garcia‚àó, Joseph M. Hellerstein, Aditya G. Parameswaran\\nRun Layer',\n",
       "   'ing environments varies depending on standards that are established in a \\ngiven organization. Most organizations have at least one testing environ -\\nment before production; some have more.\\nThe specifics of the pipeline deployment process depend on the technol -\\nogy that is used to implement the pipeline. With some no-code solutions, \\ndata scientists and ML engineers don‚Äôt handle or even see the details.\\nAlternatively, if you use a code-first technology to have more flexibility and \\ncontrol over the ML pipelines, ML engineers can deploy the pipeline using \\nstandard CI/CD processes and tools. This approach is what the diagram \\ndepicts. The diagram shows a standard CI/CD workflow, which consists of \\nthese stages:\\n1. In the CI stage, the source code is unit-tested, and the training pipe -\\nline is built and integration-tested. Any artifacts that are \\ncreated by the build are stored in an artifact repository.\\nFigure 6. The training operationalization process\\nTraining \\nOperationalization',\n",
       "   'tion 4.4, we discuss organizational efforts to effectively evaluate\\nmodels. Finally, in Section 4.5, we investigate the hacks ML engi-\\nneers use to sustain high performance in productions ML pipelines.\\n4.1 Tasks in the Production ML Lifecycle\\nWe characterized ML engineers‚Äô workflows into four high-level\\ntasks, each of which employ a wide variety of tools. We briefly\\ndescribe each task in turn, and elaborate on them as they arise in\\nour findings below.\\nData Collection and Labeling. Data collection spans sourcing\\nnew data, wrangling data from sources into a centralized reposi-\\ntory, and cleaning data. Data labeling can be outsourced (e.g., Me-\\nchanical Turk) or performed in-house with teams of annotators.\\nSince descriptions and interview studies of data collection, anal-\\nysis, wrangling and labeling activities can be found in related pa-\\npers , we focus our summary of findings on the other\\nthree tasks.\\nFeature Engineering and Model Experimentation. ML engi-'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': \"The score is 0.50 because the relevant nodes (ranked 2 and 4) are correctly ranked higher than irrelevant nodes, but there's still room for improvement as some 'no' verdicts are not properly distinguished from the top-ranked 'yes' verdicts.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not mention m\\\\u00e9tricas de avalia\\\\u00e7\\\\u00e3o at all.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text explicitly states that metrics such as accuracy, F1 and RMSE are measures of the model\\'s quality.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not mention m\\\\u00e9tricas de avalia\\\\u00e7\\\\u00e3o at all.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text explains that metrics such as accuracy, precision, recall and F1 score are used to evaluate model performance.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context does not mention m\\\\u00e9tricas de avalia\\\\u00e7\\\\u00e3o at all.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5185185185185185,\n",
       "    'reason': 'The score is 0.52 because most sentences in the expected output can be attributed to specific nodes in the retrieval context, indicating a decent level of relevance and recall.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 1st node in the retrieval context: \\'ration systems:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 2nd node in the retrieval context: \\'It should be easy to specify a con\\\\ufb01guration as a small change f rom a previous con\\\\ufb01guration.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 3rd node in the retrieval context: \\'It should be hard to make manual errors, omissions, or oversi ghts.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 4th node in the retrieval context: \\'It should be easy to see, visually, the difference in con\\\\ufb01gur ation between two models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 5th node in the retrieval context: \\'It should be easy to automatically assert and verify basic fa cts about the con\\\\ufb01guration:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 6th node in the retrieval context: \\'It should be possible to detect unused or redundant settings.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 7th node in the retrieval context: \\'Con\\\\ufb01gurations should undergo a full code review and be check ed into a repository.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 1st node in the retrieval context: \\'ration systems:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 2nd node in the retrieval context: \\'It should be easy to specify a con\\\\ufb01guration as a small change f rom a previous con\\\\ufb01guration.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 3rd node in the retrieval context: \\'It should be hard to make manual errors, omissions, or oversi ghts.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 4th node in the retrieval context: \\'It should be easy to see, visually, the difference in con\\\\ufb01gur ation between two models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 5th node in the retrieval context: \\'It should be easy to automatically assert and verify basic fa cts about the con\\\\ufb01guration:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 6th node in the retrieval context: \\'It should be possible to detect unused or redundant settings.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context are attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 7th node in the retrieval context: \\'Con\\\\ufb01gurations should undergo a full code review and be check ed into a repository.\\'\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5405405405405406,\n",
       "    'reason': \"The score is 0.54 because the retrieval context statements are not directly related to the input 'O que s√£o m√©tricas de avalia√ß√£o?' which asks about evaluation metrics, but instead discuss broader topics such as ML systems interacting with the external world and evaluating model performance using various metrics.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"It should be easy to specify a con\\\\ufb01guration as a small change f rom a previous con\\\\ufb01guration.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It should be hard to make manual errors, omissions, or oversi ghts.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It should be easy to see, visually, the difference in con\\\\ufb01gur ation between two models.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It should be easy to automatically assert and verify basic fa cts about the con\\\\ufb01guration:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It should be possible to detect unused or redundant settings .\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Con\\\\ufb01gurations should undergo a full code review and be check ed into a repository.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"One of the things that makes ML systems so fascinating is that they often interact directly with the external world.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Experience has shown that the external worl d is rarely stable.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This background rate of change creates ongoing maintenance cost.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Fixed Thresholds in Dynamic Systems. It is often necessary to pick a decision threshold for a\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"cloud platforms or on-premises infrastructure.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It is crucial to consider aspects such as scalability, security, and performance during the deployment phase.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Ensuring that the model can handle multiple concurrent requests, protect sensitive data, and provide low-latency responses is essential.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Once the model is deployed, it is essential to monitor its performance continuously.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monit oring plays a vital role in identifying any degradation in model performance and detecting errors or anomalies in the predictions.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Several metrics can be used to evaluate model performance, such as accuracy, precision, recall, and F1 score.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Additionally, it is crucial to monitor infrastructure-related metrics \\\\u2013 like latency, throughput, and resource consumption \\\\u2013 to guarantee the system\\\\u2019s stability and efficiency.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By actively monitoring the model and its surrounding infrastructure, it is possible to identify any issues early and swiftly address them.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"rather than ML-specific metrics alone like MAP (P5, P7, P15, P16, P11, P17, P18, P19).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The need to evaluate product-critical metrics stemmed from close collaboration with other stakeholders, such as product managers and business operators.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P11 felt that a key reason many ML projects fail is that they don\\\\u2019t measure metrics that will yield the organization value:\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Tying to the business\\\\u2019s KPIs (key performance indicators) is really important.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"But it\\\\u2019s a process\\\\u2014you need to figure out what are, and frankly I think that\\\\u2019s how people should be doing AI.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"It like: hey, let\\\\u2019s do these experiments and get cool numbers and show off these nice precision-recall curves to our bosses and call it a day.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is not directly related to the input \\'O que s\\\\u00e3o m\\\\u00e9tricas de avalia\\\\u00e7\\\\u00e3o?\\' which asks about evaluation metrics.\"\\n            },\\n            {\\n                \"statement\": \"It should be like: hey, let\\\\u2019s actually show the same business metrics that everyone else is held accountable to to our bosses at the end of the day.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Since product-specific metrics are, by definition, different for different ML models, it was important for engineers to treat choos-\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"end of the day.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Since product-specific metrics are, by definition, different for different ML models, it was important for engineers to treat choosing the metrics as an explicit step in their workflow and align with other stakeholders to make sure the right metrics were chosen.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For example, P16 said that for every new ML project they work on, their \\\\u201cfirst task is to figure out, what are customers actually interested in, or what\\\\u2019s the metric that they care about.\\\\u201d\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P17 said that every model change in production is validated by the product team: \\\\u201cif we can get a statistically significant greater percentage people to subscribe to , then .\\\\u201d\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For some organizations, a consequence of tightly coupling evaluation to product metrics was an additional emphasis on important customers during evaluation (P6, P10).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P6 described how, at their company, experimental changes that increased aggregate metrics could sometimes be prevented from going to production:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Evaluation is critical to ensure that the models perform well in real-world scenarios.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 0.8333333333333334,\n",
       "    'reason': 'The score is 0.83 because the actual output contains one irrelevant statement that slightly detracts from its relevance to addressing the concept of evaluation metrics, specifically a suggestion on how to show metrics to stakeholders rather than directly discussing the topic.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"M√©tricas de avalia√ß√£o s√£o formas de mensurar o desempenho de um modelo de Machine Learning (ML).\",\\n    \"Elas ajudam a verificar se o modelo est√° funcionando bem e atingindo os objetivos do projeto.\",\\n    \"Essas m√©tricas s√£o essenciais para garantir que o modelo seja eficaz e traga valor √†s organiza√ß√µes.\",\\n    \"√â importante escolher as m√©tricas certas, pois muitos projetos de ML falham porque as pessoas se concentram apenas em m√©tricas t√©cnicas como precis√£o e recall, em vez de m√©tricas que realmente importam para o neg√≥cio.\",\\n    \"√â crucial alinhar as m√©tricas com os objetivos do neg√≥cio e dos stakeholders.\",\\n    \"P11 sugere que √© importante mostrar aos gestores as mesmas m√©tricas que outros departamentos usam para serem responsabilizados.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The statement is not directly related to the concept of evaluation metrics, but rather suggests a way to show metrics to stakeholders.\"\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8333333333333334,\n",
       "    'reason': 'The score is 0.83 because the actual output only partially aligns with the retrieval context, as it acknowledges the importance of choosing the right metrics but lacks a clear explanation on how to do so.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The conÔ¨Åguration of ML systems should be easy to specify as a small change from a previous conÔ¨Åguration.\",\\n    \"It should be hard to make manual errors, omissions, or oversights in the conÔ¨Åguration of ML systems.\",\\n    \"It should be easy to visually see the difference in conÔ¨Åguration between two models.\",\\n    \"It should be easy to automatically assert and verify basic facts about the conÔ¨Åguration: number of features used, transitive closure of data dependencies, etc.\",\\n    \"It should be possible to detect unused or redundant settings in ML systems.\",\\n    \"ConÔ¨Ågurations should undergo a full code review and be checked into a repository.\",\\n    \"The external world is rarely stable, creating ongoing maintenance cost for ML systems.\",\\n    \"It is often necessary to pick a decision threshold for a cloud platform or on-premises infrastructure.\",\\n    \"Scalability, security, and performance are crucial aspects to consider during the deployment phase of ML systems.\",\\n    \"Monitoring plays a vital role in identifying any degradation in model performance and detecting errors or anomalies in predictions.\",\\n    \"Evaluation metrics such as accuracy, precision, recall, and F1 score can be used to gauge how well the model meets project objectives.\",\\n    \"It is essential to monitor infrastructure-related metrics ‚Äì like latency, throughput, and resource consumption ‚Äì to guarantee the system\\'s stability and efficiency.\",\\n    \"Tying ML-specific metrics to business KPIs (key performance indicators) is important for evaluating ML projects.\",\\n    \"Choosing product-specific metrics as an explicit step in the workflow and aligning with other stakeholders is crucial for ML engineers.\",\\n    \"Evaluation of ML models should be conducted on unseen data to assess their performance in real-world scenarios.\",\\n    \"Careful evaluation can help identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\"\\n] \\n \\nClaims:\\n[\\n    \"M√©tricas de avalia√ß√£o s√£o formas de mensurar o desempenho de um modelo de Machine Learning (ML).\",\\n    \"Elas ajudam a verificar se o modelo est√° funcionando bem e atingindo os objetivos do projeto.\",\\n    \"As m√©tricas s√£o essenciais para garantir que o modelo seja eficaz e traga valor √†s organiza√ß√µes.\",\\n    \"√â importante escolher as m√©tricas certas, pois muitos projetos de ML falham porque as pessoas se concentram apenas em m√©tricas t√©cnicas como precis√£o e recall, em vez de m√©tricas que realmente importam para o neg√≥cio.\",\\n    \"√â crucial alinhar as m√©tricas com os objetivos do neg√≥cio e dos stakeholders.\",\\n    \"P11 sugere que √© importante mostrar aos gestores as mesmas m√©tricas que outros departamentos usam para serem responsabilizados.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim suggests that choosing the right metrics is crucial, but the retrieval context does not directly contradict this. However, it does not provide a clear explanation on how to choose the right metrics.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim suggests that showing metrics to managers is important for being responsible, but there is no direct evidence in the retrieval context to support or contradict this.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que s√£o m√©tricas de avalia√ß√£o?',\n",
       "  'actual_output': 'M√©tricas de avalia√ß√£o s√£o formas de mensurar o desempenho de um modelo de Machine Learning (ML). Elas ajudam a verificar se o modelo est√° funcionando bem e atingindo os objetivos do projeto.\\n\\nNo contexto fornecido, vemos que essas m√©tricas s√£o essenciais para garantir que o modelo seja eficaz e traga valor √†s organiza√ß√µes. √â importante escolher as m√©tricas certas, pois muitos projetos de ML falham porque as pessoas se concentram apenas em m√©tricas t√©cnicas como precis√£o e recall, em vez de m√©tricas que realmente importam para o neg√≥cio.\\n\\nAl√©m disso, o contexto menciona que √© crucial alinhar as m√©tricas com os objetivos do neg√≥cio e dos stakeholders. Por exemplo, P11 sugere que √© importante mostrar aos gestores as mesmas m√©tricas que outros departamentos usam para serem responsabilizados.',\n",
       "  'expected_output': 'S√£o medidas num√©ricas que indicam a qualidade do modelo, como accuracy, F1 e RMSE.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['ration systems:\\n‚Ä¢It should be easy to specify a conÔ¨Åguration as a small change f rom a previous conÔ¨Åguration.\\n‚Ä¢It should be hard to make manual errors, omissions, or oversi ghts.\\n‚Ä¢It should be easy to see, visually, the difference in conÔ¨Ågur ation between two models.\\n‚Ä¢It should be easy to automatically assert and verify basic fa cts about the conÔ¨Åguration:\\nnumber of features used, transitive closure of data depende ncies, etc.\\n‚Ä¢It should be possible to detect unused or redundant settings .\\n‚Ä¢ConÔ¨Ågurations should undergo a full code review and be check ed into a repository.\\n6\\n7 Dealing with Changes in the External World\\nOne of the things that makes ML systems so fascinating is that they often interact directly with the\\nexternal world. Experience has shown that the external worl d is rarely stable. This background rate\\nof change creates ongoing maintenance cost.\\nFixed Thresholds in Dynamic Systems. It is often necessary to pick a decision threshold for a',\n",
       "   'cloud platforms or on-premises infrastructure.\\nIt is crucial to consider aspects such as scalability, security, and\\nperformance during the deployment phase. Ensuring that the model can\\nhandle multiple concurrent requests, protect sensitive data, and provide\\nlow-latency responses is essential.\\nMonit oring\\nOnce the model is deployed, it is essential to monitor its performance\\ncontinuously. Monit oring plays a vital role in identifying any degradation\\nin model performance and detecting errors or anomalies in the\\npredictions.\\nSeveral metrics can be used to evaluate model performance, such as\\naccuracy, precision, recall, and F1 score. Additionally, it is crucial to\\nmonitor infrastructure-related metrics ‚Äì like latency, throughput, and\\nresource consumption ‚Äì to guarantee the system‚Äôs stability and efficiency.\\nBy actively monitoring the model and its surrounding infrastructure, it is\\npossible to identify any issues early and swiftly address them. This process',\n",
       "   'rather than ML-specific metrics alone like MAP (P5, P7, P15, P16,\\nP11, P17, P18, P19). The need to evaluate product-critical metrics\\nstemmed from close collaboration with other stakeholders, such\\nas product managers and business operators. P11 felt that a key\\nreason many ML projects fail is that they don‚Äôt measure metrics\\nthat will yield the organization value:\\nTying to the business‚Äôs KPIs (key\\nperformance indicators) is really important. But it‚Äôs a\\nprocess‚Äîyou need to figure out what are, and\\nfrankly I think that‚Äôs how people should be doing AI. It\\n like: hey, let‚Äôs do these experiments and\\nget cool numbers and show off these nice precision-recall\\ncurves to our bosses and call it a day. It should be like:\\nhey, let‚Äôs actually show the same business metrics that\\neveryone else is held accountable to to our bosses at the\\nend of the day.\\nSince product-specific metrics are, by definition, different for\\ndifferent ML models, it was important for engineers to treat choos-',\n",
       "   'end of the day.\\nSince product-specific metrics are, by definition, different for\\ndifferent ML models, it was important for engineers to treat choos-\\ning the metrics as an explicit step in their workflow and align with\\nother stakeholders to make sure the right metrics were chosen. For\\nexample, P16 said that for every new ML project they work on, their\\n‚Äúfirst task is to figure out, what are customers actually interested\\nin, or what‚Äôs the metric that they care about.‚Äù P17 said that every\\nmodel change in production is validated by the product team: ‚Äúif\\nwe can get a statistically significant greater percentage people\\nto subscribe to , then .‚Äù\\nFor some organizations, a consequence of tightly coupling eval-\\nuation to product metrics was an additional emphasis on important\\ncustomers during evaluation (P6, P10). P6 described how, at their\\ncompany, experimental changes that increased aggregate metrics\\ncould sometimes be prevented from going to production:',\n",
       "   'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios. Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment. Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\n\\nModel deployment'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7555555555555555,\n",
       "    'reason': \"The score is 0.76 because irrelevant nodes (nodes 2 and 4) are correctly ranked lower than relevant nodes (nodes 1, 3, and 5), with the first node being a strong match ('model development' is mentioned).\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"This context mentions \\'model development\\' which is relevant to the topic of what a baseline model is.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not explicitly mention \\'baseline model\\', it only talks about general machine learning concepts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"This context mentions \\'model training\\' which is related to the topic of baseline models.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about what a baseline model is, it only talks about general machine learning concepts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"This context mentions \\'model evaluation\\' which is related to the topic of baseline models.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about what a baseline model is, it only talks about general machine learning concepts.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.9411764705882353,\n",
       "    'reason': 'The score is 0.94 because the contextual recall score indicates a high degree of accuracy, suggesting that most sentences in the expected output are correctly attributed to nodes in the retrieval context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No nodes in the retrieval context can be attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'this phase, data engineers work together with data scientists to prepare\\\\nand preprocess the data, performing featur e engineering to ensure the\\\\ndata has the right format and structure.\\' This sentence can be attributed to the 1st node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'During model creation, various data pipelines are developed, enabling the\\\\nsmooth flow of information between the different stages of the machine\\\\nlearning process.\\' This sentence can be attributed to the 2nd node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'Model T raining\\\\nOnce the model has been created, it is trained using a suitable dataset.\\\\nModel training is an iterative process that involves feeding data into the\\\\nmodel for it to learn and make predictions.\\' This sentence can be attributed to the 3rd node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'Several techniques can be applied during the model training phase,\\\\nincluding hyperparameter optimisation, cross-validation, and\\\\nregularisation. Utilising the right combination of these methods helps\\' This sentence can be attributed to the 4th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'\\\\u2022 Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\\\n\\\\u2022 Information about training, validation, and testing data splits that were used. \\\\n\\\\u2022 Model evaluation metrics and the validation procedure that was used.\\' This sentence can be attributed to the 5th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node: \\'If there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\\\\ntion is submitted to the model registry. The model is then ready to be reviewed, approved, and deployed to the target \\\\n18\\\\nserving environment.\\' This sentence can be attributed to the 6th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node: \\'However, in most cases, ML models need to be retrained on a regular basis \\\\nwhen new data is available or when the code changes. In this case, the \\\\noutput of the ML development process is not the model to be deployed in \\\\nproduction.\\' This sentence can be attributed to the 7th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"8th node: \\'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.\\' This sentence can be attributed to the 8th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"9th node: \\'Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.\\' This sentence can be attributed to the 9th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"10th node: \\'Model development\\\\n\\\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks.\\' This sentence can be attributed to the 10th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"11th node: \\'An essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments.\\' This sentence can be attributed to the 11th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"12th node: \\'Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.\\' This sentence can be attributed to the 12th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"13th node: \\'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios.\\' This sentence can be attributed to the 13th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"14th node: \\'Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment.\\' This sentence can be attributed to the 14th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"15th node: \\'Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\' This sentence can be attributed to the 15th node in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"16th node: \\'Model deployment\\' This sentence can be attributed to the 16th node in the retrieval context.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6551724137931034,\n",
       "    'reason': \"The score is 0.66 because most of the statements in the retrieval context are about model training, evaluation, and development, which are relevant to understanding what a baseline model is. For example, 'Model Training Once the model has been created, it is trained using a suitable dataset.' and 'This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks.' provide context about how a baseline model is created and refined.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"this phase, data engineers work together with data scientists to prepare and preprocess the data, performing featur e engineering to ensure the data has the right format and structure.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"During model creation, various data pipelines are developed, enabling the smooth flow of information between the different stages of the machine learning process.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Tools such as data engineering platforms can be used to design, test and maintain these pipelines.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model Training Once the model has been created, it is trained using a suitable dataset.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model training is an iterative process that involves feeding data into the model for it to learn and make predictions. The model is continually adjusted, and its performance is evaluated against a validation dataset to fine-tune its accuracy and effectiveness.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Several techniques can be applied during the model training phase, including hyperparameter optimisation, cross-validation, and regularisation. Utilising the right combination of these methods helps\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Hyperparameters, including trials of automated hyperparameter tuning and model selection.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Information about training, validation, and testing data splits that were used.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model evaluation metrics and the validation procedure that was used.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"If there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about the possibility of not needing to retrain the model, which is not related to what a baseline model is.\"\\n            },\\n            {\\n                \"statement\": \"The model is then ready to be reviewed, approved, and deployed to the target serving environment.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about deploying the model, which is not directly related to what a baseline model is.\"\\n            },\\n            {\\n                \"statement\": \"In addition, all the relevant metadata and artifacts that were produced during model development are tracked in the metadata tracking repository.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about tracking metadata and artifacts, which is not directly related to what a baseline model is.\"\\n            },\\n            {\\n                \"statement\": \"However, in most cases, ML models need to be retrained on a regular basis when new data is available or when the code changes.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about retraining ML models, which is not directly related to what a baseline model is.\"\\n            },\\n            {\\n                \"statement\": \"In this case, the output of the ML development process is not the model to be deployed in production. Instead, the output is the implementation of the continuous\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about the output of the ML development process and its implementation, which is not directly related to what a baseline model is.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Model development\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model development is a core phase in the data science process, focusing on constructing and refining machine learning models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"An essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This process helps optimize model performance and ensures that the development process is transparent and reproducible.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Evaluation is critical to ensure that the models perform well in real-world scenarios.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model deployment\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement \\'Model deployment\\' does not provide any relevant information about baseline models.\"\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': False,\n",
       "    'score': 0.6666666666666666,\n",
       "    'reason': 'The score is 0.67 because the model failed to provide relevant information about what a baseline model is, instead providing an irrelevant statement about the lack of context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Sobre o que voc√™ est√° estudando hoje?\",\\n    \"Infelizmente, no contexto fornecido, n√£o h√° informa√ß√µes sobre o que √© um modelo baseline.\",\\n    \"Se voc√™ tiver mais detalhes ou outro contexto, posso tentar ajudar melhor!\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"Infelizmente, no contexto fornecido, n\\\\u00e3o h\\\\u00e1 informa\\\\u00e7\\\\u00f5es sobre o que \\\\u00e9 um modelo baseline.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"Se voc\\\\u00ea tiver mais detalhes ou outro contexto, posso tentar ajudar melhor!\"\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.3333333333333333,\n",
       "    'reason': 'The score is 0.33 because the actual output does not align with the information presented in the retrieval context due to the absence of AI output being not explicitly mentioned, and there is no mention of a model baseline that would support this claim.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The phase of preparing and preprocessing data involves featur e engineering to ensure the data has the right format and structure.\",\\n    \"Data engineers work together with data scientists during this phase.\",\\n    \"Various data pipelines are developed during model creation, enabling the smooth flow of information between stages of the machine learning process.\",\\n    \"Tools such as data engineering platforms can be used to design, test, and maintain these pipelines.\",\\n    \"The model training process is iterative, involving feeding data into the model for it to learn and make predictions.\",\\n    \"The model\\'s performance is evaluated against a validation dataset to fine-tune its accuracy and effectiveness.\",\\n    \"Hyperparameter optimisation, cross-validation, and regularisation are techniques that can be applied during model training.\",\\n    \"Model evaluation metrics include accuracy, precision, recall, and fairness measures.\",\\n    \"Evaluation of the model is critical to ensure it performs well in real-world scenarios.\",\\n    \"The final model is submitted to the model registry after being reviewed, approved, and deployed to the target serving environment.\",\\n    \"All relevant metadata and artifacts produced during model development are tracked in the metadata tracking repository.\",\\n    \"ML models need to be retrained on a regular basis when new data is available or when the code changes.\",\\n    \"Continuous monitoring of model performance plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.\",\\n    \"Monitoring the performance and health of ML models ensures they continue to meet intended objectives after deployment.\",\\n    \"The process of maintaining and tracking experiments involves keeping detailed records of different model iterations, hyperparameter configurations used, and outcomes of various experiments.\",\\n    \"Meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches.\",\\n    \"Model evaluation is conducted to assess the performance of the models on unseen data.\",\\n    \"The metrics used in model evaluation provide a quantitative basis for comparing different models and selecting the best one for deployment.\"\\n] \\n \\nClaims:\\n[\\n    \"No AI output is provided about the topic being studied today.\",\\n    \"There is no information about a model baseline in the given context.\",\\n    \"The AI suggests that it may be able to help better if more details or another context are provided.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The retrieval context does not directly contradict this claim, but the absence of AI output is not explicitly mentioned in the context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"There is no mention of a model baseline in the given context, which supports this claim.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim suggests that more details or another context are needed to help better, but it\\'s unclear whether this is based on factual information or speculation. The retrieval context does not provide enough information to determine the accuracy of this claim.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© um modelo baseline?',\n",
       "  'actual_output': 'Ol√°! Sobre o que voc√™ est√° estudando hoje?\\n\\nInfelizmente, no contexto fornecido, n√£o h√° informa√ß√µes sobre o que √© um modelo baseline.\\n\\nSe voc√™ tiver mais detalhes ou outro contexto, posso tentar ajudar melhor! üòä',\n",
       "  'expected_output': '√â um modelo simples usado como refer√™ncia para comparar modelos mais complexos.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps',\n",
       "   '‚Ä¢ Hyperparameters, including trials of automated hyperparameter tuning and model selection.\\n‚Ä¢ Information about training, validation, and testing data splits that were used. \\n‚Ä¢ Model evaluation metrics and the validation procedure that was used.\\nIf there is no need to retrain the model on a regular basis, then the produced model at the end of the experimenta -\\ntion is submitted to the model registry. The model is then ready to be reviewed, approved, and deployed to the target \\n18\\nserving environment. In addition, all the relevant metadata and artifacts \\nthat were produced during model development are tracked in the metadata \\ntracking repository.\\nHowever, in most cases, ML models need to be retrained on a regular basis \\nwhen new data is available or when the code changes. In this case, the \\noutput of the ML development process is not the model to be deployed in \\nproduction. Instead, the output is the implementation of the continuous',\n",
       "   'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes. Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.',\n",
       "   'Model development\\n\\nModel development is a core phase in the data science process, focusing on constructing and refining machine learning models. This phase starts with model training, where the prepared data is used to train machine learning models that use selected algorithms and frameworks. The objective is to teach the model to make accurate predictions or decisions based on the data it has been trained on.\\n\\nAn essential aspect of model development is maintaining and tracking experiments, which involves keeping detailed records of different model iterations, the hyperparameter configurations used and the outcomes of various experiments. Such meticulous documentation is critical for comparing different models and configurations, facilitating the identification of the most effective approaches. This process helps optimize model performance and ensures that the development process is transparent and reproducible.',\n",
       "   'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios. Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment. Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\n\\nModel deployment'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7555555555555555,\n",
       "    'reason': \"The score is 0.76 because irrelevant nodes are ranked lower than relevant ones, as seen from the first 'no' verdict (node 2) being placed after the second 'yes' verdict (node 3), indicating that the system correctly prioritized the context mentioning monitoring and testing in real-time over the node discussing data testing debt.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions monitoring and testing as a way to ensure system reliability, which is relevant to the input question about monitoring latency.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not explicitly mention latency or response time, making it unlikely that this node contributed to the expected output.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses monitoring and testing as a way to ensure system reliability, which is relevant to the input question about monitoring latency.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This node appears to be discussing data testing debt, which is not directly related to monitoring latency.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions the importance of monitoring and testing in real-time, which is relevant to the input question about monitoring latency.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the contextual recall score indicates that half of the expected output sentences can be attributed to specific nodes in the retrieval context, while the other half do not have a clear connection to these nodes.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 1st node in the retrieval context: \\'Monitoring and Testing. Unit testing of individual components and end-to-end tests of running systems are valuable, but in the face of a changing world such tests are not suf\\\\ufb01cient to provide evidence that a system is working as intended.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 2nd node in the retrieval context: \\'Comprehensiv e live monitoring of system behavior in real time combined with automated response is critical fo r long-term system reliability.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 3rd node in the retrieval context: \\'We offer the follo wing starting points.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 4th node in the retrieval context: \\'Prediction Bias. In a system that is working as intended, it should usually be t he case that the distribution of predicted labels is equal to the distrib ution of observed labels.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 5th node in the retrieval context: \\'Action Limits. In systems that are used to take actions in the real world, suc h as bidding on items or marking messages as spam, it can be useful to set an d enforce action limits as a sanity check.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 6th node in the retrieval context: \\'Because external changes occur in real-time, response must also occur in real-time as well.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence does not contain any nodes from the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 7th node in the retrieval context: \\'8 Other Areas of ML-related Debt\\' and subsequent text.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The sentence does not contain any nodes from the retrieval context.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5714285714285714,\n",
       "    'reason': 'The score is 0.57 because the retrieval context contains statements about monitoring system behavior in real-time, prediction bias, and automated response, which are not directly related to monitoring latency of inference.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Monitoring and Testing.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Monitoring and Testing\\' when it has nothing to do with monitoring latency of inference.\"\\n            },\\n            {\\n                \"statement\": \"Unit testing of individual components and end-to-end tests of running systems are valuable, but in the face of a changing world such tests are not suf\\\\ufb01cient to provide evidence that a system is working as intended.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Unit testing of individual components and end-to-end tests of running systems\\' when it has nothing to do with monitoring latency of inference.\"\\n            },\\n            {\\n                \"statement\": \"Comprehensiv e live monitoring of system behavior in real time combined with automated response is critical fo r long-term system reliability.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The key question is: what to monitor?\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'what to monitor?\\' when it has nothing to do with monitoring latency of inference.\"\\n            },\\n            {\\n                \"statement\": \"Testable invariants ar e not always obvious given that many ML systems are intended to adapt over time.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Testable invariants\\' when it has nothing to do with monitoring latency of inference.\"\\n            },\\n            {\\n                \"statement\": \"Prediction Bias. In a system that is working as intended, it should usually be t he case that the distribution of predicted labels is equal to the distrib ution of observed labels.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"the distribution of predicted labels is equal to the distrib ution of observed labels.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This is by no means a comprehensive test, as it can be met by a null mode l that simply predicts average values of label occurrences without regard to the in put features.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement does not directly relate to monitoring latency of inference.\"\\n            },\\n            {\\n                \"statement\": \"However, it is a surprisingly useful diagnostic, and changes in metrics suc h as this are often indicative of an issue that requires attention.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For example, this method c an help to detect cases in which the world behavior suddenly changes, making training distr ibutions drawn from historical data no longer re\\\\ufb02ective of current reality.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Slicing predic tion bias by various dimensions isolate issues quickly, and can also be used for automated al erting.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Action Limits. In systems that are used to take actions in the real world, suc h as bidding on items or marking messages as spam, it can be useful to set an d enforce action limits as a sanity check.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These limits should be broad enough not to trig ger spuriously. If the system\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement does not directly relate to monitoring latency of inference.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"their control planes if at all possible.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Because external changes occur in real-time, response must also occur in real-time as well.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Relying on human intervention in response to alert pages is one strategy, but can be brittle for time-sensitive issues.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Creating systems to that allow automated response without direct human intervention is often well worth the investment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"8 Other Areas of ML-related Debt\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"We now briefly highlight some additional areas where ML-rela ted technical debt may accrue.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data Testing Debt. If data replaces code in ML systems, and code should be tested , then it seems clear that some amount of testing of input data is critical to a well-functioning system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Basic sanity checks are useful, as more sophisticated tests that monitor changes in input distributions.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Reproducibility Debt. As scientists, it is important that we can re-run experiments and get similar\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"on values), P6 talked about monitoring completeness (i.e., fraction of non-null values) for features, P16 mentioned embedding their pipelines with \\\\\"common sense checks,\\\\\" implemented as hard constraints on columns, and P8 described schema checks\\\\u2014making sure each data item adheres to an expected set of columns and their types.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring is both metrics and then a predicate over those metrics that triggers alerts. That second piece doesn\\\\u2019t exist\\\\u2014not because the infrastructure is hard, but because no one knows how to set those predicate values...for a lot of this stuff now, there\\\\u2019s engineering headcount to support a team doing this stuff.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Some participants discussed using black-box data monitoring services but lamented that their alerts did not prevent failures (P7,\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Setting up robust alerting and notification systems is essential to complement the monitoring efforts.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These systems serve as an early warning mechanism, flagging any signs of performance degradation or emerging issues with the deployed models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By receiving timely alerts, data scientists and engineers can quickly investigate and address these concerns, minimizing their impact on the model\\'s performance and the end-users\\' experience.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about monitoring inference latency, making all statements highly relevant to the input.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"N√£o h√° informa√ß√µes dispon√≠veis no contexto sobre o significado de \\'monitorar lat√™ncia de infer√™ncia\\'.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.0,\n",
       "    'reason': 'The score is 0.00 because the actual output claims there is no information available about monitoring latency, but a contradiction reveals that the retrieval context actually discusses monitoring and testing of individual components and end-to-end tests, which implies some level of monitoring latency.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The thresholds are learned via simple evaluation on heldout validation data.\",\\n    \"Monitoring and testing of individual components and end-to-end tests are valuable but not sufficient to provide evidence that a system is working as intended.\",\\n    \"Comprehensive live monitoring of system behavior in real-time combined with automated response is critical for long-term system reliability.\",\\n    \"What to monitor is the key question.\",\\n    \"Prediction bias should usually be equal to the distribution of observed labels in a system that is working as intended.\",\\n    \"Action limits can be useful in systems that take actions in the real world, such as bidding on items or marking messages as spam.\",\\n    \"Setting up robust alerting and notification systems is essential to complement monitoring efforts.\",\\n    \"Receiving timely alerts allows data scientists and engineers to quickly investigate and address concerns, minimizing their impact on the model\\'s performance and the end-users\\' experience.\"\\n] \\n \\nClaims:\\n[\\n    \"N√£o h√° informa√ß√µes dispon√≠veis no contexto sobre o significado de \\'monitorar lat√™ncia de infer√™ncia\\'.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The retrieval context does not mention latency, but it discusses monitoring and testing of individual components and end-to-end tests, which contradicts the claim that there is no information available about monitoring latency.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que significa monitorar lat√™ncia de infer√™ncia?',\n",
       "  'actual_output': 'Infelizmente, n√£o h√° informa√ß√µes dispon√≠veis no contexto sobre o significado de \"monitorar lat√™ncia de infer√™ncia\".',\n",
       "  'expected_output': 'Monitorar lat√™ncia garante que o modelo responda dentro dos limites necess√°rios para uso real.',\n",
       "  'context': None,\n",
       "  'retrieval_context': [', in which thresholds are learned via simple evaluation on heldout validation data.\\nMonitoring and Testing. Unit testing of individual components and end-to-end tests of running\\nsystems are valuable, but in the face of a changing world such tests are not sufÔ¨Åcient to provide\\nevidence that a system is working as intended. Comprehensiv e live monitoring of system behavior\\nin real time combined with automated response is critical fo r long-term system reliability.\\nThe key question is: what to monitor? Testable invariants ar e not always obvious given that many\\nML systems are intended to adapt over time. We offer the follo wing starting points.\\n‚Ä¢Prediction Bias. In a system that is working as intended, it should usually be t he case that\\nthe distribution of predicted labels is equal to the distrib ution of observed labels. This is\\nby no means a comprehensive test, as it can be met by a null mode l that simply predicts',\n",
       "   'the distribution of predicted labels is equal to the distrib ution of observed labels. This is\\nby no means a comprehensive test, as it can be met by a null mode l that simply predicts\\naverage values of label occurrences without regard to the in put features. However, it is a\\nsurprisingly useful diagnostic, and changes in metrics suc h as this are often indicative of\\nan issue that requires attention. For example, this method c an help to detect cases in which\\nthe world behavior suddenly changes, making training distr ibutions drawn from historical\\ndata no longer reÔ¨Çective of current reality. Slicing predic tion bias by various dimensions\\nisolate issues quickly, and can also be used for automated al erting.\\n‚Ä¢Action Limits. In systems that are used to take actions in the real world, suc h as bidding\\non items or marking messages as spam, it can be useful to set an d enforce action limits as a\\nsanity check. These limits should be broad enough not to trig ger spuriously. If the system',\n",
       "   'their control planes if at all possible.\\nBecause external changes occur in real-time, response must also occur in real-time as well. Relying\\non human intervention in response to alert pages is one strat egy, but can be brittle for time-sensitive\\nissues. Creating systems to that allow automated response w ithout direct human intervention is often\\nwell worth the investment.\\n8 Other Areas of ML-related Debt\\nWe now brieÔ¨Çy highlight some additional areas where ML-rela ted technical debt may accrue.\\nData Testing Debt. If data replaces code in ML systems, and code should be tested , then it seems\\nclear that some amount of testing of input data is critical to a well-functioning system. Basic sanity\\nchecks are useful, as more sophisticated tests that monitor changes in input distributions.\\n7\\nReproducibility Debt. As scientists, it is important that we can re-run experiment s and get similar',\n",
       "   'on values), P6 talked about monitoring completeness (i.e., fraction\\nof non-null values) for features, P16 mentioned embedding their\\npipelines with \"common sense checks,\" implemented as hard con-\\nstraints on columns, and P8 described schema checks‚Äîmaking sure\\neach data item adheres to an expected set of columns and their\\ntypes.\\nWhile rudimentary data checks were embedded in most systems,\\nP6 discussed that it was hard to figure out what higher-order data\\nchecks to compute:\\nMonitoring is both metrics and then a predicate over\\nthose metrics that triggers alerts. That second piece\\ndoesn‚Äôt exist‚Äînot because the infrastructure is hard,\\nbut because no one knows how to set those predicate\\nvalues...for a lot of this stuff now, there‚Äôs engineering\\nheadcount to support a team doing this stuff. This is\\npeople‚Äôs jobs now; this constant, periodic evaluation of\\nmodels.\\nSome participants discussed using black-box data monitoring\\nservices but lamented that their alerts did not prevent failures (P7,',\n",
       "   \"Setting up robust alerting and notification systems is essential to complement the monitoring efforts. These systems serve as an early warning mechanism, flagging any signs of performance degradation or emerging issues with the deployed models. By receiving timely alerts, data scientists and engineers can quickly investigate and address these concerns, minimizing their impact on the model's performance and the end-users' experience.\"],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': \"The score is 0.50 because irrelevant nodes (nodes 1 and 4) are ranked lower than relevant nodes (nodes 2 and 3), as they do not provide information about model validation, whereas nodes 2 and 3 explicitly mention 'validation datasets' and 'offline validation phase', making them more relevant to the topic.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context does not mention validation at all.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions \\'validation datasets\\' and \\'offline validation phase\\', which are relevant to the topic of model validation.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text discusses data engineering, preprocessing, and model training, but does not mention validation specifically.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions \\'validation dataset\\' and \\'offline validation phase\\', which are relevant to the topic of model validation.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text discusses model serving, monitoring, and deployment, but does not mention validation specifically.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the contextual recall score indicates a moderate level of matching between the expected output and the nodes in the retrieval context, but there are some sentences in the expected output that do not contain any parts that can be attributed to these nodes.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any parts that can be attributed to the nodes of retrieval contexts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'other systems. Without access controls, some of these consu mers may be undeclared , silently using\\\\nthe output of a given model as an input to another system.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any parts that can be attributed to the nodes of retrieval contexts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'this phase, data engineers work together with data scientists to prepare\\\\nand preprocess the data, performing featur e engineering to ensure the\\\\ndata has the right format and structure.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any parts that can be attributed to the nodes of retrieval contexts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Model T raining\\\\nOnce the model has been created, it is trained using a suitable dataset.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any parts that can be attributed to the nodes of retrieval contexts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Several techniques can be applied during the model training phase,\\\\nincluding hyperparameter optimisation, cross-validation, and\\\\nregularisation.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any parts that can be attributed to the nodes of retrieval contexts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'P1 described this process as\\\\na departure from what they had learned in academia: \\\\u201cYou have this\\\\nclassic issue where most researchers are evaluat against fixed\\\\ndata sets... most industry methods change their datasets.\\\\u201d\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any parts that can be attributed to the nodes of retrieval contexts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'P11 discussed how they systematically bucketed different failure modes in the offline validation phase\\\\u2014e.g., perfor-\\\\nmance drops in subpopulations users might care deeply about\\\\u2014likeP11 did\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any parts that can be attributed to the nodes of retrieval contexts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'While processes to dynamically update the validation datasets ranged from human-in-the-loop to frequent synthetic data con-\\\\nstruction (P6), we found that higher-stakes applications of ML (e.g.,\\\\nautonomous vehicles), created separate teams to manage the dy-\\\\nnamic evaluation process.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any parts that can be attributed to the nodes of retrieval contexts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'P1 said:\\\\nWe had to move away from only aggregate metrics like\\\\nMAP towards the ability to curate scenarios of interest,\\\\nand then validate model performance on them specifi-\\\\ncally. So, as an example, you can\\\\u2019t hit pedestrians, right.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any parts that can be attributed to the nodes of retrieval contexts.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'(https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets#Holdout_dataset) to evaluate\\\\nthe model quality.\\'\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5357142857142857,\n",
       "    'reason': 'The score is 0.54 because most of the retrieval context statements describe deployment methods, hyperparameter optimization, and regularisation techniques, which are not directly related to validation or quality assessment, as stated by the reasons for irrelevancy.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"other systems. Without access controls, some of these consu mers may be undeclared , silently using\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In mo re classical software engineering, these issues are referred to as visibility debt.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Undeclared consumers are expensive at best and dangerous at worst, because they create a hidden tight coupling of model mato other parts of the stack.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Changes to mawill very likely impact these other parts, potentially in ways that are unintended, poorl y understood, and detrimental.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In practice, this tight coupling can radically increase the cost and dif\\\\ufb01 culty of making any changes to maat all, even if they are improvements.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Furthermore, undeclared con sumers may create hidden feedback loops, which are described more in detail in section 4.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Undeclared consumers may be dif\\\\ufb01cult to detect unless the sy stem is speci\\\\ufb01cally designed to guard\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"this phase, data engineers work together with data scientists to prepare and preprocess the data, performing featur e engineering to ensure the data has the right format and structure.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"During model creation, various data pipelines are developed, enabling the smooth flow of information between the different stages of the machine learning process.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model training is an iterative process that involves feeding data into the model for it to learn and make predictions. The model is continually adjusted, and its performance is evaluated against a validation dataset to fine-tune its accuracy and effectiveness.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Several techniques can be applied during the model training phase, including hyperparameter optimisation, cross-validation, and regularisation. Utilising the right combination of these methods helps\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"ported processes to analyze live failure modes and update the validation datasets to prevent similar failures from happening again\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P1 described this process as a departure from what they had learned in academia: \\\\u201cYou have this classic issue where most researchers are evaluated against fixed data sets... most industry methods change their datasets.\\\\u201d\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The challenge with (2) is that many subpopulations are typically unforeseen; many times they are discovered post-deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"different failure modes in the offline validation phase\\\\u2014e.g., perfor-mance drops in subpopulations users might care deeply about\\\\u2014like\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P11 did, P8 offered a reactive strategy of spawning a new dataset for each observed live failure: \\\\u201cEvery gets into the same queue, and 3 of us sit down once a week and go through the queue...then our collect more data.\\\\u201d\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This new dataset was then used in the offline validation phase in future iterations of the production ML lifecycle.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"While processes to dynamically update the validation datasets ranged from human-in-the-loop to frequent synthetic data construction (P6),\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"we found that higher-stakes applications of ML (e.g., autonomous vehicles), created separate teams to manage the dynamic evaluation process.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P1 said: We had to move away from only aggregate metrics like MAP towards the ability to curate scenarios of interest, and then validate model performance on them specifically. So, as an example, you can\\\\u2019t hit pedestrians, right.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"to evaluate the model quality.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The output of this step is a set of metrics to assess the quality of the model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model validation: The model is confirmed to be adequate for deployment\\\\u2014that its predictive performance is better than a certain baseline.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model serving: The validated model is deployed to a target environment to serve predictions.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Microservices with a REST API to serve online predictions.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement only describes the deployment method, not related to validation or quality assessment.\"\\n            },\\n            {\\n                \"statement\": \"An embedded model to an edge or mobile device.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement only describes the deployment method, not related to validation or quality assessment.\"\\n            },\\n            {\\n                \"statement\": \"Part of a batch prediction system.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement only describes the deployment method, not related to validation or quality assessment.\"\\n            },\\n            {\\n                \"statement\": \"Model monitoring: The model predictive performance is monitored to potentially invoke a new iteration in the ML process.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about what validation cross is, making all statements highly relevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"**Valida√ß√£o Cruzada** is a technique used during the training of machine learning models.\",\\n    \"It evaluates the performance of the model and ensures it generalizes well for new data.\",\\n    \"The technique consists in dividing the dataset into several partitions (usually three: training, validation, and test) and performing multiple iterations of training and evaluation.\",\\n    \"This helps to avoid overfitting (excessive adjustment to the training set) and provides a more precise estimate of the predictive capacity of the model.\",\\n    \"This technique is frequently applied in conjunction with other approaches, such as hyperparameter optimization and regularization, during the training process.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': \"The score is 0.50 because the actual output mentions Valida√ß√£o Cruzada, which can be inferred from the retrieval context, but provides more detail than what's mentioned in the context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The model creation phase involves preparing and preprocessing data, performing feature engineering to ensure the data has the right format and structure.\",\\n    \"Data engineers work together with data scientists during the model creation phase.\",\\n    \"Various data pipelines are developed during the model creation phase, enabling the smooth flow of information between different stages of the machine learning process.\",\\n    \"Tools such as data engineering platforms can be used to design, test, and maintain these pipelines.\",\\n    \"The model training phase involves feeding data into the model for it to learn and make predictions, with the model being continually adjusted and its performance evaluated against a validation dataset.\",\\n    \"Several techniques can be applied during the model training phase, including hyperparameter optimization, cross-validation, and regularization.\",\\n    \"The right combination of these methods helps fine-tune the model\\'s accuracy and effectiveness.\",\\n    \"The model validation phase involves evaluating the model quality using metrics such as MAP, with the output being a set of metrics to assess the quality of the model.\",\\n    \"The model is confirmed to be adequate for deployment if its predictive performance is better than a certain baseline during the model validation phase.\",\\n    \"The validated model can be deployed in various ways, including microservices with a REST API, an embedded model on an edge or mobile device, or as part of a batch prediction system.\",\\n    \"Model monitoring involves tracking the model\\'s predictive performance to potentially invoke a new iteration in the ML process.\",\\n    \"The level of automation of these steps defines the maturity of the ML process, which reflects the velocity of training new models given new data or training new models given changes in the problem domain.\"\\n] \\n \\nClaims:\\n[\\n    \"**Valida√ß√£o Cruzada** is a technique used during the training of machine learning models to evaluate the model\\'s performance and ensure it generalizes well for new data.\",\\n    \"The **Valida√ß√£o Cruzada** technique consists of dividing the dataset into several partitions (usually three: training, validation, and test) and performing multiple iterations of training and evaluation.\",\\n    \"This helps to avoid overfitting (excessive adjustment to the training set) and provides a more precise estimate of the model\\'s predictive capacity.\",\\n    \"The **Valida√ß√£o Cruzada** technique is often applied in conjunction with other approaches, such as hyperparameter optimization and regularization, during the training process.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim mentions **Valida\\\\u00e7\\\\u00e3o Cruzada**, which is not explicitly mentioned in the retrieval context, but it can be inferred that cross-validation is a technique used during the model training phase.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim describes the **Valida\\\\u00e7\\\\u00e3o Cruzada** technique in more detail than what\\'s mentioned in the retrieval context, but it\\'s still a valid technique used during model training.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© valida√ß√£o cruzada?',\n",
       "  'actual_output': '**Valida√ß√£o Cruzada** √© uma t√©cnica utilizada durante o treinamento de modelos de machine learning para avaliar o desempenho do modelo e garantir que ele generalize bem para novos dados. \\n\\nEla consiste em dividir o conjunto de dados em v√°rias parti√ß√µes (geralmente tr√™s: treino, valida√ß√£o e teste) e realizar m√∫ltiplas itera√ß√µes de treinamento e avalia√ß√£o. Isso ajuda a evitar overfitting (ajuste excessivo ao conjunto de treino) e fornece uma estimativa mais precisa da capacidade preditiva do modelo.\\n\\nEssa t√©cnica √© frequentemente aplicada em conjunto com outras abordagens, como otimiza√ß√£o de hiperpar√¢metros e regulariza√ß√£o, durante o processo de treinamento.',\n",
       "  'expected_output': '√â uma t√©cnica que divide os dados em m√∫ltiplos subconjuntos para avaliar melhor a generaliza√ß√£o.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['other systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,\\nthese issues are referred to as visibility debt .\\nUndeclared consumers are expensive at best and dangerous at worst, because they create a hidden\\ntight coupling of model mato other parts of the stack. Changes to mawill very likely impact these\\nother parts, potentially in ways that are unintended, poorl y understood, and detrimental. In practice,\\nthis tight coupling can radically increase the cost and difÔ¨Å culty of making any changes to maat all,\\neven if they are improvements. Furthermore, undeclared con sumers may create hidden feedback\\nloops, which are described more in detail in section 4.\\n2\\nUndeclared consumers may be difÔ¨Åcult to detect unless the sy stem is speciÔ¨Åcally designed to guard',\n",
       "   'this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps',\n",
       "   'ported processes to analyze live failure modes and update the vali-\\ndation datasets to prevent similar failures from happening again (P1,\\nP2, P5, P6, P8, P11, P15, P16, P17, P18). P1 described this process as\\na departure from what they had learned in academia: ‚ÄúYou have this\\nclassic issue where most researchers are evaluat against fixed\\ndata sets... most industry methods change their datasets.‚Äù We\\nfound that these dynamic validation sets served two purposes: (1)\\nthe obvious goal of making sure the validation set reflects live data\\nas much as possible, given new learnings about the problem and\\nshifts in the aggregate data distribution, and (2) the more subtle goal\\nof addressing localized shifts that subpopulations may experience\\n(e.g., low accuracy for a specific label).\\nThe challenge with (2) is that many subpopulations are typically\\nunforeseen; many times they are discovered post-deployment. To\\nenumerate them, P11 discussed how they systematically bucketed',\n",
       "   'different failure modes in the offline validation phase‚Äîe.g., perfor-\\nmance drops in subpopulations users might care deeply about‚ÄîlikeP11 did, P8 offered a reactive strategy of spawning a new dataset\\nfor each observed live failure: ‚ÄúEvery gets into\\nthe same queue, and 3 of us sit down once a week and go through\\nthe queue...then our collect more data.‚Äù This\\nnew dataset was then used in the offline validation phase in future\\niterations of the production ML lifecycle.\\nWhile processes to dynamically update the validation datasets\\nranged from human-in-the-loop to frequent synthetic data con-\\nstruction (P6), we found that higher-stakes applications of ML (e.g.,\\nautonomous vehicles), created separate teams to manage the dy-\\nnamic evaluation process. P1 said:\\nWe had to move away from only aggregate metrics like\\nMAP towards the ability to curate scenarios of interest,\\nand then validate model performance on them specifi-\\ncally. So, as an example, you can‚Äôt hit pedestrians, right.',\n",
       "   '(https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets#Holdout_dataset) to evaluate\\nthe model quality. The output of this step is a set of metrics to assess the quality of\\nthe model.\\n6. Model validation: The model is confirmed to be adequate for deployment‚Äîthat its\\npredictive performance is better than a certain baseline.\\n7. Model serving: The validated model is deployed to a target environment to serve\\npredictions. This deployment can be one of the following:\\nMicroservices with a REST API to serve online predictions.\\nAn embedded model to an edge or mobile device.\\nPart of a batch prediction system.\\n8. Model monitoring: The model predictive performance is monitored to potentially\\ninvoke a new iteration in the ML process.\\nThe level of automation of these steps defines the maturity of the ML process, which\\nreflects the velocity of training new models given new data or training new models given'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5666666666666667,\n",
       "    'reason': \"The score is 0.57 because irrelevant nodes (nodes 1 and 3) are correctly ranked lower than the relevant nodes (nodes 2, 4, and 5), with the first 'yes' verdict at node 2, indicating that model drift detection is a topic of interest in natural data drift and unnatural data drift.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context does not mention anything about model drift detection.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions \\'natural data drift\\' and \\'unnatural data drift\\', which are relevant to the topic of model drift detection.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context is about fairy tales, not machine learning or model drift detection.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text discusses operationalizing machine learning and mentions \\'natural data shift\\' which is relevant to the topic of model drift detection.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text talks about online experimentation, model monitoring, and maintaining the effectiveness of models, all of which are related to model drift detection.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text emphasizes the importance of continuous monitoring of model performance for accuracy drift, bias, and other potential issues, which is relevant to the topic of model drift detection.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5454545454545454,\n",
       "    'reason': 'The score is 0.55 because the contextual recall score indicates that some sentences from the expected output are correctly attributed to nodes in the retrieval context, while others do not have a clear match.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'participants cited Covid as an example, but there are other\\\\n(better) everyday instances of unnatural data drift.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'P6 decribed a bug where users had inconsistent definitions of the\\\\nsame word, complicating the deployment of a service to a\\\\nnew user.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'P7 mentioned a bug where data from users in a\\\\ncertain geographic region arrived more sporadically than\\\\nusual.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'P10 discussed a bug where the format of raw data was\\\\noccasionally corrupted: \\\\u201cTables didn\\\\u2019t always have headers\\\\nin the same place, even though they were the same tables.\\\\u201d\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'Natural data drift: Surprisingly, participants didn\\\\u2019t seem\\\\ntoo worried about slower, expected natural data drift over\\\\ntime\\\\u2014they noted that frequent model retrains solved this\\\\nproblem (P6, P7, P8, P12, P15, P16, P17).\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node: \\'asked P17 to give an example of a natural data drift problem\\\\ntheir company faced, and they could not think of a good\\\\nexample. P14 also said they don\\\\u2019t have natural data drift\\\\nproblems:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node: \\'5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\\\ncharacter, looks for things that are not too big or not too small, things that are \\\\u201cjust\\\\nright.\\\\u201d\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"8th node: \\'Operationalizing Machine Learning: An Interview Study\\'\\\\n\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"9th node: \\'The model gets retrained every day, so we don\\\\u2019t have the\\\\nscenario of like: Oh, our models got stale and we need to re-\\\\ntrain it because it\\\\u2019s starting to make mistakes because data\\\\nhas drifted...fortunately we\\\\u2019ve never had to deal with [such\\\\na] scenario.\\'\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"10th node: \\'Sometimes there are bad jobs, but\\\\nwe can always effectively roll back to a different .\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"11th node: \\'However, a few engineers mentioned that natural data shift\\\\ncould cause some hand-curated features and data quality\\\\nchecks to corrupt (P3, P6, P8).\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No node in the retrieval context is attributed to this sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"12th node: \\'P6 discussed a histogram used\\'\\\\n\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6428571428571429,\n",
       "    'reason': 'The score is 0.64 because the retrieval context contains irrelevant information about Goldilocks and the Three Bears, The model gets retrained, bad jobs, and P6 discussed a histogram, which have no connection to model drift detection. However, some relevant statements in the context mention natural data drift, model retrains, and monitoring model performance for accuracy drift, bias, and other potential issues, indicating that the context is not entirely irrelevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"participants cited Covid as an example\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"there are other (better) everyday instances of unnatural data drift\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P6 described a bug where users had inconsistent definitions of the same word, complicating the deployment of a service to a new user.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P7 mentioned a bug where data from users in a certain geographic region arrived more sporadically than usual.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P10 discussed a bug where the format of raw data was occasionally corrupted: \\\\u201cTables didn\\\\u2019t always have headers in the same place, even though they were the same tables.\\\\u201d\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Natural data drift: Surprisingly, participants didn\\\\u2019t seem too worried about slower, expected natural data drift over time\\\\u2014they noted that frequent model retrains solved this problem (P6, P7, P8, P12, P15, P16, P17).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"As an anecdote, we asked P17 to give an example of a natural data drift problem their company faced, and they could not think of a good example.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P14 also said they don\\\\u2019t have natural data drift problems:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"asked P17 to give an example of a natural data drift problem\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"5Goldilocks and the Three Bears is a popular Western fairy tale.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'5Goldilocks and the Three Bears...\\' when it has nothing to do with model drift detection.\"\\n            },\\n            {\\n                \"statement\": \"Operationalizing Machine Learning: An Interview Study\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The model gets retrained every day, so we don\\\\u2019t have the scenario of like: Oh, our models got stale and we need to re- train it because it\\\\u2019s starting to make mistakes because data has drifted...\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'The model gets retrained...\\' when it has nothing to do with model drift detection.\"\\n            },\\n            {\\n                \"statement\": \"Sometimes there are bad jobs, but we can always effectively roll back to a different .\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Sometimes there are bad jobs...\\' when it has nothing to do with model drift detection.\"\\n            },\\n            {\\n                \"statement\": \"However, a few engineers mentioned that natural data shift could cause some hand-curated features and data quality checks to corrupt (P3, P6, P8).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"P6 discussed a histogram used\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'P6 discussed a histogram...\\' when it has nothing to do with model drift detection.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"dation system has on click-throughs and on conversation rates.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The results of online experimentation should be integrated with the model registry capability to facilitate the decision about releasing the model to production.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Online experimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models and to promote well-performing ones.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Key functionalities in online experimentation include the following: \\\\u2022 Support canary and shadow deployments. \\\\u2022 Support traffic splitting and A/B tests. \\\\u2022 Support multi-armed bandit (MAB) tests.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model monitoring The model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production to ensure predictive quality and business continuity. This capability informs you if your models are stale and need to be investigated and updated. Key functionalities in model monitoring include the following:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"A pivotal aspect of MLOps is the maintenance and management of data, models and code.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By maintaining distinct versions of these components, teams can effectively keep aware of changes over time, which is essential for troubleshooting issues, ensuring reproducibility of results and facilitating easier rollbacks when necessary.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monitoring the performance and health of ML models is critical to ensure that they continue to meet the intended objectives after deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This process involves regularly assessing for model drift, bias and other potential issues that could compromise their effectiveness.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about model drift detection, providing a relevant and accurate answer.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Model drift detection is the process of identifying when a machine learning model starts to work differently than expected after being deployed in production.\",\\n    \"This can happen due to changes in the operational environment or data quality that were not predicted during the model\\'s development.\",\\n    \"There are two main forms of drift:\",\\n    \"Drift natural: Slow and expected changes in data over time, which are resolved by frequent retraining of models.\",\\n    \"Drift accidental: Unexpected problems, such as inconsistent data formats or specific data corruptions in certain regions.\",\\n    \"Detection of drift is a crucial part of maintaining ML models, ensuring they continue to be efficient and relevant even after deployment.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"Covid was cited as an example of unnatural data drift.\",\\n    \"There are better everyday instances of unnatural data drift than Covid.\",\\n    \"Inconsistent definitions of the same word can complicate the deployment of a service to a new user.\",\\n    \"Data from users in a certain geographic region may arrive more sporadically than usual.\",\\n    \"The format of raw data was occasionally corrupted, with tables not always having headers in the same place.\",\\n    \"Frequent model retrains solve the problem of slower, expected natural data drift over time.\",\\n    \"Some companies do not have natural data drift problems.\",\\n    \"Goldilocks and the Three Bears is a popular Western fairy tale.\",\\n    \"Machine learning models can get stale and need to be retrained due to data drift.\",\\n    \"Natural data shift can cause hand-curated features and data quality checks to corrupt.\",\\n    \"The model registry capability facilitates the decision about releasing the model to production.\",\\n    \"Online experimentation enhances the reliability of ML releases by helping decide which models to discard or promote.\",\\n    \"Canary and shadow deployments, traffic splitting, A/B tests, and MAB tests are key functionalities in online experimentation.\",\\n    \"Model monitoring tracks the efficiency and effectiveness of deployed models in production to ensure predictive quality and business continuity.\",\\n    \"Continuous monitoring of model performance is critical for maintaining optimal model performance and preventing unexpected outcomes.\",\\n    \"MLOps involves the maintenance and management of data, models, and code.\",\\n    \"Maintaining distinct versions of these components aids in troubleshooting issues, ensuring reproducibility of results, and facilitating easier rollbacks when necessary.\",\\n    \"Monitoring ML models\\' performance and health is critical to ensure they continue to meet intended objectives after deployment.\"\\n] \\n \\nClaims:\\n[\\n    \"Model drift detection is the process of identifying when a machine learning model starts to work differently than expected after being deployed in production.\",\\n    \"This can happen due to changes in the operational environment or data quality that were not predicted during the model\\'s development.\",\\n    \"There are two main forms of drift:\",\\n    \"Drift natural: Slow and expected changes in data over time, which are resolved by frequent retraining of models.\",\\n    \"Drift accidental: Unexpected problems, such as inconsistent data formats or specific data corruptions in certain regions.\",\\n    \"Detection of drift is a crucial part of maintaining ML models, ensuring they continue to be efficient and relevant even after deployment.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim does not directly contradict the context, but it is unclear whether the context supports or contradicts the claim.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© model drift detection?',\n",
       "  'actual_output': 'Model drift detection √© o processo de identificar quando um modelo de machine learning come√ßa a funcionar de maneira diferente do esperado ap√≥s ser implantado em produ√ß√£o. Isso pode acontecer devido a mudan√ßas no ambiente operacional ou na qualidade dos dados, que n√£o eram previstas durante o desenvolvimento do modelo.\\n\\nNo contexto fornecido, h√° duas formas principais de drift:\\n1. **Drift natural**: Mudan√ßas lentas e esperadas nos dados ao longo do tempo, que s√£o resolvidas por retrainamentos frequentes dos modelos.\\n2. **Drift acidental**: Problemas inesperados, como formatos de dados inconsistentes ou corrup√ß√µes em dados espec√≠ficos de certas regi√µes.\\n\\nA detec√ß√£o de drift √© uma parte crucial da manuten√ß√£o de modelos de ML, garantindo que eles continuem eficientes e relevantes mesmo ap√≥s a implanta√ß√£o.',\n",
       "  'expected_output': '√â o processo automatizado de identificar mudan√ßas na distribui√ß√£o ou rela√ß√£o dos dados que afetam a performance do modelo.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['participants cited Covid as an example, but there are other\\n(better) everyday instances of unnatural data drift. P6 de-\\nscribed a bug where users had inconsistent definitions of the\\nsame word, complicating the deployment of a service to a\\nnew user. P7 mentioned a bug where data from users in a\\ncertain geographic region arrived more sporadically than\\nusual. P10 discussed a bug where the format of raw data was\\noccasionally corrupted: ‚ÄúTables didn‚Äôt always have headers\\nin the same place, even though they were the same tables.‚Äù\\n‚Ä¢Natural data drift: Surprisingly, participants didn‚Äôt seem\\ntoo worried about slower, expected natural data drift over\\ntime‚Äîthey noted that frequent model retrains solved this\\nproblem (P6, P7, P8, P12, P15, P16, P17). As an anecdote, we\\nasked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:',\n",
       "   'asked P17 to give an example of a natural data drift problem\\ntheir company faced, and they could not think of a good\\nexample. P14 also said they don‚Äôt have natural data drift\\nproblems:\\n5Goldilocks and the Three Bears is a popular Western fairy tale. Goldilocks, the main\\ncharacter, looks for things that are not too big or not too small, things that are ‚Äújust\\nright.‚Äù\\nOperationalizing Machine Learning: An Interview Study\\nThe model gets retrained every day, so we don‚Äôt have the\\nscenario of like: Oh, our models got stale and we need to re-\\ntrain it because it‚Äôs starting to make mistakes because data\\nhas drifted...fortunately we‚Äôve never had to deal with [such\\na] scenario. Sometimes there are bad jobs, but\\nwe can always effectively roll back to a different .\\nHowever, a few engineers mentioned that natural data shift\\ncould cause some hand-curated features and data quality\\nchecks to corrupt (P3, P6, P8). P6 discussed a histogram used',\n",
       "   'dation system has on click-throughs and on conversation rates. The results of online experimentation should be \\nintegrated with the model registry capability to facilitate the decision about releasing the model to production. Online \\nexperimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models \\nand to promote well-performing ones. Key functionalities in online experimentation include the following:\\n‚Ä¢ Support canary and shadow deployments.\\n‚Ä¢ Support traffic splitting and A/B tests.\\n‚Ä¢ Support multi-armed bandit (MAB) tests.\\nModel monitoring\\nThe model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production \\nto ensure predictive quality and business continuity. This capability informs you if your models are stale and need to \\nbe investigated and updated. Key functionalities in model monitoring include the following:',\n",
       "   'Continuous monitoring of model performance for accuracy drift, bias and other potential issues plays a critical role in maintaining the effectiveness of models and preventing unexpected outcomes. Monitoring the performance and health of ML models ensures that they continue to meet the intended objectives after deployment. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.',\n",
       "   'A pivotal aspect of MLOps is the maintenance and management of data, models and code. By maintaining distinct versions of these components, teams can effectively keep aware of changes over time, which is essential for troubleshooting issues, ensuring reproducibility of results and facilitating easier rollbacks when necessary. This approach aids in maintaining the integrity of the development process and enables auditability in ML projects.\\n\\nMonitoring the performance and health of ML models is critical to ensure that they continue to meet the intended objectives after deployment. This process involves regularly assessing for model drift, bias and other potential issues that could compromise their effectiveness. By proactively identifying and addressing these concerns, organizations can maintain optimal model performance, mitigate risks and adapt to changing conditions or feedback.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6396524110809825,\n",
       "    'reason': 'The score is 0.64 because irrelevant nodes (nodes ranked 2-11) are correctly ranked lower than relevant nodes (nodes ranked 1 and 3-12), as they do not provide information about the importance of a lineage tracker in MLOps, whereas the top-ranked nodes and most nodes after that do.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'lineage tracker\\' which is directly related to the topic of MLOps and its importance.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the importance of a lineage tracker in MLOps, it only describes what it does.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that ML metadata and artifact tracking is foundational to all other MLOps capabilities, which supports the idea that lineage tracking is important.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the importance of a bridge between machine learning development and production environment.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that ML metadata and artifact tracking is foundational to all other MLOps capabilities, which supports the idea that lineage tracking is important.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the importance of automated training, model versioning, continuous integration and deployment, or monitoring in MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that ML metadata and artifact tracking is foundational to all other MLOps capabilities, which supports the idea that lineage tracking is important.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the importance of supporting various data modalities in MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that ML metadata and artifact tracking is foundational to all other MLOps capabilities, which supports the idea that lineage tracking is important.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the importance of proper data management in an ML Ops platform.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that ML metadata and artifact tracking is foundational to all other MLOps capabilities, which supports the idea that lineage tracking is important.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide any information about the importance of compliance and monitoring in an ML Ops platform.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains that ML metadata and artifact tracking is foundational to all other MLOps capabilities, which supports the idea that lineage tracking is important.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the contextual recall score indicates a moderate level of accuracy in attributing sentences from the expected output to corresponding nodes in the retrieval context, with some sentences having clear connections and others not being directly linked.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 1st node in the retrieval context, which mentions \\'lineage tracking\\' and its importance in MLOps.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 2nd node in the retrieval context, which describes ML metadata and artifact tracking as foundational to all other MLOps capabilities.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 3rd node in the retrieval context, which describes key functionalities in ML metadata and artifact tracking.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 4th node in the retrieval context, which describes MLOps processes and their relationship to other upstream and downstream tasks.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 5th node in the retrieval context, which describes the ML Ops platform and its components.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 6th node in the retrieval context, which describes various types of ML artifacts and their metadata.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 7th node in the retrieval context, which describes ML metadata and artifact tracking as foundational to all other MLOps capabilities.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The sentence can be attributed to the 8th node in the retrieval context, which describes MLOps processes and their relationship to other upstream and downstream tasks.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This sentence does not contain any specific nodes or parts of the retrieval context that can be attributed to it.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7073170731707317,\n",
       "    'reason': \"The score is 0.71 because the retrieval context contains statements that directly relate to the importance of a lineage tracker in MLOps, such as 'Provide traceability and lineage tracking of ML artifacts.' and 'ML metadata and artifact tracking capability is foundational to all other MLOps capabilities.', which are highly relevant to the input question.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"The ML metadata and artifact tracking capability is foundational to all other MLOps capabilities.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Provide traceability and lineage tracking of ML artifacts.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Share and track experimentation and pipeline parameter configurations.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Store, access, investigate, visualize, download, and archive ML artifacts.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Integrate with all other MLOps capabilities.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This section describes each of the core MLOps processes in detail. It describes key tasks and flow of control between tasks, the key artifacts created by the tasks, and the relationship of tasks to other upstream and downstream\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'This section describes each of the core MLOps processes in detail...\\' when it has nothing to do with the importance of a lineage tracker in MLOps.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"bridge the gap between machine learning development and the implementation of ML systems in a production environment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The platform helps streamline the process of building, deploying, and monitoring models, by providing a standardised and automated workflow.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The ML Ops platform typically includes multiple components such as:11/11/25, 9:50 PM MLOps Now - The MLOps Platform: Revolutionising Machine Learning Efficiency https://mlopsnow.com/blog/mlops-platforms-revolutionising-machine-learning/ 2/10\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Automat ed Training : Automating the training of machine learning models on a scheduled basis to keep them updated with fresh data.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model V ersioning : Keeping track of different versions of models and simplifying the management of those models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Continuous Int egration and Deployment : Ensuring continuous integration (CI) and automatic deployment of ML models in the production environment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Monit oring : Tracking model performance, identifying drifts, and providing alerts for potential issues.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Support various data modalities, including tabular data, images, and text.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML data assets can be managed at the entity features level or at the full dataset level.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"For example, a feature repository might contain an entity called customer, which includes features like age group, postal code, and gender.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"On the other hand, a dataset repository might include a customer churn dataset, which includes features from the customer and product entities, as well as purchase- and web-activity event logs.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML metadata and artifact tracking\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Various types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive statistics and data schemas, trained models, and evaluation results.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML metadata is the information about these artifacts, including their location, types, properties, and associations to experiments and runs.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Proper data management in an ML Ops platform ensures that datasets are: Cleaned and preprocessed efficiently.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Easily accessible and shareable among users or teams.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Version-controlled to keep track of changes and updates.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Compliance and Monit oring\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Compliance and Monit oring\\' when it has nothing to do with the importance of a lineage tracker in MLOps.\"\\n            },\\n            {\\n                \"statement\": \"Monitoring tools provide essential insights to detect and mitigate potential security threats.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Monitoring tools provide essential insights to detect and mitigate potential security threats.\\' when it has nothing to do with the importance of a lineage tracker in MLOps.\"\\n            },\\n            {\\n                \"statement\": \"These tools help in: Identifying vulnerabilities and generating alerts in real-time.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Identifying vulnerabilities and generating alerts in real-time.\\' when it has nothing to do with the importance of a lineage tracker in MLOps.\"\\n            },\\n            {\\n                \"statement\": \"Ensuring data protection and regulatory compliance.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Ensuring data protection and regulatory compliance.\\' when it has nothing to do with the importance of a lineage tracker in MLOps.\"\\n            },\\n            {\\n                \"statement\": \"Tracking user activities, thus allowing auditing and accountability.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Tracking user activities, thus allowing auditing and accountability.\\' when it has nothing to do with the importance of a lineage tracker in MLOps.\"\\n            },\\n            {\\n                \"statement\": \"MLOps platforms should implement policies and best practices to maintain compliance with data protection laws and industrial regulations.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'MLOps platforms should implement policies and best practices to maintain compliance with data protection laws and industrial regulations.\\' when it has nothing to do with the importance of a lineage tracker in MLOps.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"processing\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"model training\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"model evaluation\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"model serving\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"online experimentation\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"model monitoring\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML pipeline\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"model registry\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"an ML metadata and artifact repository\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"an ML dataset and feature repository\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The experimentation capability lets your data scientists and ML researchers collaboratively perform exploratory data analysis, create prototype model architectures, and implement training routines.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Provide notebook environments that are integrated with version control tools like Git.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about the importance of a lineage tracker in MLOps, making all statements highly relevant.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Um lineage tracker √© uma funcionalidade fundamental dentro de um ML Ops.\",\\n    \"Sua import√¢ncia reside principalmente em Traceabilidade.\",\\n    \"Ele permite rastrear a origem e a evolu√ß√£o de todos os artefatos criados ao longo do ciclo de vida do projeto de Machine Learning.\",\\n    \"Isso inclui dados de entrada, pr√©-processamentos, modelos treinados, resultados de avalia√ß√£o e muito mais.\",\\n    \"Saber exatamente de onde veio um dado ou um modelo √© crucial.\",\\n    \"Com o rastreamento da linhagem, √© poss√≠vel replicar exatamente as mesmas condi√ß√µes e passos que levaram √† cria√ß√£o de um artefato espec√≠fico.\",\\n    \"Isso √© vital para valida√ß√£o, auditoria e para tentar corrigir problemas em sistemas j√° implementados.\",\\n    \"Se um modelo come√ßa a falhar ou produzir resultados inesperados, o lineage tracker ajuda a entender por onde ele passou.\",\\n    \"Voc√™ pode verificar qual conjunto de dados foi usado, quais pr√©-processamentos foram aplicados, qual foi a vers√£o do modelo e at√© mesmo o ambiente de treinamento.\",\\n    \"Isso facilita enormemente a identifica√ß√£o de problemas.\",\\n    \"O lineage tracker √© uma pe√ßa fundamental para garantir que os processos de MLOps sejam confi√°veis, audit√°veis e eficientes.\",\\n    \"Permitindo um melhor gerenciamento de projetos e uma maior capacidade de depurar problemas.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"\"\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The score is 1.00 because there are no contradictions found in the 'actual output', indicating perfect alignment with the retrieval context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"EML metadata and artifact tracking capability is foundational to all other MLOps capabilities.\",\\n    \"The ML metadata and artifact tracking capability enables reproducibility and debugging of complex ML tasks and pipelines.\",\\n    \"Key functionalities in ML metadata and artifact tracking include providing traceability and lineage tracking of ML artifacts, sharing and tracking experimentation and pipeline parameter configurations, storing, accessing, investigating, visualizing, downloading, and archiving ML artifacts, and integrating with all other MLOps capabilities.\",\\n    \"The ML Ops platform typically includes multiple components such as Automat ed Training, Model V ersioning, Continuous Int egration and Deployment, Monit oring, Support various data modalities, including tabular data, images, and text.\",\\n    \"ML metadata is the information about ML artifacts, including their location, types, properties, and associations to experiments and runs.\",\\n    \"Proper data management in an ML Ops platform ensures that datasets are cleaned and preprocessed efficiently, easily accessible and shareable among users or teams, version-controlled to keep track of changes and updates.\",\\n    \"MLOps platforms should implement policies and best practices to maintain compliance with data protection laws and industrial regulations.\",\\n    \"The following MLOps capabilities include experimentation, model training, model evaluation, model serving, online experimentation, model monitoring, ML pipeline, and model registry.\",\\n    \"Two cross-cutting capabilities that enable integration and interaction are an ML metadata and artifact repository and an ML dataset and feature repository.\"\\n] \\n \\nClaims:\\n[\\n    \"E um lineage tracker √© uma funcionalidade fundamental dentro de um ML Ops (MLOps).\",\\n    \"Sua import√¢ncia reside principalmente em: Traceabilidade, Reprodutibilidade e Depura√ß√£o.\",\\n    \"Ele permite rastrear a origem e a evolu√ß√£o de todos os artefatos criados ao longo do ciclo de vida do projeto de Machine Learning.\",\\n    \"Isso inclui dados de entrada, pr√©-processamentos, modelos treinados, resultados de avalia√ß√£o e muito mais.\",\\n    \"Saber exatamente de onde veio um dado ou um modelo √© crucial.\",\\n    \"Com o rastreamento da linhagem, √© poss√≠vel replicar exatamente as mesmas condi√ß√µes e passos que levaram √† cria√ß√£o de um artefato espec√≠fico (como um modelo ou um conjunto de dados processado).\",\\n    \"Isso √© vital para valida√ß√£o, auditoria e para tentar corrigir problemas em sistemas j√° implementados.\",\\n    \"Se um modelo come√ßa a falhar ou produzir resultados inesperados, o lineage tracker ajuda a entender por onde ele passou.\",\\n    \"Voc√™ pode verificar qual conjunto de dados foi usado, quais pr√©-processamentos foram aplicados, qual foi a vers√£o do modelo e at√© mesmo o ambiente de treinamento.\",\\n    \"Isso facilita enormemente a identifica√ß√£o de problemas.\",\\n    \"O lineage tracker √© uma pe√ßa fundamental para garantir que os processos de MLOps sejam confi√°veis, audit√°veis e eficientes, permitindo um melhor gerenciamento de projetos e uma maior capacidade de depurar problemas.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'Qual a import√¢ncia de um lineage tracker em MLOps?',\n",
       "  'actual_output': 'Um **lineage tracker** (ou rastreador de linhagem) √© uma funcionalidade fundamental dentro de um **ML Ops (MLOps)**. Sua import√¢ncia reside principalmente em:\\n\\n1.  **Traceabilidade:** Ele permite rastrear a origem e a evolu√ß√£o de todos os artefatos criados ao longo do ciclo de vida do projeto de Machine Learning. Isso inclui dados de entrada, pr√©-processamentos, modelos treinados, resultados de avalia√ß√£o e muito mais. Saber exatamente de onde veio um dado ou um modelo √© crucial.\\n\\n2.  **Reprodutibilidade:** Com o rastreamento da linhagem, √© poss√≠vel replicar exatamente as mesmas condi√ß√µes e passos que levaram √† cria√ß√£o de um artefato espec√≠fico (como um modelo ou um conjunto de dados processado). Isso √© vital para valida√ß√£o, auditoria e para tentar corrigir problemas em sistemas j√° implementados.\\n\\n3.  **Depura√ß√£o:** Se um modelo come√ßa a falhar ou produzir resultados inesperados, o lineage tracker ajuda a entender por onde ele passou. Voc√™ pode verificar qual conjunto de dados foi usado, quais pr√©-processamentos foram aplicados, qual foi a vers√£o do modelo e at√© mesmo o ambiente de treinamento. Isso facilita enormemente a identifica√ß√£o de problemas.\\n\\nEm resumo, o lineage tracker √© uma pe√ßa fundamental para garantir que os processos de MLOps sejam confi√°veis, audit√°veis e eficientes, permitindo um melhor gerenciamento de projetos e uma maior capacidade de depurar problemas.',\n",
       "  'expected_output': 'Lineage tracking permite rastrear dados, modelos, experimentos e artefatos para auditoria e reprodutibilidade.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['artifacts, including their location, types, properties, and associations to experiments and runs. The ML metadata and \\nartifact tracking capability is foundational to all other MLOps capabilities. Such a capability enables reproducibility \\nand debugging of complex ML tasks and pipelines. Key functionalities in ML metadata and artifact tracking include \\nthe following:\\n‚Ä¢ Provide traceability and lineage tracking of ML artifacts.\\n‚Ä¢ Share and track experimentation and pipeline parameter configurations.\\n‚Ä¢ Store, access, investigate, visualize, download, and archive ML artifacts.\\n‚Ä¢ Integrate with all other MLOps capabilities.\\nDeep dive of MLOps processes\\nThis section describes each of the core MLOps processes in detail. It describes key tasks and flow of control be -\\ntween tasks, the key artifacts created by the tasks, and the relationship of tasks to other upstream and downstream',\n",
       "   'bridge the gap between machine learning development and the\\nimplementation of ML systems in a production environment. The platform\\nhelps streamline the process of building, deploying, and monitoring\\nmodels, by providing a standardised and automated workflow.\\nThe ML Ops platform typically includes multiple components such as:11/11/25, 9:50 PM MLOps Now - The MLOps Platform: Revolutionising Machine Learning Efficiency\\nhttps://mlopsnow.com/blog/mlops-platforms-revolutionising-machine-learning/ 2/10\\nAutomat ed Training : Automating the training of machine learning\\nmodels on a scheduled basis to keep them updated with fresh data.\\nModel V ersioning : Keeping track of different versions of models and\\nsimplifying the management of those models.\\nContinuous Int egration and Deployment : Ensuring continuous\\nintegration (CI) and automatic deployment of ML models in the\\nproduction environment.\\nMonit oring : Tracking model performance, identifying drifts, and\\nproviding alerts for potential issues.',\n",
       "   '‚Ä¢ Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi -\\ntory might contain an entity called customer, which includes features like age group, postal code, and gender. On the \\nother hand, a dataset repository might include a customer churn dataset, which includes features from the customer \\nand product entities, as well as purchase- and web-activity event logs.\\nML metadata and artifact tracking\\nVarious types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive \\nstatistics and data schemas, trained models, and evaluation results. ML metadata is the information about these \\nartifacts, including their location, types, properties, and associations to experiments and runs. The ML metadata and',\n",
       "   'Proper data management in an ML Ops platform ensures that datasets are:\\nCleaned and preprocessed efficiently.\\nEasily accessible and shareable among users or teams.\\nVersion-controlled to keep track of changes and updates.\\nCompliance and Monit oring\\nCompliance and monitoring play crucial roles in maintaining governance\\nand security in ML Ops platforms. Monitoring tools provide essential\\ninsights to detect and mitigate potential security threats. These tools help\\nin:\\nIdentifying vulnerabilities and generating alerts in real-time.\\nEnsuring data protection and regulatory compliance.\\nTracking user activities, thus allowing auditing and accountability.\\nMLOps platforms should implement policies and best practices to maintain\\ncompliance with data protection laws and industrial regulations. This11/11/25, 9:50 PM MLOps Now - The MLOps Platform: Revolutionising Machine Learning Efficiency\\nhttps://mlopsnow.com/blog/mlops-platforms-revolutionising-machine-learning/ 7/10',\n",
       "   'processing, model training, model evaluation, model serving, online experimentation, model monitoring, ML pipeline, \\nand model registry. Finally, two cross-cutting capabilities that enable integration and interaction are an ML metadata \\nand artifact repository and an ML dataset and feature repository.\\nFigure 4. Core MLOps technical capabilities\\n11\\nThe following sections outline the characteristics of each of the MLOps capabilities.\\nExperimentation \\nThe experimentation capability lets your data scientists and ML researchers collaboratively perform exploratory data \\nanalysis, create prototype model architectures, and implement training routines. An ML environment should also let \\nthem write modular, reusable, and testable source code that is version controlled. Key functionalities in experimenta -\\ntion include the following:\\n‚Ä¢ Provide notebook environments that are integrated with version control tools like Git.'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7095238095238094,\n",
       "    'reason': 'The score is 0.71 because the relevant nodes (nodes 1, 3, and 5) are ranked higher than irrelevant nodes (nodes 2, 4, and 6-8), with the reasons being that these irrelevant nodes only provide superficial information about CT without explaining what it is or how it works.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'continuous training\\' (CT) as a process in ML development, which matches the expected output\\'s mention of CT.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide information about what CT is or how it works, only that it is a process in ML development.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains the importance of CI/CD and automated data and model validation steps for continuous training, which aligns with the expected output\\'s description of CT as retraining models automatically.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide information about what a \\'model prediction service\\' is or how it relates to CT.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context discusses the importance of automating data and model validation steps for continuous training, which aligns with the expected output\\'s description of CT as retraining models automatically.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide information about what \\'metadata management\\' is or how it relates to CT.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context explains the importance of automating data and model validation steps for continuous training, which aligns with the expected output\\'s description of CT as retraining models automatically.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The text does not provide information about what \\'rapid experiment\\' is or how it relates to CT.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6,\n",
       "    'reason': 'The score is 0.60 because the expected output partially matches with nodes in retrieval context, particularly with sentences related to machine learning development phases and processes, such as experimentation, model training, and continuous integration.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node (The core activity during this ML development phase is experimentation...)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node (However, in ML, there are a few notable differences:...)\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node (CT is no longer about a single software package or a service, but a system...)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node (Data science steps for ML\\\\nIn any ML project, after you define the business use case and establish the success criteria,...)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node (\\\\u2022 ML development concerns experimenting and developing a robust and reproducible model training proce -\\\\ndure (training pipeline code), which consists of multiple tasks from data preparation and transformation to \\\\nmodel training and evaluation.)\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node (\\\\u2022 Continuous training concerns repeatedly executing the training pipeline in response to new data or to code \\\\nchanges, or on a schedule, potentially with new training settings.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node (Continuous integration\\\\nIn this setup, the pipeline and its components are built, tested, and packaged when new\\\\ncode is committed or pushed to the source code repository.)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node (Testing that your model training converges (that is, the loss of your model goes down\\\\nby iterations and overfitsxa0(https://en.wikipedia.org/wiki/Overfitting) a few sample records).)\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node (pipeline; this lets you achieve continuous delivery of model prediction service.)\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the retrieval context contains irrelevant information about Figure 3, while relevant statements mention continuous training (CT) as a unique property concerned with automatically retraining and serving models, and repeatedly executing the training pipeline in response to new data or code changes.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"The core activity during this ML development phase is experimentation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"As data scientists and ML research -ers prototype model architectures and training routines, they create labeled datasets, and they use features and other reusable ML artifacts that are governed through the data and model management process.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The primary output of this process is a formalized training procedure, which includes data preprocessing, model architecture, and model training settings.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"If the ML system requires continuous training (repeated retraining of the model), the training procedure is operationalized as a training pipeline.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This requires a CI/CD routine to build, test, and deploy the pipeline to the target execution environment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The continuous training pipeline is executed repeatedly based on retraining triggers, and it produces a model as output.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The model is retrained as new data becomes available, or if model performance decay is detected.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"testing, integration testing, and continuous delivery of the software module or the package.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"CD is no longer about a single software package or a service, but a system (an ML training pipeline) that should automatically deploy another service (model prediction service).\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"CT is a new property, unique to ML systems, that\\'s concerned with automatically retraining and serving the models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The following section discusses the typical steps for training and evaluating an ML model to serve as a prediction service.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data science steps for ML\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"The processes can consist of the following:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"ML development concerns experimenting and developing a robust and reproducible model training procedure (training pipeline code), which consists of multiple tasks from data preparation and transformation to model training and evaluation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Training operationalization concerns automating the process of packaging, testing, and deploying repeatable and reliable training pipelines.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Continuous training concerns repeatedly executing the training pipeline in response to new data or to code changes, or on a schedule, potentially with new training settings.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model deployment concerns packaging, testing, and deploying a model to a serving environment for online experimentation and production serving.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Prediction serving is about serving the model that is deployed in production for inference.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Continuous monitoring is about monitoring the effectiveness and efficiency of a deployed model.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous integration\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In this setup, the pipeline and its components are built, tested, and packaged when new code is committed or pushed to the source code repository.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Besides building packages, container images, and executables, the CI process can include the following tests:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Unit testing your feature engineering logic.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Unit testing the different methods implemented in your model. For example, you have a function that accepts a categorical data column and you encode the function as a one-hot feature.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing that your model training converges (that is, the loss of your model goes down by iterations and overfits a few sample records).\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing that your model training doesn\\'t produce NaN values due to dividing by zero or manipulating small or large values.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing that each component in the pipeline produces the expected artifacts.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"To automate the process of using new data to retrain models in production\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The following figure is a schematic representation of an automated ML pipeline for CT.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Characteristics The following list highlights the characteristics of the MLOps level 1 setup, as shown in Figure 3:\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'Figure 3\\' when it has nothing to do with continuous training (CT).\"\\n            },\\n            {\\n                \"statement\": \"Rapid experiment: The steps of the ML experiment are orchestrated. The transition between steps is automated, which leads to rapid iteration of experiments and better\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly answers the question about what continuous training (CT) is, without any irrelevant information.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"**Continuous Training (CT)** is a unique property of Machine Learning systems that ensures models are retrained automatically to maintain their performance over time.\",\\n    \"The pipeline of training is executed repeatedly.\",\\n    \"Executions are triggered by different triggers, such as: Availability of new data. Detection of decay in the model\\'s performance. Changes in the model code or data. Scheduled events.\",\\n    \"A new model is generated and replaces the old model in production at each execution.\",\\n    \"**CT (Continuous Training)** is specific to ML. The focus is on testing and validating data, models, and training pipelines, and retraining the model to continue serving accurate predictions with the latest data.\",\\n    \"The **Continuous Training** ensures that your ML model is always updated and relevant, learning from new information or adjusting when its performance starts to decline.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The statement is not directly relevant to the definition of continuous training, but it provides supporting information about triggers that can initiate retraining.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.6666666666666666,\n",
       "    'reason': 'The score is 0.67 because the actual output contradicts the retrieval context by stating that the model is retrained automatically or replaced in production, which goes against the focus on experimentation and prototype development mentioned in the context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The core activity during this ML development phase is experimentation.\",\\n    \"As data scientists and ML researchers prototype model architectures and training routines, they create labeled datasets, and they use features and other reusable ML artifacts that are governed through the data and model management process.\",\\n    \"The primary output of this process is a formalized training procedure, which includes data preprocessing, model architecture, and model training settings.\",\\n    \"If the ML system requires continuous training (repeated retraining of the model), the training procedure is operationalized as a training pipeline.\",\\n    \"This requires a CI/CD routine to build, test, and deploy the pipeline to the target execution environment.\",\\n    \"The continuous training pipeline is executed repeatedly based on retraining triggers, and it produces a model as output.\",\\n    \"The model is retrained as new data becomes available, or if model performance decay is detected.\",\\n    \"CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.\",\\n    \"CD is no longer about a single software package or a service, but a system (an ML training pipeline) that should automatically deploy another service (model prediction service).\",\\n    \"CT is a new property, unique to ML systems, that\\'s concerned with automatically retraining and serving the models.\",\\n    \"The process of delivering an ML model to production involves the following steps: defining the business use case, establishing success criteria, experimenting and developing a robust and reproducible model training procedure (training pipeline code), automating the process of packaging, testing, and deploying repeatable and reliable training pipelines, repeatedly executing the training pipeline in response to new data or to code changes, or on a schedule, potentially with new training settings, packaging, testing, and deploying a model to a serving environment for online experimentation and production serving, and monitoring the effectiveness and efficiency of a deployed model.\",\\n    \"Prediction serving is about serving the model that is deployed in production for inference.\",\\n    \"Continuous monitoring is about monitoring the effectiveness and efficiency of a deployed model.\",\\n    \"The CI process can include unit testing your feature engineering logic, unit testing the different methods implemented in your model, testing that your model training converges, testing that your model training doesn\\'t produce NaN values due to dividing by zero or manipulating small or large values, and testing that each component in the pipeline produces the expected artifacts.\",\\n    \"To automate the process of using new data to retrain models in production, you need to introduce automated data and model validation steps to the pipeline, as well as pipeline triggers and metadata management.\"\\n] \\n \\nClaims:\\n[\\n    \"**Continuous Training (CT)** √© uma propriedade √∫nica das sistemas de Machine Learning que garante que os modelos de ML sejam **ree treinados automaticamente** para manterem seu desempenho ao longo do tempo.\",\\n    \"O pipeline de treinamento (que foi formalizado no est√°gio anterior) √© executado repetidamente.\",\\n    \"Essas execu√ß√µes autom√°ticas s√£o acionadas por diferentes gatilhos, como: Disponibilidade de novos dados. Detec√ß√£o de decaimento do desempenho do modelo (performance decay). Altera√ß√µes no c√≥digo do modelo ou nos dados. Cronogramas pr√©-definidos.\",\\n    \"A cada execu√ß√£o, um **novo modelo** √© gerado e substitui o modelo antigo no ambiente de produ√ß√£o.\",\\n    \"**CT (Continuous Training):** √â espec√≠fico de ML. O foco √© testar e validar dados, modelos e pipelines de treinamento, e **ree treinar o modelo** para que ele continue servindo previs√µes precisas com os dados mais recentes.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim states that the model is retrained automatically to maintain its performance over time, which contradicts the retrieval context\\'s focus on experimentation and prototype development.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim mentions different triggers for automatic executions, but it does not provide specific information about these triggers or how they relate to the ML system. The retrieval context only provides general information about continuous training and retraining.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim states that a new model is generated and replaces the old one in the production environment, which contradicts the retrieval context\\'s description of the CI/CD routine as building, testing, and deploying the pipeline to the target execution environment.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© continuous training (CT)?',\n",
       "  'actual_output': 'Okay, vamos esclarecer! üòä\\n\\n**Continuous Training (CT)** √© uma propriedade √∫nica das sistemas de Machine Learning que garante que os modelos de ML sejam **ree treinados automaticamente** para manterem seu desempenho ao longo do tempo.\\n\\nAqui est√° o que isso significa na pr√°tica:\\n\\n1.  **Reentrenamento Autom√°tico:** O pipeline de treinamento (que foi formalizado no est√°gio anterior) √© executado repetidamente.\\n2.  **Gatilhos:** Essas execu√ß√µes autom√°ticas s√£o acionadas por diferentes gatilhos, como:\\n    *   Disponibilidade de novos dados.\\n    *   Detec√ß√£o de decaimento do desempenho do modelo (performance decay).\\n    *   Altera√ß√µes no c√≥digo do modelo ou nos dados.\\n    *   Cronogramas pr√©-definidos.\\n\\n3.  **Sa√≠da:** A cada execu√ß√£o, um **novo modelo** √© gerado e substitui o modelo antigo no ambiente de produ√ß√£o.\\n\\n**Por que √© diferente do CI/CD tradicional?**\\n\\n*   **CI/CD (Integra√ß√£o e Entrega Continuas):** Trabalha com software tradicional. O foco √© testar e validar mudan√ßas no c√≥digo e componentes, e entregar pacotes ou servi√ßos.\\n*   **CT (Continuous Training):** √â espec√≠fico de ML. O foco √© testar e validar dados, modelos e pipelines de treinamento, e **ree treinar o modelo** para que ele continue servindo previs√µes precisas com os dados mais recentes.\\n\\nEm resumo, o **Continuous Training** garante que seu modelo ML seja sempre atualizado e relevante, aprendendo com novas informa√ß√µes ou ajustando-se quando seu desempenho come√ßa a declinar. √â como ter um modelo que \"estuda\" sozinho para se manter atualizado! üìö‚ú®',\n",
       "  'expected_output': 'CT √© a pr√°tica de treinar novamente modelos automaticamente com novos dados conforme regras definidas.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['flow:\\n1. The core activity during this ML development phase is experimentation. As data scientists and ML research -\\ners prototype model architectures and training routines, they create labeled datasets, and they use features \\nand other reusable ML artifacts that are governed through the data and model management process. The \\nFigure 3. The MLOps process\\n9\\nprimary output of this process is a formalized training procedure, which includes data preprocessing, model \\narchitecture, and model training settings. \\n2. If the ML system requires continuous training (repeated retraining of the model), the training procedure is \\noperationalized as a training pipeline. This requires a CI/CD routine to build, test, and deploy the pipeline to \\nthe target execution environment.\\n3. The continuous training pipeline is executed repeatedly based on retraining triggers, and it produces a model \\nas output. The model is retrained as new data becomes available, or if model performance decay is detected.',\n",
       "   \"testing, integration testing, and continuous delivery of the software module or the package.\\nHowever, in ML, there are a few notable differences:\\nCI is no longer only about testing and validating code and components, but also\\ntesting and validating data, data schemas, and models.\\nCD is no longer about a single software package or a service, but a system (an ML\\ntraining pipeline) that should automatically deploy another service (model prediction\\nservice).\\nCT is a new property, unique to ML systems, that's concerned with automatically\\nretraining and serving the models.\\nThe following section discusses the typical steps for training and evaluating an ML model\\nto serve as a prediction service.\\nData science steps for ML\\nIn any ML project, after you define the business use case and establish the success criteria,\\nthe process of delivering an ML model to production involves the following steps. These\\nsteps can be completed manually or can be completed by an automatic pipeline.\",\n",
       "   'The processes can consist of the following:\\n‚Ä¢ ML development concerns experimenting and developing a robust and reproducible model training proce -\\ndure (training pipeline code), which consists of multiple tasks from data preparation and transformation to \\nmodel training and evaluation.\\n‚Ä¢ Training operationalization concerns automating the process of packaging, testing, and deploying repeat -\\nable and reliable training pipelines.\\n‚Ä¢ Continuous training concerns repeatedly executing the training pipeline in response to new data or to code \\nchanges, or on a schedule, potentially with new training settings.\\n‚Ä¢ Model deployment concerns packaging, testing, and deploying a model to a serving environment for online \\nexperimentation and production serving.\\nFigure 2 . The MLOps lifecycle\\n8\\n‚Ä¢ Prediction serving is about serving the model that is deployed in production for inference.\\n‚Ä¢ Continuous monitoring is about monitoring the effectiveness and efficiency of a deployed model.',\n",
       "   \"Continuous integration\\nIn this setup, the pipeline and its components are built, tested, and packaged when new\\ncode is committed or pushed to the source code repository. Besides building packages,\\ncontainer images, and executables, the CI process can include the following tests:\\nUnit testing your feature engineering logic.\\nUnit testing the different methods implemented in your model. For example, you have\\na function that accepts a categorical data column and you encode the function as a\\none-hot\\xa0(https://en.wikipedia.org/wiki/One-hot) feature.\\nTesting that your model training converges (that is, the loss of your model goes down\\nby iterations and overfits\\xa0(https://en.wikipedia.org/wiki/Overfitting) a few sample records).\\nTesting that your model training doesn't produce NaN\\xa0(https://en.wikipedia.org/wiki/NaN)\\nvalues due to dividing by zero or manipulating small or large values.\\nTesting that each component in the pipeline produces the expected artifacts.\",\n",
       "   'pipeline; this lets you achieve continuous delivery of model prediction service. To automate\\nthe process of using new data to retrain models in production, you need to introduce\\nautomated data and model validation steps to the pipeline, as well as pipeline triggers and\\nmetadata management.\\nThe following figure is a schematic representation of an automated ML pipeline for CT.11/13/25, 11:39 PM MLOps: Continuous delivery and automation pipelines in machine learning | Cloud Architecture Center | Google Cloud Do‚Ä¶\\nhttps://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning 8/18\\nFigure 3. ML pipeline automation for CT.\\nCharacteristics\\nThe following list highlights the characteristics of the MLOps level 1 setup, as shown in\\nFigure 3:\\nRapid experiment: The steps of the ML experiment are orchestrated. The transition\\nbetween steps is automated, which leads to rapid iteration of experiments and better'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': False,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.25,\n",
       "    'reason': \"The score is 0.25 because the first four nodes are irrelevant to understanding how a system of AB testing works for models, as they discuss unrelated topics such as MLOps capabilities and version control. The fifth node, however, mentions A/B testing and its relevance to introducing new models, indicating that it should be ranked higher than the other 'no' verdicts.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context does not provide information about how a system of AB testing works for models.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The context discusses MLOps capabilities, but does not specifically mention AB testing.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context talks about the steps involved in delivering an ML model to production, but does not provide information about how a system of AB testing works for models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context mentions \\'A/B testing is sometimes overlooked in Machine Learning but is a great way to introduce new models.\\' This suggests that the author has some knowledge about A/B testing, which is relevant to the topic of how a system of AB testing works for models.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context discusses version control in ML Ops, but does not provide information about how a system of AB testing works for models.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.52,\n",
       "    'reason': 'The score is 0.52 because the contextual recall score indicates that the expected output sentence partially matches with nodes in the retrieval context, but not perfectly, suggesting a moderate level of relevance between the two.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'Typical assets produced in this process include the following:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Core MLOps capabilities:\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'Data changes\\\\nModel training code changes\\\\nApplication code changes.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'Automated testing helps you discover problems early for fast error \\\\ufb01xes and learnings.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'Read about IaC \\\\u00bb\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node: \\'Continuous X\\\\nThrough automation, you can continuously run tests and deploy code across your ML pipeline.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node: \\'CI is no longer only about testing and validating code and components, but also\\\\ntesting and validating data, data schemas, and models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"8th node: \\'CT is a new property, unique to ML systems, that\\'s concerned with automatically\\\\nretraining and serving the models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"9th node: \\'Data science steps for ML\\\\nIn any ML project, after you define the business use case and establish the success criteria,\\\\nthe process of delivering an ML model to production involves the following steps.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"10th node: \\'Continuous Integration.\\\\nMonit oring identifies model drif t over time. Without model monitoring,\\\\nproduction systems are flying blind.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"11th node: \\'Testing ensur es the accuracy and r eliability o f models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"12th node: \\'Use A/B t esting t o identif y best models.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"13th node: \\'Version Contr ol\\\\nVersion control is a significant aspect of ML Ops. It allows teams to track\\'\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': False,\n",
       "    'score': 0.3793103448275862,\n",
       "    'reason': 'The score is 0.38 because the retrieval context contains general information about MLOps capabilities and typical assets produced in an MLOps process, but none of these statements have any relevance to how a system of AB testing for models works.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Como funciona um sistema de AB testing para modelos?\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Typical assets produced in this process include the following:\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained general information about MLOps capabilities, but it has nothing to do with how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Notebooks for experimentation and visualization\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of typical assets produced in an MLOps process, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Metadata and artifacts of the experiments\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of typical assets produced in an MLOps process, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Data schemas\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of typical assets produced in an MLOps process, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Query scripts for the training data\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of typical assets produced in an MLOps process, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Source code and configurations for data validation and transformation\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of typical assets produced in an MLOps process, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Source code and configurations for creating, training, and evaluating models\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of typical assets produced in an MLOps process, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Source code and configurations for the training-pipeline workflow\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of typical assets produced in an MLOps process, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Source code for unit tests and integration tests\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of typical assets produced in an MLOps process, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"Core MLOps capabilities:\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of MLOps capabilities, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Dataset & feature repository\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of MLOps capabilities, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Data processing\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of MLOps capabilities, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Experimentation\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of MLOps capabilities, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Model training\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of MLOps capabilities, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 Model registry\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of MLOps capabilities, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"\\\\u2022 ML metadata & artifact repository\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the list of MLOps capabilities, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"19\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A pipeline typically goes through a series of testing and staging environments before it is released to production.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the context about MLOps, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"The number of testing and staging environments varies depending on standards that are established in a given organization.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the context about MLOps, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            },\\n            {\\n                \"statement\": \"Most organizations have at least one testing environment before production; some have more.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement is part of the context about MLOps, but it has no relevance to the input question about how a system of AB testing for models works.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Data changes\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model training code changes\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Application code changes.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Automated testing helps you discover problems early for fast error \\\\ufb01xes and learnings.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Automation is more e\\\\ufb03cient with infrastructure as code (IaC).\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"You can use tools to de\\\\ufb01ne and manage infrastructure.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"This helps ensure it\\'s reproducible and can be consistently deployed across various environments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Read about IaC \\\\u00bb\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Continuous X\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Through automation, you can continuously run tests and deploy code across your ML pipeline.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In MLOps, continuous refers to four activities that happen continuously if any change is made anywhere in the system:\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Continuous integration extends the validation and testing of code to data and models in the pipeline\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Continuous delivery automatically deploys the newly trained model or model prediction service\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Continuous training automatically retrains ML models for redeployment\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Continuous monitoring concerns data monitoring and model monitoring using metrics related to business Model governance\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"testing, integration testing, and continuous delivery of the software module or the package.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about CI in the context of software development, not ML model training.\"\\n            },\\n            {\\n                \"statement\": \"CD is no longer about a single software package or a service, but a system (an ML training pipeline) that should automatically deploy another service (model prediction service).\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The statement talks about CD in the context of software development, not ML model training.\"\\n            },\\n            {\\n                \"statement\": \"CT is a new property, unique to ML systems, that\\'s concerned with automatically retraining and serving the models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The following section discusses the typical steps for training and evaluating an ML model to serve as a prediction service.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Data science steps for ML\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous Integration.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"\\\\\"Continuous Integration.\\\\\" has no relevance to the functioning of an A/B testing system for models.\"\\n            },\\n            {\\n                \"statement\": \"Monit oring identifies model drif t over time.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without model monitoring, production systems are flying blind.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By monitoring for model drift the data science team is able to proactively work rather than reactively.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing ensur es the accuracy and r eliability o f models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Validating both the model\\\\u2019s predictions and the data sets used is a fundamental step in greenlighting models for production.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Use A/B t esting t o identif y best models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A/B testing is sometimes overlooked in Machine Learning but is a great way to introduce new models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Rather than swapping models out straight away you can introduce the new model alongside the old. This weighted approach allows you to see the efficacy of the new model in production before committing to it.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Version Contr ol\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"\\\\\"Version Contr ol\\\\\" has no relevance to the functioning of an A/B testing system for models.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Verifying that models meet the predictive performance targets before they are deployed.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Automated deployment to a test environment, for example, a deployment that is triggered by pushing code to the development branch.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about automated deployment, but it has nothing to do with how AB testing works.\"\\n            },\\n            {\\n                \"statement\": \"Semi-automated deployment to a pre-production environment, for example, a deployment that is triggered by merging code to the main branch after reviewers approve the changes.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about semi-automated deployment, but it has nothing to do with how AB testing works.\"\\n            },\\n            {\\n                \"statement\": \"Manual deployment to a production environment after several successful runs of the pipeline on the pre-production environment.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about manual deployment, but it has nothing to do do with how AB testing works.\"\\n            },\\n            {\\n                \"statement\": \"To summarize, implementing ML in a production environment doesn\\'t only mean deploying your model as an API for prediction. Rather, it means deploying an ML pipeline that can automate the retraining and deployment of new models.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about implementing ML in a production environment, but it has nothing to do with how AB testing works.\"\\n            },\\n            {\\n                \"statement\": \"Setting up a CI/CD system lets you automatically test and deploy new pipeline implementations. This system lets you cope with rapid changes in your data and business environment.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained information about setting up a CI/CD system, but it has nothing to do with how AB testing works.\"\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about how a system of A/B testing works for models, with no irrelevant statements.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"A/B testing for models works as follows.\",\\n    \"The introduction of the new model is gradual, not immediate.\",\\n    \"Data input is divided randomly between the old and new models.\",\\n    \"Performance metrics are monitored in real-time.\",\\n    \"Relevant metrics are collected, such as precision, recall, or conversion rate.\",\\n    \"Results are analyzed statistically to determine if the new model\\'s performance is significant and better than the old one.\",\\n    \"If the new model shows statistically significant better performance, it can be promoted to production.\",\\n    \"Otherwise, the old model remains as standard.\",\\n    \"Imagine a recommendation system with an old and new model.\",\\n    \"During A/B testing, 10% of users receive recommendations from the new model, while 90% continue using the old one.\",\\n    \"If the new model results in a 10% higher click rate, it can be adopted completely.\",\\n    \"This approach reduces the risk of implementing a bad model directly into production.\",\\n    \"It provides concrete data to validate improvements before scaling up.\",\\n    \"This approach is essential for ensuring models meet business requirements reliably and efficiently.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"This statement is not directly related to the functioning of an A/B testing system for models, but it provides a concrete example that supports the concept.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.875,\n",
       "    'reason': 'The score is 0.88 because the actual output does not align with the information presented in the retrieval context due to a contradiction that the retrieval context does not mention A/B testing for models, which is the main topic of this claim.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"MLOps capabilities include dataset & feature repository, data processing, experimentation, model training, model registry, ML metadata & artifact repository.\",\\n    \"A pipeline typically goes through a series of testing and staging environments before it is released to production.\",\\n    \"The number of testing and staging environments varies depending on standards that are established in a given organization.\",\\n    \"Most organizations have at least one testing environment before production; some have more.\",\\n    \"Automated testing helps you discover problems early for fast error fixes and learnings.\",\\n    \"Automation is more efficient with infrastructure as code (IaC).\",\\n    \"IaC helps ensure it\\'s reproducible and can be consistently deployed across various environments.\",\\n    \"Continuous integration extends the validation and testing of code to data and models in the pipeline.\",\\n    \"Continuous delivery automatically deploys the newly trained model or model prediction service.\",\\n    \"Continuous training automatically retrains ML models for redeployment.\",\\n    \"Continuous monitoring concerns data monitoring and model monitoring using metrics related to business.\",\\n    \"The typical steps for training and evaluating an ML model include continuous integration, testing, and continuous delivery.\",\\n    \"Model governance is a concern in MLOps.\",\\n    \"In ML, CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.\",\\n    \"CD is no longer about a single software package or service, but a system (an ML training pipeline) that should automatically deploy another service (model prediction service).\",\\n    \"CT is a new property, unique to ML systems, that\\'s concerned with automatically retraining and serving the models.\",\\n    \"The process of delivering an ML model to production involves defining the business use case, establishing success criteria, continuous integration, monitoring, testing, and version control.\",\\n    \"Model drift over time can be identified through monitoring.\",\\n    \"Testing ensures the accuracy and reliability of models.\",\\n    \"A/B testing is a way to identify the best models.\",\\n    \"Version control is a significant aspect of ML Ops.\",\\n    \"Implementing ML in a production environment means deploying an ML pipeline that can automate the retraining and deployment of new models.\"\\n] \\n \\nClaims:\\n[\\n    \"A/B testing for models works by introducing the new model alongside the old one, with input data being divided randomly between the two.\",\\n    \"The performance of both models is monitored in real-time and relevant metrics are collected, such as precision, recall, conversion rate, or any other criterion defined by the project.\",\\n    \"The results are analyzed statistically to determine if the difference in performance of the new model is significant and better than the old one.\",\\n    \"If the new model demonstrates statistically significant better performance, it can be promoted to production. Otherwise, the old model remains as standard.\",\\n    \"A/B testing reduces the risk of implementing a bad model directly into production.\",\\n    \"A/B testing provides concrete data to validate improvements before scaling up.\",\\n    \"This approach is essential to ensure that models meet business requirements in a reliable and efficient manner.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The retrieval context does not mention A/B testing for models, which is the main topic of this claim.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim mentions monitoring in real-time and collecting relevant metrics, but it\\'s unclear if these steps are directly contradicted by the retrieval context or if they\\'re just not mentioned.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": \"The claim mentions reducing risk and providing concrete data, but it\\'s unclear if these steps are directly contradicted by the retrieval context or if they\\'re just not mentioned.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'Como funciona um sistema de AB testing para modelos?',\n",
       "  'actual_output': 'Um sistema de A/B testing para modelos funciona da seguinte forma:\\n\\n1. **Introdu√ß√£o Gradual do Novo Modelo**:  \\n   Em vez de substituir imediatamente o modelo antigo, ele √© introduzido ao lado dele. Dados de entrada s√£o divididos aleatoriamente entre os dois modelos (antigo e novo).\\n\\n2. **Coleta de M√©tricas**:  \\n   O desempenho de ambos os modelos √© monitorado em tempo real. S√£o coletadas m√©tricas relevantes, como precis√£o, recall, taxa de convers√£o ou qualquer outro crit√©rio definido pelo projeto.\\n\\n3. **Compara√ß√£o Estat√≠stica**:  \\n   Os resultados s√£o analisados estatisticamente para determinar se a diferen√ßa no desempenho do novo modelo √© significativa e melhor do que o modelo antigo.\\n\\n4. **Decis√£o**:  \\n   - Se o novo modelo demonstrar melhor desempenho estatisticamente significativo, ele pode ser promovido para produ√ß√£o.  \\n   - Caso contr√°rio, o modelo antigo permanece como padr√£o.\\n\\n**Exemplo Pr√°tico**:  \\nImagine que voc√™ tem um sistema de recomenda√ß√£o. O modelo antigo est√° em produ√ß√£o e o novo modelo foi desenvolvido. Durante o A/B testing:  \\n- 10% dos usu√°rios recebem recomenda√ß√µes do novo modelo.  \\n- 90% continuam usando o modelo antigo.  \\nSe o novo modelo resultar em uma taxa de cliques 10% maior, ele pode ser adotado completamente.\\n\\n**Benef√≠cios**:  \\n- Reduz o risco de implementar um modelo ruim diretamente em produ√ß√£o.  \\n- Fornece dados concretos para validar melhorias antes de expandir a escala.  \\n\\nEssa abordagem √© essencial para garantir que os modelos atendam aos requisitos de neg√≥cio de forma confi√°vel e eficiente.',\n",
       "  'expected_output': 'O sistema divide tr√°fego entre modelos diferentes para comparar performance estatisticamente.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['Typical assets produced in this \\nprocess include the following:\\n‚Ä¢ Notebooks for experimentation \\nand visualization\\n‚Ä¢ Metadata and artifacts of the \\nexperiments\\n‚Ä¢ Data schemas\\n‚Ä¢ Query scripts for the training data\\n‚Ä¢ Source code and configurations for \\ndata validation and transformation\\n‚Ä¢ Source code and configurations for \\ncreating, training, and evaluating \\nmodels\\n‚Ä¢ Source code and configurations for \\nthe training-pipeline workflow\\n‚Ä¢ Source code for unit tests and \\nintegration tests\\nCore MLOps capabilities:\\n‚Ä¢ Dataset & feature repository\\n‚Ä¢ Data processing\\n‚Ä¢ Experimentation\\n‚Ä¢ Model training\\n‚Ä¢ Model registry\\n‚Ä¢ ML metadata & artifact repository\\n19\\nA pipeline typically goes through a series of testing and staging environ -\\nments before it is released to production. The number of testing and stag -\\ning environments varies depending on standards that are established in a \\ngiven organization. Most organizations have at least one testing environ -\\nment before production; some have more.',\n",
       "   \"Data changes\\nModel training code changes\\nApplication code changes.\\nAutomated testing helps you discover problems early for fast error Ô¨Åxes and learnings. Automation is more\\neÔ¨Écient with infrastructure as code (IaC). You can use tools to deÔ¨Åne and manage infrastructure. This helps\\nensure it's reproducible and can be consistently deployed across various environments.\\nRead about IaC ¬ª\\nContinuous X\\nThrough automation, you can continuously run tests and deploy code across your ML pipeline.\\nIn MLOps, continuous refers to four activities that happen continuously if any change is made anywhere in\\nthe system:\\nContinuous integration extends the validation and testing of code to data and models in the pipeline\\nContinuous delivery automatically deploys the newly trained model or model prediction service\\nContinuous training automatically retrains ML models for redeployment\\nContinuous monitoring concerns data monitoring and model monitoring using metrics related to\\nbusiness\\nModel governance\",\n",
       "   \"testing, integration testing, and continuous delivery of the software module or the package.\\nHowever, in ML, there are a few notable differences:\\nCI is no longer only about testing and validating code and components, but also\\ntesting and validating data, data schemas, and models.\\nCD is no longer about a single software package or a service, but a system (an ML\\ntraining pipeline) that should automatically deploy another service (model prediction\\nservice).\\nCT is a new property, unique to ML systems, that's concerned with automatically\\nretraining and serving the models.\\nThe following section discusses the typical steps for training and evaluating an ML model\\nto serve as a prediction service.\\nData science steps for ML\\nIn any ML project, after you define the business use case and establish the success criteria,\\nthe process of delivering an ML model to production involves the following steps. These\\nsteps can be completed manually or can be completed by an automatic pipeline.\",\n",
       "   'Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track',\n",
       "   \"Verifying that models meet the predictive performance targets before they are\\ndeployed.\\nAutomated deployment to a test environment, for example, a deployment that is\\ntriggered by pushing code to the development branch.\\nSemi-automated deployment to a pre-production environment, for example, a\\ndeployment that is triggered by merging code to the main branch after reviewers\\napprove the changes.\\nManual deployment to a production environment after several successful runs of the\\npipeline on the pre-production environment.\\nTo summarize, implementing ML in a production environment doesn't only mean deploying\\nyour model as an API for prediction. Rather, it means deploying an ML pipeline that can\\nautomate the retraining and deployment of new models. Setting up a CI/CD system lets you\\nautomatically test and deploy new pipeline implementations. This system lets you cope\\nwith rapid changes in your data and business environment. You don't have to immediately\"],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None},\n",
       " {'name': 'test_case_0',\n",
       "  'success': True,\n",
       "  'metrics_data': [{'name': 'Contextual Precision',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': \"The score is 0.50 because irrelevant nodes (nodes 1 and 3) are ranked lower than relevant nodes (nodes 2 and 4), indicating that the model correctly prioritizes contexts with information about 'champion' and 'challenger' models.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context does not provide information about champion vs challenger models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions \\'champion\\' and \\'challenger\\' models, which are relevant to the topic of model comparison.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context does not provide information about champion vs challenger models.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text mentions \\'champion\\' and \\'challenger\\' models, which are relevant to the topic of model comparison.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"This context does not provide information about champion vs challenger models.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Recall',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.8888888888888888,\n",
       "    'reason': \"The score is 0.89 because the contextual recall accurately captures the relationships between sentences in the expected output, with most sentences being attributed to nodes in the retrieval context, except for one standalone statement that doesn't require specific context.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"1st node: \\'O modelo champion \\\\u00e9 o atual em produ\\\\u00e7\\\\u00e3o...\\' - This sentence can be attributed to the nodes of retrieval contexts as it is a standalone statement that does not require any specific context.\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"No specific node in the retrieval context can be attributed to this sentence, as it appears to be an independent thought.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"2nd node: \\'Undeclared Consumers. Oftentimes, a prediction from a machine learning model mais made...\\' - This sentence can be attributed to the nodes of retrieval contexts as it is part of a larger discussion about undeclared consumers.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"3rd node: \\'Continuous Integration.\\\\nMonit oring identifies model drif t over time...\\' - This sentence can be attributed to the nodes of retrieval contexts as it appears to be part of a larger discussion about continuous integration and monitoring.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"4th node: \\'Testing ensur es the accuracy and r eliability o f models...\\' - This sentence can be attributed to the nodes of retrieval contexts as it is part of a larger discussion about testing and validation in machine learning.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"5th node: \\'Use A/B t esting t o identif y best models...\\' - This sentence can be attributed to the nodes of retrieval contexts as it appears to be part of a larger discussion about testing and validation in machine learning.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"6th node: \\'4. Version Contr ol\\\\nVersion control is a significant aspect of ML Ops...\\' - This sentence can be attributed to the nodes of retrieval contexts as it appears to be part of a larger discussion about version control in machine learning.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"7th node: \\'Model T raining\\\\nOnce the model has been created, it is trained using a suitable dataset...\\' - This sentence can be attributed to the nodes of retrieval contexts as it appears to be part of a larger discussion about model training in machine learning.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"8th node: \\'Following the training phase, model evaluation is conducted to assess the performance...\\' - This sentence can be attributed to the nodes of retrieval contexts as it appears to be part of a larger discussion about model evaluation in machine learning.\"\\n    }\\n]'},\n",
       "   {'name': 'Contextual Relevancy',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.7567567567567568,\n",
       "    'reason': \"The score is 0.76 because the retrieval context contains relevant statements about machine learning models, specifically discussing topics like model monitoring, validation, and evaluation, which are closely related to champion vs challenger models. For example, statements like 'By monitoring for model drift the data science team is able to proactively work rather than reactively.' and 'Evaluation is critical to ensure that the models perform well in real-world scenarios.' demonstrate a connection between the retrieval context and the input question.\",\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"more expensive to analyze improvements to that model in the future.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The cost increases when correction models are cascaded, with a model for problem A\\\\u2032\\\\u2032learned on top of m\\\\u2032 a, and so on, for several slightly different test distributions.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Once in place, a correction cascade can create an improvement deadlock, as improving the accuracy of any individual component actually leads to system-level detriments.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Mitigation strategies are to augment learn the corrections directly within the same model by adding features to distinguish among the cases, or to accept the cost of creating a separate model for A\\\\u2032.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Undeclared Consumers. Oftentimes, a prediction from a machine learning model mais made widely accessible, either at runtime or by writing to \\\\ufb01les or logs that may later be consumed by other systems.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without access controls, some of these consu mers may be undeclared , silently using the output of a given model as an input to another system.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In mo re classical software engineering,\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"The retrieval context contained the information \\'In more classical software engineering\\' when it has nothing to do with champion vs challenger models.\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Without access controls, some of these consu mers may be undeclared , silently using\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In mo re classical software engineering, these issues are referred to as visibility debt.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Undeclared consumers are expensive at best and dangerous at worst, because they create a hidden tight coupling of model mato other parts of the stack.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Changes to mawill very likely impact these other parts, potentially in ways that are unintended, poorl y understood, and detrimental.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"In practice, this tight coupling can radically increase the cost and dif\\\\ufb01 culty of making any changes to maat all, even if they are improvements.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Furthermore, undeclared con sumers may create hidden feedback loops, which are described more in detail in section 4.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Undeclared consumers may be dif\\\\ufb01cult to detect unless the sy stem is speci\\\\ufb01cally designed to guard\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Continuous Integration.\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"\\\\\"Continuous Integration.\\\\\" has no relevance to the topic \\\\\"champion vs challenger\\\\\".\"\\n            },\\n            {\\n                \"statement\": \"Monit oring identifies model drift over time.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Without model monitoring, production systems are flying blind.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"By monitoring for model drift the data science team is able to proactively work rather than reactively.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Testing ensures the accuracy and reliability of models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Validating both the model\\'s predictions and the data sets used is a fundamental step in greenlighting models for production.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Use A/B testing to identify best models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"A/B testing is sometimes overlooked in Machine Learning but is a great way to introduce new models.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Rather than swapping models out straight away you can introduce the new model alongside the old. This weighted approach allows you to see the efficacy of the new model in production before committing to it.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"4. Version Control\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"\\\\\"Version Control\\\\\" has no relevance to the topic \\\\\"champion vs challenger.\\\\\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"this phase, data engineers work together with data scientists to prepare and preprocess the data, performing featur e engineering to ensure the data has the right format and structure.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"During model creation, various data pipelines are developed, enabling the smooth flow of information between the different stages of the machine learning process.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Tools such as data engineering platforms can be used to design, test and maintain these pipelines.\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Once the model has been created, it is trained using a suitable dataset.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Model training is an iterative process that involves feeding data into the model for it to learn and make predictions.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"The model is continually adjusted, and its performance is evaluated against a validation dataset to fine-tune its accuracy and effectiveness.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Several techniques can be applied during the model training phase, including hyperparameter optimisation, cross-validation, and regularisation.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Utilising the right combination of these methods helps\",\\n                \"verdict\": \"no\",\\n                \"reason\": null\\n            }\\n        ]\\n    },\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Evaluation is critical to ensure that the models perform well in real-world scenarios.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'},\n",
       "   {'name': 'Answer Relevancy',\n",
       "    'threshold': 0.8,\n",
       "    'success': True,\n",
       "    'score': 1.0,\n",
       "    'reason': 'The score is 1.00 because the actual output directly addresses the question about the difference between a Champion and Challenger model, making all statements highly relevant to the input.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Statements:\\n[\\n    \"Um modelo Champion vs Challenger √© uma abordagem estrat√©gica utilizada para gerenciar modelos de machine learning em produ√ß√£o.\",\\n    \"Existem dois modelos: Modelo Champion (Campe√£o) e Modelo Challenger.\",\\n    \"O modelo Champion atualmente em produ√ß√£o √© confi√°vel e est√° sendo monitorado.\",\\n    \"O modelo Challenger √© um novo modelo que est√° sendo testado em paralelo com o Champion.\",\\n    \"O objetivo √© validar seu desempenho em dados de produ√ß√£o antes de substituir completamente o modelo Champion.\",\\n    \"O modelo Challenger √© lan√ßado inicialmente em uma fra√ß√£o de tr√°fego (ou dados) para minimizar riscos.\",\\n    \"Seu desempenho √© monitorado cuidadosamente usando m√©tricas como precis√£o, recall e m√©tricas de neg√≥cios relevantes.\",\\n    \"Se o Challenger demonstrar consistentemente melhor desempenho, ele pode ser promovido ao papel de Champion. Caso contr√°rio, o Champion permanece como modelo principal.\",\\n    \"Essa pr√°tica √© especialmente √∫til em ambientes cr√≠ticos, onde mudan√ßas indireitas podem ter consequ√™ncias severas.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'},\n",
       "   {'name': 'Faithfulness',\n",
       "    'threshold': 0.5,\n",
       "    'success': True,\n",
       "    'score': 0.5,\n",
       "    'reason': 'The score is 0.50 because the actual output contradicts the retrieval context by discussing specific approaches to managing machine learning models, Champion-Challenger model validation, monitoring and evaluation of performance, scenarios where new models replace existing ones, minimizing risks when introducing new models, and critical environments for changes, which are not mentioned in the retrieval context.',\n",
       "    'strict_mode': False,\n",
       "    'evaluation_model': 'llama3:latest (Ollama)',\n",
       "    'error': None,\n",
       "    'evaluation_cost': 0.0,\n",
       "    'verbose_logs': 'Truths (limit=None):\\n[\\n    \"The cost of analyzing improvements to a model increases when correction models are cascaded.\",\\n    \"A correction cascade can create an improvement deadlock, where improving the accuracy of any individual component leads to system-level detriments.\",\\n    \"Mitigation strategies for improvement deadlocks include augmenting to learn corrections directly within the same model or creating a separate model for each problem.\",\\n    \"Undeclared consumers of a machine learning model\\'s output can be expensive and dangerous because they create hidden tight coupling with other parts of the stack.\",\\n    \"Changes to a model can impact undeclared consumers in unintended, poorly understood, and detrimental ways.\",\\n    \"Undeclared consumers may create hidden feedback loops.\",\\n    \"Model monitoring is necessary for identifying model drift over time.\",\\n    \"Continuous integration ensures the accuracy and reliability of models by validating predictions and data sets used.\",\\n    \"A/B testing is a way to introduce new models and identify the best one.\",\\n    \"Version control is significant in ML Ops, allowing teams to track changes and collaborate.\",\\n    \"Data engineers work together with data scientists to prepare and preprocess data for model creation.\",\\n    \"Various data pipelines are developed during model creation to enable smooth flow of information between stages.\",\\n    \"Model training involves feeding data into the model for it to learn and make predictions.\",\\n    \"Model evaluation is critical to assess the performance of models on unseen data.\",\\n    \"Evaluation metrics include accuracy, precision, recall, and fairness measures.\",\\n    \"Careful evaluation helps identify and address potential issues like bias or overfitting.\"\\n] \\n \\nClaims:\\n[\\n    \"Um **modelo Champion vs Challenger** √© uma abordagem estrat√©gica utilizada para gerenciar modelos de machine learning em produ√ß√£o.\",\\n    \"H√° dois modelos: o Modelo Champion (Campe√£o) e o Modelo Challenger.\",\\n    \"O modelo Champion √© confi√°vel e est√° sendo monitorado.\",\\n    \"O objetivo do Modelo Challenger √© validar seu desempenho em dados de produ√ß√£o antes de substituir completamente o modelo Champion.\",\\n    \"O modelo Challenger √© lan√ßado inicialmente em uma fra√ß√£o de tr√°fego (ou dados) para minimizar riscos.\",\\n    \"Seu desempenho √© monitorado cuidadosamente usando m√©tricas como precis√£o, recall e m√©tricas de neg√≥cios relevantes.\",\\n    \"Se o Modelo Challenger demonstrar consistentemente melhor desempenho, ele pode ser promovido ao papel de Champion. Caso contr√°rio, o Champion permanece como modelo principal.\",\\n    \"A abordagem **Champion vs Challenger** evita impactos negativos imediatos ao mudar repentinamente para um modelo inacredit√°vel.\",\\n    \"Essa pr√°tica √© especialmente √∫til em ambientes cr√≠ticos, onde mudan√ßas indireitas podem ter consequ√™ncias severas.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The provided claims are about a specific approach to managing machine learning models in production, which is not mentioned in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claims describe a Champion-Challenger model validation process, which is not discussed in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claims detail the monitoring and evaluation of the Challenger model\\'s performance, which is not mentioned in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claims describe a scenario where a new model (Challenger) replaces an existing one (Champion), which is not discussed in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claims highlight the importance of minimizing risks when introducing a new model, which is not mentioned in the retrieval context.\"\\n    },\\n    {\\n        \"verdict\": \"idk\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claims emphasize the criticality of environments where changes can have severe consequences, which is not discussed in the retrieval context.\"\\n    }\\n]'}],\n",
       "  'conversational': False,\n",
       "  'multimodal': False,\n",
       "  'input': 'O que √© um modelo champion vs challenger?',\n",
       "  'actual_output': 'Um **modelo Champion vs Challenger** √© uma abordagem estrat√©gica utilizada para gerenciar modelos de machine learning em produ√ß√£o. Nessa abordagem, existem dois modelos:\\n\\n1. **Modelo Champion (Campe√£o)**: O modelo atualmente em produ√ß√£o, que √© confi√°vel e est√° sendo monitorado. Ele √© mantido at√© que seja comprovado que o modelo Challenger ofere√ßa melhorias significativas.\\n\\n2. **Modelo Challenger**: Um novo modelo que est√° sendo testado em paralelo com o Champion. O objetivo √© validar seu desempenho em dados de produ√ß√£o antes de substituir completamente o modelo Champion.\\n\\n### Como funciona?\\n- **Introdu√ß√£o Gradual**: O modelo Challenger √© lan√ßado inicialmente em uma fra√ß√£o de tr√°fego (ou dados) para minimizar riscos.\\n- **Avalia√ß√£o em Produ√ß√£o**: Seu desempenho √© monitorado cuidadosamente usando m√©tricas como precis√£o, recall e m√©tricas de neg√≥cios relevantes.\\n- **Decis√£o Bin√°ria**: Se o Challenger demonstrar consistentemente melhor desempenho, ele pode ser promovido ao papel de Champion. Caso contr√°rio, o Champion permanece como modelo principal.\\n\\n### Por que essa abordagem?\\n- **Redu√ß√£o de Riscos**: Evita impactos negativos imediatos ao mudar repentinamente para um modelo inacredit√°vel.\\n- **Valida√ß√£o Pr√°tica**: Garante que o modelo funcione bem em condi√ß√µes reais, e n√£o apenas em dados de treino.\\n\\nEssa pr√°tica √© especialmente √∫til em ambientes cr√≠ticos, onde mudan√ßas indireitas podem ter consequ√™ncias severas.',\n",
       "  'expected_output': 'O modelo champion √© o atual em produ√ß√£o, enquanto challengers s√£o avaliados como potenciais substitutos.',\n",
       "  'context': None,\n",
       "  'retrieval_context': ['more expensive to analyze improvements to that model in the f uture. The cost increases when\\ncorrection models are cascaded, with a model for problem A‚Ä≤‚Ä≤learned on top of m‚Ä≤\\na, and so on,\\nfor several slightly different test distributions. Once in place, a correction cascade can create an\\nimprovement deadlock, as improving the accuracy of any indi vidual component actually leads to\\nsystem-level detriments. Mitigation strategies are to aug mentmato learn the corrections directly\\nwithin the same model by adding features to distinguish amon g the cases, or to accept the cost of\\ncreating a separate model for A‚Ä≤.\\nUndeclared Consumers. Oftentimes, a prediction from a machine learning model mais made\\nwidely accessible, either at runtime or by writing to Ô¨Åles or logs that may later be consumed by\\nother systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,',\n",
       "   'other systems. Without access controls, some of these consu mers may be undeclared , silently using\\nthe output of a given model as an input to another system. In mo re classical software engineering,\\nthese issues are referred to as visibility debt .\\nUndeclared consumers are expensive at best and dangerous at worst, because they create a hidden\\ntight coupling of model mato other parts of the stack. Changes to mawill very likely impact these\\nother parts, potentially in ways that are unintended, poorl y understood, and detrimental. In practice,\\nthis tight coupling can radically increase the cost and difÔ¨Å culty of making any changes to maat all,\\neven if they are improvements. Furthermore, undeclared con sumers may create hidden feedback\\nloops, which are described more in detail in section 4.\\n2\\nUndeclared consumers may be difÔ¨Åcult to detect unless the sy stem is speciÔ¨Åcally designed to guard',\n",
       "   'Continuous Integration.\\xa0\\nMonit oring identifies model drif t over time. Without model monitoring,\\nproduction systems are flying blind. By monitoring for model drift the data\\nscience team is able to proactively work rather than reactively.\\xa0\\nTesting ensur es the accuracy and r eliability o f models. Validating both\\nthe model‚Äôs predictions and the data sets used is a fundamental step in\\ngreenlighting models for production.\\xa0\\nUse A/B t esting t o identif y best models. A/B testing is sometimes\\noverlooked in Machine Learning but is a great way to introduce new\\nmodels. Rather than swapping models out straight away you can introduce\\nthe new model alongside the old. This weighted approach allows you to\\nsee the efficacy of the new model in production before committing to it.\\n4. Version Contr ol\\nVersion control is a significant aspect of ML Ops. It allows teams to track',\n",
       "   'this phase, data engineers work together with data scientists to prepare\\nand preprocess the data, performing featur e engineering to ensure the\\ndata has the right format and structure.\\nDuring model creation, various data pipelines are developed, enabling the\\nsmooth flow of information between the different stages of the machine\\nlearning process. T ools such as data engineering platforms can be used to\\ndesign, test and maintain these pipelines.\\nModel T raining\\nOnce the model has been created, it is trained using a suitable dataset.\\nModel training is an iterative process that involves feeding data into the\\nmodel for it to learn and make predictions. The model is continually\\nadjusted, and its performance is evaluated against a validation dataset to\\nfine-tune its accuracy and effectiveness.\\nSeveral techniques can be applied during the model training phase,\\nincluding hyperparameter optimisation, cross-validation, and\\nregularisation. Utilising the right combination of these methods helps',\n",
       "   'Following the training phase, model evaluation is conducted to assess the performance of the models on unseen data. Evaluation is critical to ensure that the models perform well in real-world scenarios. Metrics such as accuracy, precision, recall and fairness measures gauge how well the model meets the project objectives. These metrics provide a quantitative basis for comparing different models and selecting the best one for deployment. Through careful evaluation, data scientists can identify and address potential issues, such as bias or overfitting, ensuring that the final model is effective and fair.\\n\\nModel deployment'],\n",
       "  'turns': None,\n",
       "  'additional_metadata': None}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval.metrics import (\n",
    "  ContextualRelevancyMetric,\n",
    "  ContextualRecallMetric,\n",
    "  ContextualPrecisionMetric,\n",
    "  AnswerRelevancyMetric,\n",
    "  FaithfulnessMetric\n",
    ")\n",
    "from deepeval import evaluate\n",
    "from deepeval.evaluate import AsyncConfig\n",
    "\n",
    "\n",
    "contextual_precision = ContextualPrecisionMetric(model=model)\n",
    "contextual_recall = ContextualRecallMetric(model=model)\n",
    "contextual_relevancy = ContextualRelevancyMetric(model=model)\n",
    "answer_relevancy = AnswerRelevancyMetric(threshold=0.8, model=model)\n",
    "faithfulness = FaithfulnessMetric(model=model)\n",
    "\n",
    "async_config = AsyncConfig(\n",
    "    run_async=True,\n",
    "    throttle_value=5,  \n",
    "    max_concurrent=1,\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for tc in test_cases:\n",
    "    tc_results = evaluate([tc], \n",
    "                          metrics=[contextual_precision, contextual_recall, contextual_relevancy, answer_relevancy, faithfulness],\n",
    "                          async_config=async_config,\n",
    "                          )\n",
    "    results.append(tc_results.model_dump()['test_results'][0])\n",
    "    \n",
    "# results = evaluate([test_cases[0]], metrics=[contextual_precision, contextual_recall, contextual_relevancy, answer_relevancy, faithfulness])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51eb635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar em JSON resultados da avalia√ß√£o acima\n",
    "\n",
    "with open(\"artifacts/eval_metrics/deepseek-r1/results_deepeval.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b30ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Carrega o JSON salvo anteriormente\n",
    "# with open(\"results_deepeval.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     results = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-pca (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
